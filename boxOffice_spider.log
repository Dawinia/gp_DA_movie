2020-04-30 00:37:43,922 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-04-30 00:37:43,997 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-04-30 00:37:44,009 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-04-30 00:37:44,086 -  telnet.py[line:60] - INFO: Telnet Password: 78ef43be8f48b540
2020-04-30 00:37:44,187 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-30 00:37:45,383 -  middlewares.py[line:135] - ERROR: start to use judge duplicate
2020-04-30 00:37:45,399 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-30 00:37:45,406 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-30 00:37:45,470 -  pipelines.py[line:16] - ERROR: start to use judge duplicate
2020-04-30 00:37:45,471 -  pipelines.py[line:62] - ERROR: setting: custom boxOffice setting
2020-04-30 00:37:45,628 -  pipelines.py[line:58] - ERROR: pipeline init
2020-04-30 00:37:45,629 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.BoxOfficePipeline', 'movie.pipelines.MySQLPipeline']
2020-04-30 00:37:45,629 -  engine.py[line:257] - INFO: Spider opened
2020-04-30 00:37:45,635 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-30 00:37:45,638 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6024
2020-04-30 00:37:45,654 -  movie_spider.py[line:96] - ERROR: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-04-30 00:37:45,658 -  middlewares.py[line:147] - ERROR: url = http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430
2020-04-30 00:37:45,886 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430> (referer: None)
2020-04-30 00:37:46,197 -  movie_spider.py[line:115] - ERROR: now crawl url : http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430
2020-04-30 00:37:46,355 -  movie_spider.py[line:143] - WARNING: get 1 movie info, named .
2020-04-30 00:37:46,358 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:46,359 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:46,364 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:46,791 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'sql_mode'
2020-04-30 00:37:46,791 -  log.py[line:110] - INFO: {}
2020-04-30 00:37:46,866 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'lower_case_table_names'
2020-04-30 00:37:46,867 -  log.py[line:110] - INFO: {}
2020-04-30 00:37:46,872 -  log.py[line:110] - INFO: SELECT DATABASE()
2020-04-30 00:37:46,873 -  log.py[line:110] - INFO: {}
2020-04-30 00:37:46,875 -  log.py[line:110] - INFO: show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'
2020-04-30 00:37:46,875 -  log.py[line:110] - INFO: {}
2020-04-30 00:37:46,979 -  log.py[line:110] - INFO: SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1
2020-04-30 00:37:46,979 -  log.py[line:110] - INFO: {}
2020-04-30 00:37:46,981 -  log.py[line:110] - INFO: SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1
2020-04-30 00:37:46,981 -  log.py[line:110] - INFO: {}
2020-04-30 00:37:46,983 -  log.py[line:110] - INFO: SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1
2020-04-30 00:37:46,984 -  log.py[line:110] - INFO: {}
2020-04-30 00:37:46,988 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:46,992 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:46,993 -  log.py[line:110] - INFO: {'movieID': 248172, 'movieName': '复仇者联盟4：终局之战', 'seatRate': '20.3%', 'boxInfo': '25633.43', 'boxRate': '89.1%', 'releaseInfo': '上映7天', 'showInfo': 196869, 'showRate': '67.7%', 'splitBoxInfo': '24376.14', 'splitSumBoxInfo': '248400.0', 'sumBoxInfo': '261400.0', 'showView': '28', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#1'}
2020-04-30 00:37:47,017 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:47,284 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:47,751 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled
2020-04-30 00:37:47,751 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 00:37:47,783 -  movie_spider.py[line:143] - WARNING: get 2 movie info, named .
2020-04-30 00:37:47,784 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:47,784 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:47,784 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:47,784 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:47,785 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:47,785 -  log.py[line:110] - INFO: {'movieID': 1218727, 'movieName': '何以为家', 'seatRate': '17.1%', 'boxInfo': '1532.82', 'boxRate': '5.3%', 'releaseInfo': '重映2天', 'showInfo': 33430, 'showRate': '11.5%', 'splitBoxInfo': '1410.52', 'splitSumBoxInfo': '2615.2', 'sumBoxInfo': '2852.7', 'showView': '16', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#2'}
2020-04-30 00:37:47,786 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:47,951 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:47,997 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled
2020-04-30 00:37:47,997 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-04-30 00:37:48,030 -  movie_spider.py[line:143] - WARNING: get 3 movie info, named .
2020-04-30 00:37:48,032 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:48,032 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:48,033 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:48,033 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:48,033 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:48,033 -  log.py[line:110] - INFO: {'movieID': 672279, 'movieName': '雪暴', 'seatRate': '7.8%', 'boxInfo': '518.13', 'boxRate': '1.8%', 'releaseInfo': '上映首日', 'showInfo': 25016, 'showRate': '8.6%', 'splitBoxInfo': '495.67', 'splitSumBoxInfo': '519.1', 'sumBoxInfo': '541.8', 'showView': '7', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#3'}
2020-04-30 00:37:48,035 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:48,134 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:48,851 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-04-30 00:37:48,882 -  movie_spider.py[line:143] - WARNING: get 4 movie info, named .
2020-04-30 00:37:48,884 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:48,884 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:48,884 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:48,884 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:48,885 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:48,885 -  log.py[line:110] - INFO: {'movieID': 1228776, 'movieName': '下一任：前任', 'seatRate': '42.4%', 'boxInfo': '307.56', 'boxRate': '1.0%', 'releaseInfo': '零点场', 'showInfo': 1756, 'showRate': '0.6%', 'splitBoxInfo': '279.29', 'splitSumBoxInfo': '279.2', 'sumBoxInfo': '307.5', 'showView': '52', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#4'}
2020-04-30 00:37:48,886 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:48,987 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:49,652 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-04-30 00:37:49,663 -  movie_spider.py[line:143] - WARNING: get 5 movie info, named .
2020-04-30 00:37:49,663 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:49,663 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:49,664 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:49,664 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:49,664 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:49,664 -  log.py[line:110] - INFO: {'movieID': 1243904, 'movieName': '动物出击', 'seatRate': '10.3%', 'boxInfo': '170.74', 'boxRate': '0.5%', 'releaseInfo': '上映首日', 'showInfo': 9806, 'showRate': '3.3%', 'splitBoxInfo': '168.29', 'splitSumBoxInfo': '174.7', 'sumBoxInfo': '177.2', 'showView': '6', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#5'}
2020-04-30 00:37:49,665 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:49,793 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:50,323 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-04-30 00:37:50,355 -  movie_spider.py[line:143] - WARNING: get 6 movie info, named .
2020-04-30 00:37:50,356 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:50,357 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:50,357 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:50,357 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:50,358 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:50,358 -  log.py[line:110] - INFO: {'movieID': 1211727, 'movieName': '反贪风暴4', 'seatRate': '7.7%', 'boxInfo': '128.25', 'boxRate': '0.4%', 'releaseInfo': '上映27天', 'showInfo': 6052, 'showRate': '2.0%', 'splitBoxInfo': '119.37', 'splitSumBoxInfo': '72300.0', 'sumBoxInfo': '78300.0', 'showView': '7', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#6'}
2020-04-30 00:37:50,359 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:50,468 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:50,540 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:37:50,691 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled
2020-04-30 00:37:50,692 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-04-30 00:37:50,708 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:37:50,712 -  movie_spider.py[line:143] - WARNING: get 7 movie info, named .
2020-04-30 00:37:50,712 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:50,712 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:50,713 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:50,713 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:50,713 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:50,713 -  log.py[line:110] - INFO: {'movieID': 1230152, 'movieName': '撞死了一只羊', 'seatRate': '8.0%', 'boxInfo': '96.69', 'boxRate': '0.3%', 'releaseInfo': '上映5天', 'showInfo': 3094, 'showRate': '1.0%', 'splitBoxInfo': '94.05', 'splitSumBoxInfo': '674.5', 'sumBoxInfo': '701.1', 'showView': '9', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#7'}
2020-04-30 00:37:50,720 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:50,869 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:50,872 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:37:50,873 -  movie_spider.py[line:167] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-04-30 and tpp_id = 248172
2020-04-30 00:37:50,874 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 00:37:50,874 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:37:50,874 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 00:37:52,144 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled
2020-04-30 00:37:52,144 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-04-30 00:37:52,172 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 00:37:52,187 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:37:52,191 -  movie_spider.py[line:167] - INFO: movie_name = 何以为家 and movie_year = 2019-04-30 and tpp_id = 1218727
2020-04-30 00:37:52,191 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-04-30 00:37:52,191 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:37:52,191 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-04-30 00:37:53,531 -  movie_spider.py[line:143] - WARNING: get 8 movie info, named .
2020-04-30 00:37:53,534 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:53,534 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:53,535 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:53,536 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:53,537 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:53,537 -  log.py[line:110] - INFO: {'movieID': 1239544, 'movieName': '调音师', 'seatRate': '11.6%', 'boxInfo': '81.45', 'boxRate': '0.2%', 'releaseInfo': '上映28天', 'showInfo': 2678, 'showRate': '0.9%', 'splitBoxInfo': '74.25', 'splitSumBoxInfo': '28400.0', 'sumBoxInfo': '31500.0', 'showView': '10', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#8'}
2020-04-30 00:37:53,539 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:53,714 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:53,716 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-04-30 00:37:53,726 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:37:53,753 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98)
2020-04-30 00:37:53,754 -  movie_spider.py[line:167] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-04-30 and tpp_id = 1211727
2020-04-30 00:37:53,754 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-04-30 00:37:53,754 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:37:53,754 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-04-30 00:37:55,724 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled
2020-04-30 00:37:55,725 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:37:55,734 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-04-30 00:37:55,741 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:37:55,743 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6)
2020-04-30 00:37:55,746 -  movie_spider.py[line:167] - INFO: movie_name = 雪暴 and movie_year = 2019-04-30 and tpp_id = 672279
2020-04-30 00:37:55,746 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-04-30 00:37:55,746 -  movie_spider.py[line:173] - INFO: len of text is 2
2020-04-30 00:37:55,746 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-04-30 00:37:57,633 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-04-30 00:37:57,636 -  movie_spider.py[line:143] - WARNING: get 9 movie info, named .
2020-04-30 00:37:57,638 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:37:57,638 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:37:57,638 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:37:57,638 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:37:57,639 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:37:57,639 -  log.py[line:110] - INFO: {'movieID': 1211412, 'movieName': '神奇乐园历险记', 'seatRate': '6.5%', 'boxInfo': '38.32', 'boxRate': '0.1%', 'releaseInfo': '上映12天', 'showInfo': 2274, 'showRate': '0.7%', 'splitBoxInfo': '36.31', 'splitSumBoxInfo': '2668.2', 'sumBoxInfo': '2863.7', 'showView': '6', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#9'}
2020-04-30 00:37:57,640 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:37:57,750 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:37:57,752 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-04-30 00:37:57,770 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled
2020-04-30 00:37:57,770 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-04-30 00:37:57,776 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:37:57,778 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44)
2020-04-30 00:37:57,778 -  movie_spider.py[line:167] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-04-30 and tpp_id = 1230152
2020-04-30 00:37:57,779 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-04-30 00:37:57,779 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:37:57,779 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-04-30 00:37:58,973 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 00:37:58,992 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:37:58,993 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:37:58,993 -  movie_spider.py[line:223] - CRITICAL: items = ['小罗伯特·唐尼', '克里斯·埃文斯', '马克·鲁弗洛', '克里斯·海姆斯沃斯', '斯嘉丽·约翰逊', '杰瑞米·雷纳', '保罗·路德', '凯伦·吉兰', '唐·钱德尔', '布丽·拉尔森']
2020-04-30 00:37:58,995 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['831441'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-04-30 00:38:00,707 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled
2020-04-30 00:38:00,707 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:38:00,737 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-04-30 00:38:00,752 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:00,754 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4)
2020-04-30 00:38:00,757 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4)
2020-04-30 00:38:01,930 -  movie_spider.py[line:167] - INFO: movie_name = 下一任：前任 and movie_year = 2019-04-30 and tpp_id = 1228776
2020-04-30 00:38:01,932 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-04-30 00:38:01,932 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:38:01,932 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-04-30 00:38:03,674 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-04-30 00:38:03,689 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:03,689 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:03,690 -  movie_spider.py[line:223] - CRITICAL: items = ['赞恩·阿尔·拉菲亚', '约丹诺斯·希费罗', '博鲁瓦蒂夫·特雷杰·班科尔', '卡萨尔·艾尔·哈达德', '法迪·尤瑟夫', '海塔·塞德拉·伊扎姆', '阿拉·乔什涅', '娜丁·拉巴基', '埃利亚斯·库利', '努尔·艾尔·侯赛尼']
2020-04-30 00:38:03,691 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30170448
{'actors': '赞恩·阿尔·拉菲亚/约丹诺斯·希费罗/博鲁瓦蒂夫·特雷杰·班科尔/卡萨尔·艾尔·哈达德/法迪·尤瑟夫/海塔·塞德拉·伊扎姆/阿拉·乔什涅/娜丁·拉巴基/埃利亚斯·库利/努尔·艾尔·侯赛尼',
 'area': ' 黎巴嫩 / 法国 / 美国',
 'dbMovieID': ['30170448'],
 'directors': '娜丁·拉巴基',
 'doubanRate': ['9.1'],
 'duration': [126],
 'genre': '剧情',
 'movieName': ['何以为家 كفرناحوم'],
 'publishedDate': ['2018-05-17'],
 'rateCount': ['635987'],
 'tppMovieID': [1218727],
 'writers': '娜丁·拉巴基/吉哈德·霍加里/米歇尔·凯斯沃尼/乔治斯·哈巴兹/哈立德·穆扎纳'}
2020-04-30 00:38:03,693 -  movie_spider.py[line:143] - WARNING: get 10 movie info, named .
2020-04-30 00:38:03,694 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:03,694 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:03,694 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:03,695 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:03,695 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:38:03,695 -  log.py[line:110] - INFO: {'movieID': 330115, 'movieName': '我和神马查干', 'seatRate': '--', 'boxInfo': '24.05', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 154, 'showRate': '<0.1%', 'splitBoxInfo': '23.94', 'splitSumBoxInfo': '1982.0', 'sumBoxInfo': '1988.9', 'showView': '51', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#10'}
2020-04-30 00:38:03,696 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:03,912 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:38:03,914 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-04-30 00:38:03,942 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:03,947 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A)
2020-04-30 00:38:03,948 -  movie_spider.py[line:167] - INFO: movie_name = 调音师 and movie_year = 2019-04-30 and tpp_id = 1239544
2020-04-30 00:38:03,948 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:03,948 -  movie_spider.py[line:173] - INFO: len of text is 6
2020-04-30 00:38:03,948 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:05,595 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:05,595 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-04-30 00:38:05,611 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:05,611 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:05,611 -  movie_spider.py[line:223] - CRITICAL: items = ['古天乐', '郑嘉颖', '林峯', '林家栋', '周秀娜', '张智霖', '谭耀文', '张继聪', '蔡瀚亿', '廖启智']
2020-04-30 00:38:05,613 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27202819
{'actors': '古天乐/郑嘉颖/林峯/林家栋/周秀娜/张智霖/谭耀文/张继聪/蔡瀚亿/廖启智',
 'area': ' 中国香港 / 中国大陆',
 'dbMovieID': ['27202819'],
 'directors': '林德禄',
 'doubanRate': ['6.0'],
 'duration': [96],
 'genre': '动作/犯罪',
 'movieName': ['反贪风暴4 P風暴'],
 'publishedDate': ['2019-04-04'],
 'rateCount': ['131724'],
 'tppMovieID': [1211727],
 'writers': '黄浩华/何文龙'}
2020-04-30 00:38:07,215 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled
2020-04-30 00:38:07,215 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-04-30 00:38:07,243 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:07,261 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled
2020-04-30 00:38:07,261 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:07,280 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB)
2020-04-30 00:38:08,811 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:10,750 -  movie_spider.py[line:167] - INFO: movie_name = 动物出击 and movie_year = 2019-04-30 and tpp_id = 1243904
2020-04-30 00:38:10,752 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-04-30 00:38:10,754 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:38:10,754 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-04-30 00:38:12,189 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-04-30 00:38:12,214 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:12,214 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:12,214 -  movie_spider.py[line:223] - CRITICAL: items = ['张震', '倪妮', '廖凡', '黄觉', '刘桦', '张奕聪', '李光洁', '岳小军', '昌隆', '王太利']
2020-04-30 00:38:12,215 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:12,216 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:38:12,216 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:12,216 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:12,217 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-04-30 00:38:12,217 -  log.py[line:110] - INFO: {'dbMovieID': '26899146', 'tppMovieID': 672279, 'movieName': '雪暴', 'directors': '崔斯韦', 'writers': '崔斯韦', 'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利', 'genre': '动作/犯罪/悬疑', 'area': ' 中国大陆', 'duration': 111, 'publishedDate': '2018-10-05', 'rateCount': '52266', 'doubanRate': '6.2'}
2020-04-30 00:38:12,218 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:12,823 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4>
None
2020-04-30 00:38:12,824 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-04-30 00:38:12,838 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:12,838 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:12,839 -  movie_spider.py[line:223] - CRITICAL: items = ['张震', '倪妮', '廖凡', '黄觉', '刘桦', '张奕聪', '李光洁', '岳小军', '昌隆', '王太利']
2020-04-30 00:38:12,840 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26899146
{'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利',
 'area': ' 中国大陆',
 'dbMovieID': ['26899146'],
 'directors': '崔斯韦',
 'doubanRate': ['6.2'],
 'duration': [111],
 'genre': '动作/犯罪/悬疑',
 'movieName': ['雪暴'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['52266'],
 'tppMovieID': [672279],
 'writers': '崔斯韦'}
2020-04-30 00:38:12,842 -  movie_spider.py[line:143] - WARNING: get 11 movie info, named .
2020-04-30 00:38:12,842 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:12,842 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:12,842 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:12,843 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:12,843 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:38:12,843 -  log.py[line:110] - INFO: {'movieID': 1189325, 'movieName': '捉妖学院', 'seatRate': '4.0%', 'boxInfo': '23.76', 'boxRate': '<0.1%', 'releaseInfo': '上映首日', 'showInfo': 285, 'showRate': '<0.1%', 'splitBoxInfo': '23.73', 'splitSumBoxInfo': '23.7', 'sumBoxInfo': '23.7', 'showView': '9', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#11'}
2020-04-30 00:38:12,844 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:13,089 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:38:13,091 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-04-30 00:38:13,117 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:13,134 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:13,137 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88)
2020-04-30 00:38:13,139 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88)
2020-04-30 00:38:13,139 -  movie_spider.py[line:167] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-04-30 and tpp_id = 1211412
2020-04-30 00:38:13,139 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:38:13,139 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:38:13,139 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:38:14,651 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-04-30 00:38:14,663 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:14,663 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:14,664 -  movie_spider.py[line:223] - CRITICAL: items = ['金巴', '更登彭措', '索朗旺姆', '加华草']
2020-04-30 00:38:14,665 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30283179
{'actors': '金巴/更登彭措/索朗旺姆/加华草',
 'area': ' 中国大陆',
 'dbMovieID': ['30283179'],
 'directors': '万玛才旦',
 'doubanRate': ['7.2'],
 'duration': [87],
 'genre': '剧情',
 'movieName': ['撞死了一只羊'],
 'publishedDate': ['2018-09-04'],
 'rateCount': ['40862'],
 'tppMovieID': [1230152],
 'writers': '万玛才旦/次仁罗布'}
2020-04-30 00:38:16,556 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:20,845 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-04-30 00:38:20,852 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled
2020-04-30 00:38:20,852 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:20,858 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:38:20,867 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB)
2020-04-30 00:38:20,868 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88)
2020-04-30 00:38:22,390 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-04-30 00:38:22,403 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:22,403 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:22,403 -  movie_spider.py[line:223] - CRITICAL: items = ['郭采洁', '郑恺', '李东学', '谢依霖', '刘心悠', '邱欣怡', '李荣浩', '蓝心湄', '林辰唏', '林美秀']
2020-04-30 00:38:22,405 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:22,405 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:38:22,405 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:22,405 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:22,406 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-04-30 00:38:22,406 -  log.py[line:110] - INFO: {'dbMovieID': '26311974', 'tppMovieID': 1228776, 'movieName': '下一任：前任', 'directors': '陈鸿仪', 'writers': '陈鸿仪', 'actors': '郭采洁/郑恺/李东学/谢依霖/刘心悠/邱欣怡/李荣浩/蓝心湄/林辰唏/林美秀', 'genre': '爱情', 'area': ' 中国台湾 / 中国大陆', 'duration': 99, 'publishedDate': '2019-05-01', 'rateCount': '23766', 'doubanRate': '2.8'}
2020-04-30 00:38:22,406 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:22,559 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-04-30 00:38:23,742 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:23,748 -  movie_spider.py[line:143] - WARNING: get 12 movie info, named .
2020-04-30 00:38:23,749 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:23,749 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:23,749 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:23,750 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:23,750 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:38:23,750 -  log.py[line:110] - INFO: {'movieID': 476263, 'movieName': '天上再见', 'seatRate': '8.4%', 'boxInfo': '20.58', 'boxRate': '<0.1%', 'releaseInfo': '上映首日', 'showInfo': 2292, 'showRate': '0.7%', 'splitBoxInfo': '19.00', 'splitSumBoxInfo': '34.8', 'sumBoxInfo': '36.5', 'showView': '3', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#12'}
2020-04-30 00:38:23,775 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:23,932 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:38:23,933 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled
2020-04-30 00:38:23,933 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:23,962 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:23,966 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88)
2020-04-30 00:38:23,970 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0)
2020-04-30 00:38:23,970 -  movie_spider.py[line:167] - INFO: movie_name = 我和神马查干 and movie_year = 2019-04-30 and tpp_id = 330115
2020-04-30 00:38:23,971 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-04-30 00:38:23,971 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:38:23,971 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-04-30 00:38:25,655 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:25,672 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:25,672 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:25,672 -  movie_spider.py[line:223] - CRITICAL: items = ['阿尤斯曼·库拉纳', '塔布', '拉迪卡·艾普特', '安尔·德霍万', '马纳夫·维吉', '阿什维尼·卡尔塞卡', '查亚·卡达姆', '萨基尔·侯赛因', '拉什米·阿格德卡', '莫希尼·凯瓦拉曼']
2020-04-30 00:38:25,674 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:25,674 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:38:25,674 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:25,674 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:25,674 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-04-30 00:38:25,674 -  log.py[line:110] - INFO: {'dbMovieID': '30334073', 'tppMovieID': 1239544, 'movieName': '调音师 Andhadhun', 'directors': '斯里兰姆·拉格万', 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内', 'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼', 'genre': '喜剧/犯罪/悬疑/惊悚', 'area': ' 印度', 'duration': 139, 'publishedDate': '2018-10-05', 'rateCount': '654885', 'doubanRate': '8.3'}
2020-04-30 00:38:25,675 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:25,876 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-04-30 00:38:25,877 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:25,919 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:25,919 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:25,920 -  movie_spider.py[line:223] - CRITICAL: items = ['阿尤斯曼·库拉纳', '塔布', '拉迪卡·艾普特', '安尔·德霍万', '马纳夫·维吉', '阿什维尼·卡尔塞卡', '查亚·卡达姆', '萨基尔·侯赛因', '拉什米·阿格德卡', '莫希尼·凯瓦拉曼']
2020-04-30 00:38:25,922 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30334073
{'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼',
 'area': ' 印度',
 'dbMovieID': ['30334073'],
 'directors': '斯里兰姆·拉格万',
 'doubanRate': ['8.3'],
 'duration': [139],
 'genre': '喜剧/犯罪/悬疑/惊悚',
 'movieName': ['调音师 Andhadhun'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['654885'],
 'tppMovieID': [1239544],
 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内'}
2020-04-30 00:38:29,506 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:29,653 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-04-30 00:38:29,662 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled
2020-04-30 00:38:29,662 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:29,667 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-04-30 00:38:29,676 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88)
2020-04-30 00:38:32,528 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-04-30 00:38:32,540 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:32,540 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:32,540 -  movie_spider.py[line:223] - CRITICAL: items = ['景熙童', '宝德', '冯冯', '冯薇朵', '陈长海', '李浩轩']
2020-04-30 00:38:32,542 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:32,542 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:38:32,542 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:32,543 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:32,543 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-04-30 00:38:32,543 -  log.py[line:110] - INFO: {'dbMovieID': '30345341', 'tppMovieID': 1243904, 'movieName': '动物出击', 'directors': '冯小宁', 'writers': '冯小宁', 'actors': '景熙童/宝德/冯冯/冯薇朵/陈长海/李浩轩', 'genre': '科幻/冒险', 'area': ' 中国大陆', 'duration': 105, 'publishedDate': '2019-04-30', 'rateCount': '1909', 'doubanRate': '3.5'}
2020-04-30 00:38:32,544 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:32,817 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB>
None
2020-04-30 00:38:32,818 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:32,843 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:32,843 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:32,843 -  movie_spider.py[line:223] - CRITICAL: items = ['阿拉·杰米多娃', '雷娜塔·利特维诺娃', '尼娜·鲁斯拉诺娃', 'Yuri', 'Vladimir', '纳塔利亚·布兹科', 'Sergei', 'Olga']
2020-04-30 00:38:32,845 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-04-30 00:38:34,685 -  movie_spider.py[line:143] - WARNING: get 13 movie info, named .
2020-04-30 00:38:34,687 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:34,687 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:34,688 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:34,688 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:34,688 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:38:34,688 -  log.py[line:110] - INFO: {'movieID': 1228750, 'movieName': '照相师', 'seatRate': '70.4%', 'boxInfo': '19.35', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 58, 'showRate': '<0.1%', 'splitBoxInfo': '19.35', 'splitSumBoxInfo': '2046.6', 'sumBoxInfo': '2059.1', 'showView': '83', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#13'}
2020-04-30 00:38:34,689 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:34,790 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:38:34,793 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:34,799 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88)
2020-04-30 00:38:34,804 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2)
2020-04-30 00:38:34,805 -  movie_spider.py[line:167] - INFO: movie_name = 捉妖学院 and movie_year = 2019-04-30 and tpp_id = 1189325
2020-04-30 00:38:34,805 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-04-30 00:38:34,805 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:38:34,805 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-04-30 00:38:36,628 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:36,644 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:36,645 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:36,645 -  movie_spider.py[line:223] - CRITICAL: items = ['阿拉·杰米多娃', '雷娜塔·利特维诺娃', '尼娜·鲁斯拉诺娃', 'Yuri', 'Vladimir', '纳塔利亚·布兹科', 'Sergei', 'Olga']
2020-04-30 00:38:36,646 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-04-30 00:38:36,647 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:38:36,659 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:36,659 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:36,659 -  movie_spider.py[line:223] - CRITICAL: items = ['索菲亚·玛丽', '詹妮弗·加纳', '肯·哈德森·坎贝尔', '基南·汤普森', '米拉·库尼斯', '约翰·奥利弗', '郑肯', '诺贝特·里奥·布茨', '马修·布罗德里克', '凯特·麦克格雷格-斯图尔特']
2020-04-30 00:38:36,661 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26662282
{'actors': '索菲亚·玛丽/詹妮弗·加纳/肯·哈德森·坎贝尔/基南·汤普森/米拉·库尼斯/约翰·奥利弗/郑肯/诺贝特·里奥·布茨/马修·布罗德里克/凯特·麦克格雷格-斯图尔特',
 'area': ' 美国 / 西班牙',
 'dbMovieID': ['26662282'],
 'directors': '迪兰·布朗',
 'doubanRate': ['6.3'],
 'duration': [86],
 'genre': '喜剧/动画/奇幻/冒险',
 'movieName': ['神奇乐园历险记 Wonder Park'],
 'publishedDate': ['2019-03-15'],
 'rateCount': ['2946'],
 'tppMovieID': [1211412],
 'writers': '乔什·阿佩尔鲍姆/安德烈·内梅克/罗伯特·戈登'}
2020-04-30 00:38:40,008 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled
2020-04-30 00:38:40,008 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:38:40,014 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-04-30 00:38:42,453 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:42,462 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:42,462 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:42,463 -  movie_spider.py[line:223] - CRITICAL: items = ['阿拉·杰米多娃', '雷娜塔·利特维诺娃', '尼娜·鲁斯拉诺娃', 'Yuri', 'Vladimir', '纳塔利亚·布兹科', 'Sergei', 'Olga']
2020-04-30 00:38:42,464 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-04-30 00:38:42,467 -  movie_spider.py[line:143] - WARNING: get 14 movie info, named .
2020-04-30 00:38:42,468 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:42,468 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:42,468 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:42,469 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:42,469 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:38:42,469 -  log.py[line:110] - INFO: {'movieID': 1212492, 'movieName': '老师·好', 'seatRate': '9.0%', 'boxInfo': '16.08', 'boxRate': '<0.1%', 'releaseInfo': '重映40天', 'showInfo': 570, 'showRate': '0.1%', 'splitBoxInfo': '15.52', 'splitSumBoxInfo': '32600.0', 'sumBoxInfo': '35300.0', 'showView': '9', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#14'}
2020-04-30 00:38:42,470 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:42,659 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:38:42,662 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:42,668 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2)
2020-04-30 00:38:42,669 -  movie_spider.py[line:167] - INFO: movie_name = 天上再见 and movie_year = 2019-04-30 and tpp_id = 476263
2020-04-30 00:38:42,669 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-04-30 00:38:42,669 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:38:42,669 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-04-30 00:38:44,361 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 00:38:44,382 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:44,383 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:44,383 -  movie_spider.py[line:223] - CRITICAL: items = ['阿拉·杰米多娃', '雷娜塔·利特维诺娃', '尼娜·鲁斯拉诺娃', 'Yuri', 'Vladimir', '纳塔利亚·布兹科', 'Sergei', 'Olga']
2020-04-30 00:38:44,385 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-04-30 00:38:44,386 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-04-30 00:38:44,396 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:44,397 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:44,397 -  movie_spider.py[line:223] - CRITICAL: items = ['']
2020-04-30 00:38:44,398 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:44,398 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:38:44,399 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:44,399 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:44,399 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-04-30 00:38:44,399 -  log.py[line:110] - INFO: {'dbMovieID': '20438453', 'tppMovieID': 330115, 'movieName': '我和神马查干', 'directors': '侯克明/刘珅', 'writers': '刘珅', 'actors': '', 'genre': '剧情/儿童', 'area': ' 中国大陆', 'duration': 90, 'publishedDate': '2012-12-05', 'rateCount': '54', 'doubanRate': '5.3'}
2020-04-30 00:38:44,400 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:44,611 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2>
None
2020-04-30 00:38:44,613 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-04-30 00:38:50,318 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled
2020-04-30 00:38:50,319 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:38:50,335 -  logstats.py[line:48] - INFO: Crawled 31 pages (at 31 pages/min), scraped 19 items (at 19 items/min)
2020-04-30 00:38:50,336 -  movie_spider.py[line:143] - WARNING: get 15 movie info, named .
2020-04-30 00:38:50,337 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:50,337 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:50,337 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:50,337 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:50,338 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-04-30 00:38:50,338 -  log.py[line:110] - INFO: {'movieID': 1236912, 'movieName': '远去的牧歌', 'seatRate': '32.3%', 'boxInfo': '14.79', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 48, 'showRate': '<0.1%', 'splitBoxInfo': '14.79', 'splitSumBoxInfo': '933.7', 'sumBoxInfo': '938.3', 'showView': '74', 'crawlDate': '2019-04-30', 'yearRate': '2019-04-30#15'}
2020-04-30 00:38:50,338 -  log.py[line:110] - INFO: COMMIT
2020-04-30 00:38:50,451 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430>
None
2020-04-30 00:38:50,452 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81)
2020-04-30 00:38:50,453 -  movie_spider.py[line:167] - INFO: movie_name = 照相师 and movie_year = 2019-04-30 and tpp_id = 1228750
2020-04-30 00:38:50,453 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:38:50,453 -  movie_spider.py[line:173] - INFO: len of text is 2
2020-04-30 00:38:50,453 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:38:51,547 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:38:51,549 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-04-30 00:38:51,561 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:51,561 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:51,562 -  movie_spider.py[line:223] - CRITICAL: items = ['王泽宗', '慈婉彤', '周海媚', '胡昌霖']
2020-04-30 00:38:51,563 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:51,563 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:38:51,563 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:51,563 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-04-30 00:38:51,564 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-04-30 00:38:51,564 -  log.py[line:110] - INFO: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}
2020-04-30 00:38:51,578 -  log.py[line:110] - INFO: ROLLBACK
2020-04-30 00:38:51,578 -  scraper.py[line:236] - ERROR: Error processing {'actors': '王泽宗/慈婉彤/周海媚/胡昌霖',
 'area': ' 中国大陆',
 'dbMovieID': ['26879542'],
 'directors': '田梓橙',
 'doubanRate': [''],
 'duration': [96],
 'genre': '奇幻/冒险',
 'movieName': ['捉妖学院'],
 'publishedDate': ['2019-04-30'],
 'rateCount': ['0'],
 'tppMovieID': [1189325],
 'writers': '方岚/田梓橙'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1265, "Data truncated for column 'doubanRate' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-04-30 00:38:51,763 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled
2020-04-30 00:38:51,763 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:38:51,787 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:38:51,978 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:54,326 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C has been crawled
2020-04-30 00:38:54,327 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C
2020-04-30 00:38:54,335 -  movie_spider.py[line:143] - WARNING: get 16 movie info, named .
2020-04-30 00:38:54,336 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:54,336 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:54,336 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:54,336 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['13.97'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1229702],
 'movieName': ['青蛙王子历险记'],
 'releaseInfo': ['上映26天'],
 'seatRate': ['15.1%'],
 'showInfo': [84],
 'showRate': ['<0.1%'],
 'showView': ['22'],
 'splitBoxInfo': ['13.97'],
 'splitSumBoxInfo': ['1009.4'],
 'sumBoxInfo': ['1065.7'],
 'yearRate': ['2019-04-30#16']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:38:54,464 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88)
2020-04-30 00:38:54,471 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88)
2020-04-30 00:38:54,472 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-04-30 00:38:54,509 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:38:54,509 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:38:54,509 -  movie_spider.py[line:223] - CRITICAL: items = ['纳威尔·佩雷兹·毕斯卡亚特', '阿尔贝·杜邦泰尔', '罗兰·拉斐特', '尼尔斯·阿贺斯图普', '艾米莉·德奎恩', '梅兰尼·蒂埃里', '埃洛伊兹·巴尔斯特', '菲利普·乌禅', '安德烈·马尔孔', '米歇尔·维耶尔莫']
2020-04-30 00:38:54,511 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:54,512 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:38:54,512 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:54,512 -  scraper.py[line:236] - ERROR: Error processing {'actors': '纳威尔·佩雷兹·毕斯卡亚特/阿尔贝·杜邦泰尔/罗兰·拉斐特/尼尔斯·阿贺斯图普/艾米莉·德奎恩/梅兰尼·蒂埃里/埃洛伊兹·巴尔斯特/菲利普·乌禅/安德烈·马尔孔/米歇尔·维耶尔莫',
 'area': ' 法国 / 加拿大',
 'dbMovieID': ['26731376'],
 'directors': '阿尔贝·杜邦泰尔',
 'doubanRate': ['8.1'],
 'duration': [117],
 'genre': '喜剧/战争/犯罪',
 'movieName': ['天上再见 Au revoir là-haut'],
 'publishedDate': ['2017-10-25'],
 'rateCount': ['27333'],
 'tppMovieID': [476263],
 'writers': '阿尔贝·杜邦泰尔/皮耶尔·勒迈特'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:38:54,516 -  movie_spider.py[line:143] - WARNING: get 17 movie info, named .
2020-04-30 00:38:54,517 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:54,517 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:54,517 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:54,518 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['13.52'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1217701],
 'movieName': ['九克拉战栗'],
 'releaseInfo': ['重映首日'],
 'seatRate': ['8.4%'],
 'showInfo': [1395],
 'showRate': ['0.4%'],
 'showView': ['4'],
 'splitBoxInfo': ['12.69'],
 'splitSumBoxInfo': ['12.9'],
 'sumBoxInfo': ['13.8'],
 'yearRate': ['2019-04-30#17']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:38:55,485 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 00:38:55,506 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled
2020-04-30 00:38:55,507 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:38:55,513 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:57,455 -  movie_spider.py[line:167] - INFO: movie_name = 老师·好 and movie_year = 2019-04-30 and tpp_id = 1212492
2020-04-30 00:38:57,457 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:38:57,457 -  movie_spider.py[line:173] - INFO: len of text is 6
2020-04-30 00:38:57,457 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:38:58,663 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:38:58,666 -  movie_spider.py[line:143] - WARNING: get 18 movie info, named .
2020-04-30 00:38:58,668 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:38:58,668 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:38:58,669 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:38:58,670 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['13.45'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [643506],
 'movieName': ['古镇画情'],
 'releaseInfo': ['展映'],
 'seatRate': ['--'],
 'showInfo': [67],
 'showRate': ['<0.1%'],
 'showView': ['50'],
 'splitBoxInfo': ['13.41'],
 'splitSumBoxInfo': ['1097.5'],
 'sumBoxInfo': ['1100.3'],
 'yearRate': ['2019-04-30#18']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:38:59,595 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled
2020-04-30 00:38:59,595 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-04-30 00:38:59,621 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:38:59,634 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled
2020-04-30 00:38:59,634 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:38:59,644 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:38:59,645 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:01,144 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:01,147 -  movie_spider.py[line:143] - WARNING: get 19 movie info, named .
2020-04-30 00:39:01,149 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:01,150 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:01,151 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:01,152 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['12.10'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1205909],
 'movieName': ['祈祷落幕时'],
 'releaseInfo': ['上映19天'],
 'seatRate': ['9.8%'],
 'showInfo': [442],
 'showRate': ['0.1%'],
 'showView': ['8'],
 'splitBoxInfo': ['11.08'],
 'splitSumBoxInfo': ['5996.1'],
 'sumBoxInfo': ['6631.6'],
 'yearRate': ['2019-04-30#19']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:01,156 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:39:01,178 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:01,178 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:01,178 -  movie_spider.py[line:223] - CRITICAL: items = ['']
2020-04-30 00:39:01,180 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :34970135
{'actors': '',
 'area': ' 中国大陆',
 'dbMovieID': ['34970135'],
 'directors': '',
 'doubanRate': [''],
 'duration': [4],
 'genre': '短片',
 'movieName': ['照相师'],
 'publishedDate': [''],
 'rateCount': ['0'],
 'tppMovieID': [1228750],
 'writers': ''}
2020-04-30 00:39:01,180 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 00:39:01,192 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:01,192 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:01,193 -  movie_spider.py[line:223] - CRITICAL: items = ['谢钢', '刘牧', '康磊', '涓子', '秦楚明', '马东延', '于卉怡', '上泽', '张优', '方子怡']
2020-04-30 00:39:01,194 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:01,194 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:39:01,194 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:01,195 -  scraper.py[line:236] - ERROR: Error processing {'actors': '谢钢/刘牧/康磊/涓子/秦楚明/马东延/于卉怡/上泽/张优/方子怡',
 'area': ' 中国大陆',
 'dbMovieID': ['30258232'],
 'directors': '张唯',
 'doubanRate': ['5.2'],
 'duration': [112],
 'genre': '剧情/历史',
 'movieName': ['照相师'],
 'publishedDate': ['2018-12-12'],
 'rateCount': ['880'],
 'tppMovieID': [1228750],
 'writers': '张敏'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:01,195 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled
2020-04-30 00:39:01,195 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:01,202 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:01,204 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD)
2020-04-30 00:39:01,205 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD)
2020-04-30 00:39:01,205 -  movie_spider.py[line:167] - INFO: movie_name = 远去的牧歌 and movie_year = 2019-04-30 and tpp_id = 1236912
2020-04-30 00:39:01,206 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C
2020-04-30 00:39:01,206 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:01,206 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30327768/?suggest=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C
2020-04-30 00:39:03,853 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:07,736 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled
2020-04-30 00:39:07,736 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-04-30 00:39:07,743 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled
2020-04-30 00:39:07,743 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:07,750 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30327768/?suggest=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C
2020-04-30 00:39:07,759 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD)
2020-04-30 00:39:07,765 -  movie_spider.py[line:167] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-04-30 and tpp_id = 1217701
2020-04-30 00:39:07,765 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 00:39:07,765 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:07,765 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 00:39:09,141 -  movie_spider.py[line:167] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-04-30 and tpp_id = 1229702
2020-04-30 00:39:09,141 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:39:09,142 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:09,142 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:39:12,537 -  movie_spider.py[line:143] - WARNING: get 20 movie info, named .
2020-04-30 00:39:12,539 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:12,539 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:12,540 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:12,541 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['9.57'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1213175],
 'movieName': ['在乎你'],
 'releaseInfo': ['上映19天'],
 'seatRate': ['11.1%'],
 'showInfo': [36],
 'showRate': ['<0.1%'],
 'showView': ['39'],
 'splitBoxInfo': ['9.57'],
 'splitSumBoxInfo': ['681.3'],
 'sumBoxInfo': ['713.1'],
 'yearRate': ['2019-04-30#20']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:13,296 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled
2020-04-30 00:39:13,296 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:13,323 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:39:13,337 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 00:39:13,346 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:13,348 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD)
2020-04-30 00:39:13,350 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30327768/?suggest=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C)
2020-04-30 00:39:13,350 -  movie_spider.py[line:167] - INFO: movie_name = 古镇画情 and movie_year = 2019-04-30 and tpp_id = 643506
2020-04-30 00:39:13,350 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-04-30 00:39:13,350 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:13,351 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-04-30 00:39:15,157 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:15,174 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:15,174 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:15,174 -  movie_spider.py[line:223] - CRITICAL: items = ['于谦', '汤梦佳', '王广源', '秦鸣悦', '徐子力', '孙艺杨', '徐紫茵', '郝鹏飞', '郜玄铭', '黑妹']
2020-04-30 00:39:15,176 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216192'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-04-30 00:39:15,177 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:15,190 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:15,190 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:15,190 -  movie_spider.py[line:223] - CRITICAL: items = ['于谦', '汤梦佳', '王广源', '秦鸣悦', '徐子力', '孙艺杨', '徐紫茵', '郝鹏飞', '郜玄铭', '黑妹']
2020-04-30 00:39:15,192 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216192'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-04-30 00:39:15,196 -  movie_spider.py[line:143] - WARNING: get 21 movie info, named .
2020-04-30 00:39:15,197 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:15,197 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:15,197 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:15,197 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['7.07'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1238926],
 'movieName': ['我们的爱情'],
 'releaseInfo': ['上映54天'],
 'seatRate': ['45.7%'],
 'showInfo': [32],
 'showRate': ['<0.1%'],
 'showView': ['74'],
 'splitBoxInfo': ['7.07'],
 'splitSumBoxInfo': ['76.9'],
 'sumBoxInfo': ['77.2'],
 'yearRate': ['2019-04-30#21']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:16,130 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85 has been crawled
2020-04-30 00:39:16,130 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:16,147 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-04-30 00:39:16,153 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:16,154 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0)
2020-04-30 00:39:19,239 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:19,267 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:19,267 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:19,267 -  movie_spider.py[line:223] - CRITICAL: items = ['于谦', '汤梦佳', '王广源', '秦鸣悦', '徐子力', '孙艺杨', '徐紫茵', '郝鹏飞', '郜玄铭', '黑妹']
2020-04-30 00:39:19,269 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216192'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-04-30 00:39:19,270 -  movie_spider.py[line:143] - WARNING: get 22 movie info, named .
2020-04-30 00:39:19,270 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:19,271 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:19,271 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:19,271 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['7.06'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1238775],
 'movieName': ['特别追踪'],
 'releaseInfo': [''],
 'seatRate': ['35.4%'],
 'showInfo': [29],
 'showRate': ['<0.1%'],
 'showView': ['49'],
 'splitBoxInfo': ['7.05'],
 'splitSumBoxInfo': ['459.1'],
 'sumBoxInfo': ['459.3'],
 'yearRate': ['2019-04-30#22']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:19,893 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA has been crawled
2020-04-30 00:39:19,893 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA
2020-04-30 00:39:19,903 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:19,904 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85)
2020-04-30 00:39:19,905 -  movie_spider.py[line:167] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-04-30 and tpp_id = 1205909
2020-04-30 00:39:19,906 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-04-30 00:39:19,906 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:19,906 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-04-30 00:39:21,798 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 00:39:21,814 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:21,815 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:21,815 -  movie_spider.py[line:223] - CRITICAL: items = ['于谦', '汤梦佳', '王广源', '秦鸣悦', '徐子力', '孙艺杨', '徐紫茵', '郝鹏飞', '郜玄铭', '黑妹']
2020-04-30 00:39:21,817 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216192'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-04-30 00:39:21,817 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30327768/?suggest=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C
2020-04-30 00:39:21,829 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:21,829 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:21,829 -  movie_spider.py[line:223] - CRITICAL: items = ['海拉提·哈木', '玛尔江·巴依吐肯', '丽娜·夏侃']
2020-04-30 00:39:21,831 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30327768
{'actors': '海拉提·哈木/玛尔江·巴依吐肯/丽娜·夏侃',
 'area': ' 中国大陆',
 'dbMovieID': ['30327768'],
 'directors': '阿迪夏·夏热合曼/周军',
 'doubanRate': ['6.9'],
 'duration': [94],
 'genre': '剧情/西部/冒险',
 'movieName': ['远去的牧歌'],
 'publishedDate': ['2018-09-11'],
 'rateCount': ['1400'],
 'tppMovieID': [1236912],
 'writers': '哈依夏·塔巴热克/高黄刚/周军'}
2020-04-30 00:39:22,993 -  movie_spider.py[line:143] - WARNING: get 23 movie info, named .
2020-04-30 00:39:22,994 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:22,994 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:22,995 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:22,995 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['6.68'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1263355],
 'movieName': ['狗眼看人心'],
 'releaseInfo': ['上映11天'],
 'seatRate': ['3.9%'],
 'showInfo': [878],
 'showRate': ['0.3%'],
 'showView': ['3'],
 'splitBoxInfo': ['6.28'],
 'splitSumBoxInfo': ['1682.7'],
 'sumBoxInfo': ['1812.6'],
 'yearRate': ['2019-04-30#23']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:23,537 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled
2020-04-30 00:39:23,537 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-04-30 00:39:23,544 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-04-30 00:39:23,551 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:26,387 -  movie_spider.py[line:167] - INFO: movie_name = 在乎你 and movie_year = 2019-04-30 and tpp_id = 1213175
2020-04-30 00:39:26,388 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:26,388 -  movie_spider.py[line:173] - INFO: len of text is 6
2020-04-30 00:39:26,388 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:28,155 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:28,156 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:39:28,169 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:28,170 -  movie_spider.py[line:201] - ERROR: json decode error Invalid control character at: line 32 column 73 (char 646) in url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 00:39:28,170 -  scraper.py[line:159] - ERROR: Spider error processing <GET https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0)
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/middlewares.py", line 45, in process_spider_output
    for i in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 203, in parse_movie_info
    text = json.loads(data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 32 column 73 (char 646)
2020-04-30 00:39:28,273 -  movie_spider.py[line:143] - WARNING: get 24 movie info, named .
2020-04-30 00:39:28,274 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:28,274 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:28,274 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:28,275 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['4.71'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [836],
 'movieName': ['毕业那年'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [26],
 'showRate': ['<0.1%'],
 'showView': ['55'],
 'splitBoxInfo': ['4.71'],
 'splitSumBoxInfo': ['1002.1'],
 'sumBoxInfo': ['1003.6'],
 'yearRate': ['2019-04-30#24']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:29,091 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled
2020-04-30 00:39:29,092 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:39:29,101 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:29,108 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled
2020-04-30 00:39:29,108 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:29,116 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:29,117 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6)
2020-04-30 00:39:29,117 -  movie_spider.py[line:167] - INFO: movie_name = 我们的爱情 and movie_year = 2019-04-30 and tpp_id = 1238926
2020-04-30 00:39:29,117 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:29,118 -  movie_spider.py[line:173] - INFO: len of text is 6
2020-04-30 00:39:29,118 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:30,613 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:30,614 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-04-30 00:39:30,624 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:30,624 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:30,624 -  movie_spider.py[line:223] - CRITICAL: items = ['韩夫一']
2020-04-30 00:39:30,626 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:30,626 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:39:30,626 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:30,626 -  scraper.py[line:236] - ERROR: Error processing {'actors': '韩夫一',
 'area': ' 中国',
 'dbMovieID': ['4006324'],
 'directors': '',
 'doubanRate': [''],
 'duration': [0],
 'genre': '剧情',
 'movieName': ['古镇画情'],
 'publishedDate': [''],
 'rateCount': ['0'],
 'tppMovieID': [643506],
 'writers': ''}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:31,707 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:31,713 -  movie_spider.py[line:143] - WARNING: get 25 movie info, named .
2020-04-30 00:39:31,715 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:31,716 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:31,716 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:31,717 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['3.89'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [342568],
 'movieName': ['诡梦凶铃'],
 'releaseInfo': [''],
 'seatRate': ['63.2%'],
 'showInfo': [7],
 'showRate': ['<0.1%'],
 'showView': ['213'],
 'splitBoxInfo': ['3.89'],
 'splitSumBoxInfo': ['1115.7'],
 'sumBoxInfo': ['1115.7'],
 'yearRate': ['2019-04-30#25']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:31,854 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled
2020-04-30 00:39:31,854 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 00:39:31,882 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled
2020-04-30 00:39:31,882 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:31,899 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:31,909 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85 has been crawled
2020-04-30 00:39:31,909 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:31,917 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:31,919 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0)
2020-04-30 00:39:31,920 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0)
2020-04-30 00:39:33,135 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:35,000 -  movie_spider.py[line:167] - INFO: movie_name = 特别追踪 and movie_year = 2019-04-30 and tpp_id = 1238775
2020-04-30 00:39:35,001 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA
2020-04-30 00:39:35,001 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:35,001 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30327877/?suggest=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA
2020-04-30 00:39:38,143 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:38,146 -  movie_spider.py[line:143] - WARNING: get 26 movie info, named .
2020-04-30 00:39:38,149 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:38,149 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:38,150 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:38,151 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['3.73'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1216383],
 'movieName': ['比悲伤更悲伤的故事'],
 'releaseInfo': ['上映48天'],
 'seatRate': ['6.6%'],
 'showInfo': [301],
 'showRate': ['0.1%'],
 'showView': ['5'],
 'splitBoxInfo': ['3.50'],
 'splitSumBoxInfo': ['85800.0'],
 'sumBoxInfo': ['95700.0'],
 'yearRate': ['2019-04-30#26']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:38,444 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled
2020-04-30 00:39:38,445 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:39:38,464 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled
2020-04-30 00:39:38,464 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:38,470 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30327877/?suggest=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA
2020-04-30 00:39:38,477 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85 has been crawled
2020-04-30 00:39:38,477 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:38,484 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:38,486 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0)
2020-04-30 00:39:38,486 -  movie_spider.py[line:167] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-04-30 and tpp_id = 1263355
2020-04-30 00:39:38,486 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-04-30 00:39:38,486 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:38,487 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-04-30 00:39:40,182 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-04-30 00:39:40,197 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:40,197 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:40,198 -  movie_spider.py[line:223] - CRITICAL: items = ['阿部宽', '松岛菜菜子', '沟端淳平', '田中丽奈', '木村绿子', '乌丸节子', '春风亭升太', '音尾琢真', '饭丰万理江', '上杉祥三']
2020-04-30 00:39:40,199 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27040737
{'actors': '阿部宽/松岛菜菜子/沟端淳平/田中丽奈/木村绿子/乌丸节子/春风亭升太/音尾琢真/饭丰万理江/上杉祥三',
 'area': ' 日本',
 'dbMovieID': ['27040737'],
 'directors': '福泽克雄',
 'doubanRate': ['8.0'],
 'duration': [119],
 'genre': '剧情/悬疑',
 'movieName': ['祈祷落幕时 祈りの幕が下りる時'],
 'publishedDate': ['2018-01-27'],
 'rateCount': ['123679'],
 'tppMovieID': [1205909],
 'writers': '李正美/东野圭吾'}
2020-04-30 00:39:41,755 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:43,180 -  movie_spider.py[line:143] - WARNING: get 27 movie info, named .
2020-04-30 00:39:43,183 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:43,183 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:43,184 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:43,185 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['3.00'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [319904],
 'movieName': ['盛世秧歌'],
 'releaseInfo': ['展映'],
 'seatRate': ['--'],
 'showInfo': [3],
 'showRate': ['<0.1%'],
 'showView': ['100'],
 'splitBoxInfo': ['3.00'],
 'splitSumBoxInfo': ['1376.1'],
 'sumBoxInfo': ['1377.7'],
 'yearRate': ['2019-04-30#27']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:43,841 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 00:39:43,852 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85 has been crawled
2020-04-30 00:39:43,852 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:43,853 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-04-30 00:39:43,860 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:43,866 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0)
2020-04-30 00:39:43,868 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30327877/?suggest=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA)
2020-04-30 00:39:45,361 -  movie_spider.py[line:167] - INFO: movie_name = 毕业那年 and movie_year = 2019-04-30 and tpp_id = 836
2020-04-30 00:39:45,363 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:39:45,363 -  movie_spider.py[line:173] - INFO: len of text is 2
2020-04-30 00:39:45,363 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:39:46,602 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:39:46,604 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:46,618 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:46,618 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:46,618 -  movie_spider.py[line:223] - CRITICAL: items = ['俞飞鸿', '大泽隆夫', '木下彩音', '卢洋洋', '前田公辉', '星由里子']
2020-04-30 00:39:46,620 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4336'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-04-30 00:39:46,620 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:46,633 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:46,633 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:46,633 -  movie_spider.py[line:223] - CRITICAL: items = ['俞飞鸿', '大泽隆夫', '木下彩音', '卢洋洋', '前田公辉', '星由里子']
2020-04-30 00:39:46,635 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4336'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-04-30 00:39:48,268 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:48,274 -  movie_spider.py[line:143] - WARNING: get 28 movie info, named .
2020-04-30 00:39:48,277 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:48,277 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:48,278 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:48,279 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['2.82'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [248906],
 'movieName': ['流浪地球'],
 'releaseInfo': [''],
 'seatRate': ['10.0%'],
 'showInfo': [140],
 'showRate': ['<0.1%'],
 'showView': ['7'],
 'splitBoxInfo': ['2.65'],
 'splitSumBoxInfo': ['435400.0'],
 'sumBoxInfo': ['468000.0'],
 'yearRate': ['2019-04-30#28']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:48,302 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled
2020-04-30 00:39:48,302 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-04-30 00:39:48,309 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85 has been crawled
2020-04-30 00:39:48,309 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:39:48,311 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:39:48,312 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled
2020-04-30 00:39:48,312 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:39:48,320 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97)
2020-04-30 00:39:48,328 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85)
2020-04-30 00:39:48,334 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:48,334 -  movie_spider.py[line:167] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-04-30 and tpp_id = 342568
2020-04-30 00:39:48,334 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 00:39:48,335 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:39:48,335 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 00:39:49,961 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:39:49,975 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:39:49,975 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:39:49,976 -  movie_spider.py[line:223] - CRITICAL: items = ['俞飞鸿', '大泽隆夫', '木下彩音', '卢洋洋', '前田公辉', '星由里子']
2020-04-30 00:39:49,977 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4336'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-04-30 00:39:50,026 -  logstats.py[line:48] - INFO: Crawled 63 pages (at 32 pages/min), scraped 20 items (at 1 items/min)
2020-04-30 00:39:56,220 -  movie_spider.py[line:143] - WARNING: get 29 movie info, named .
2020-04-30 00:39:56,225 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:39:56,225 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:39:56,226 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:39:56,227 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['2.78'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1249315],
 'movieName': ['大路朝天'],
 'releaseInfo': [''],
 'seatRate': ['82.6%'],
 'showInfo': [18],
 'showRate': ['<0.1%'],
 'showView': ['78'],
 'splitBoxInfo': ['2.78'],
 'splitSumBoxInfo': ['2594.3'],
 'sumBoxInfo': ['2595.5'],
 'yearRate': ['2019-04-30#29']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:39:56,230 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 00:39:56,248 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85)
2020-04-30 00:39:56,249 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83)
2020-04-30 00:39:56,251 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:39:58,233 -  movie_spider.py[line:167] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-04-30 and tpp_id = 1216383
2020-04-30 00:39:58,236 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:39:58,236 -  movie_spider.py[line:173] - INFO: len of text is 2
2020-04-30 00:39:58,237 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:40:00,019 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:40:00,020 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 00:40:00,035 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:00,035 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:00,035 -  movie_spider.py[line:223] - CRITICAL: items = ['俞飞鸿', '大泽隆夫', '木下彩音', '卢洋洋', '前田公辉', '星由里子']
2020-04-30 00:40:00,037 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4336'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-04-30 00:40:00,037 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30327877/?suggest=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA
2020-04-30 00:40:00,048 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:00,048 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:00,048 -  movie_spider.py[line:223] - CRITICAL: items = ['周浩东', '牛宝军', '李宜儒', '于心妍']
2020-04-30 00:40:00,050 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:00,050 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:00,050 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:00,050 -  scraper.py[line:236] - ERROR: Error processing {'actors': '周浩东/牛宝军/李宜儒/于心妍',
 'area': ' 中国大陆',
 'dbMovieID': ['30327877'],
 'directors': '王启蘅',
 'doubanRate': ['4.4'],
 'duration': [0],
 'genre': '犯罪',
 'movieName': ['特别追踪'],
 'publishedDate': ['2018-09-19'],
 'rateCount': ['991'],
 'tppMovieID': [1238775],
 'writers': '田水泉'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:00,843 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9 has been crawled
2020-04-30 00:40:00,843 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:00,853 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:40:00,861 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:40:00,870 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85)
2020-04-30 00:40:00,872 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4)
2020-04-30 00:40:00,873 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4)
2020-04-30 00:40:00,874 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 00:40:00,884 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:00,884 -  movie_spider.py[line:201] - ERROR: json decode error Invalid control character at: line 50 column 60 (char 920) in url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 00:40:00,885 -  scraper.py[line:159] - ERROR: Spider error processing <GET https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97)
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/middlewares.py", line 45, in process_spider_output
    for i in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 203, in parse_movie_info
    text = json.loads(data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 50 column 60 (char 920)
2020-04-30 00:40:00,885 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:40:00,894 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:00,894 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:00,894 -  movie_spider.py[line:223] - CRITICAL: items = ['戴韩安妮', '刘冠男', '马卉', '陈亮', '张流畅', '陈强生']
2020-04-30 00:40:00,896 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:00,896 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:00,896 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:00,896 -  scraper.py[line:236] - ERROR: Error processing {'actors': '戴韩安妮/刘冠男/马卉/陈亮/张流畅/陈强生',
 'area': ' 中国大陆',
 'dbMovieID': ['30378898'],
 'directors': '汪小白',
 'doubanRate': [''],
 'duration': [89],
 'genre': '爱情',
 'movieName': ['我们的爱情'],
 'publishedDate': ['2019-03-08'],
 'rateCount': ['0'],
 'tppMovieID': [1238926],
 'writers': '王子豪'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:00,897 -  movie_spider.py[line:167] - INFO: movie_name = 盛世秧歌 and movie_year = 2019-04-30 and tpp_id = 319904
2020-04-30 00:40:00,897 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 00:40:00,897 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:40:00,897 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 00:40:06,945 -  movie_spider.py[line:143] - WARNING: get 30 movie info, named .
2020-04-30 00:40:06,948 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:06,948 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.BoxOfficeItem'>
2020-04-30 00:40:06,948 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:06,948 -  scraper.py[line:236] - ERROR: Error processing {'boxInfo': ['2.22'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1167831],
 'movieName': ['波西米亚狂想曲'],
 'releaseInfo': ['上映40天'],
 'seatRate': ['8.8%'],
 'showInfo': [82],
 'showRate': ['<0.1%'],
 'showView': ['8'],
 'splitBoxInfo': ['2.04'],
 'splitSumBoxInfo': ['8931.1'],
 'sumBoxInfo': ['9855.1'],
 'yearRate': ['2019-04-30#30']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:07,126 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled
2020-04-30 00:40:07,127 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 00:40:07,147 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 00:40:07,155 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83)
2020-04-30 00:40:07,156 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:40:07,157 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B)
2020-04-30 00:40:09,087 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:40:09,097 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:09,097 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:09,097 -  movie_spider.py[line:223] - CRITICAL: items = ['戴韩安妮', '刘冠男', '马卉', '陈亮', '张流畅', '陈强生']
2020-04-30 00:40:09,099 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30378898
{'actors': '戴韩安妮/刘冠男/马卉/陈亮/张流畅/陈强生',
 'area': ' 中国大陆',
 'dbMovieID': ['30378898'],
 'directors': '汪小白',
 'doubanRate': [''],
 'duration': [89],
 'genre': '爱情',
 'movieName': ['我们的爱情'],
 'publishedDate': ['2019-03-08'],
 'rateCount': ['0'],
 'tppMovieID': [1238926],
 'writers': '王子豪'}
2020-04-30 00:40:09,099 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-04-30 00:40:09,112 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:09,112 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:09,112 -  movie_spider.py[line:223] - CRITICAL: items = ['黄磊', '闫妮', '韩童生', '崔新琴', '沙俊伯', '丁嘉丽', '冯嘉怡', '沙溢', '果靖霖', '胡可']
2020-04-30 00:40:09,114 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30479973
{'actors': '黄磊/闫妮/韩童生/崔新琴/沙俊伯/丁嘉丽/冯嘉怡/沙溢/果靖霖/胡可',
 'area': ' 中国大陆',
 'dbMovieID': ['30479973'],
 'directors': '吴楠',
 'doubanRate': ['5.9'],
 'duration': [91],
 'genre': '剧情/家庭',
 'movieName': ['狗眼看人心'],
 'publishedDate': ['2019-04-20'],
 'rateCount': ['6295'],
 'tppMovieID': [1263355],
 'writers': '吴楠'}
2020-04-30 00:40:09,114 -  movie_spider.py[line:167] - INFO: movie_name = 流浪地球 and movie_year = 2019-04-30 and tpp_id = 248906
2020-04-30 00:40:09,114 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-04-30 00:40:09,114 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:40:09,114 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-04-30 00:40:10,221 -  movie_spider.py[line:156] - ERROR: boxOffice start parse
2020-04-30 00:40:10,222 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-04-30 00:40:10,230 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B)
2020-04-30 00:40:10,231 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 00:40:10,232 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C)
2020-04-30 00:40:10,236 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:40:10,246 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:10,246 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:10,246 -  movie_spider.py[line:223] - CRITICAL: items = ['戴韩安妮', '刘冠男', '马卉', '陈亮', '张流畅', '陈强生']
2020-04-30 00:40:10,248 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30378898
{'actors': '戴韩安妮/刘冠男/马卉/陈亮/张流畅/陈强生',
 'area': ' 中国大陆',
 'dbMovieID': ['30378898'],
 'directors': '汪小白',
 'doubanRate': [''],
 'duration': [89],
 'genre': '爱情',
 'movieName': ['我们的爱情'],
 'publishedDate': ['2019-03-08'],
 'rateCount': ['0'],
 'tppMovieID': [1238926],
 'writers': '王子豪'}
2020-04-30 00:40:10,248 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:40:10,259 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:10,260 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:10,260 -  movie_spider.py[line:223] - CRITICAL: items = ['顾莉雅', '朱文超', '叶青青', '王仲欣', '丁汀', '飞龙', '龙泽']
2020-04-30 00:40:10,262 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:10,262 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:10,262 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:10,262 -  scraper.py[line:236] - ERROR: Error processing {'actors': '顾莉雅/朱文超/叶青青/王仲欣/丁汀/飞龙/龙泽',
 'area': ' 中国大陆',
 'dbMovieID': ['10759842'],
 'directors': '姚宇',
 'doubanRate': ['3.8'],
 'duration': [88],
 'genre': '剧情/音乐',
 'movieName': ['毕业那年'],
 'publishedDate': ['2012-09-21'],
 'rateCount': ['1972'],
 'tppMovieID': [836],
 'writers': '仧縯'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:10,263 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 00:40:10,273 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:10,274 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:10,274 -  movie_spider.py[line:223] - CRITICAL: items = ['顾莉雅', '朱文超', '叶青青', '王仲欣', '丁汀', '飞龙', '龙泽']
2020-04-30 00:40:10,276 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :10759842
{'actors': '顾莉雅/朱文超/叶青青/王仲欣/丁汀/飞龙/龙泽',
 'area': ' 中国大陆',
 'dbMovieID': ['10759842'],
 'directors': '姚宇',
 'doubanRate': ['3.8'],
 'duration': [88],
 'genre': '剧情/音乐',
 'movieName': ['毕业那年'],
 'publishedDate': ['2012-09-21'],
 'rateCount': ['1972'],
 'tppMovieID': [836],
 'writers': '仧縯'}
2020-04-30 00:40:12,732 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85)
2020-04-30 00:40:12,733 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85)
2020-04-30 00:40:12,735 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83)
2020-04-30 00:40:12,735 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 00:40:12,745 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:12,745 -  movie_spider.py[line:201] - ERROR: json decode error Invalid control character at: line 61 column 57 (char 1181) in url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 00:40:12,745 -  scraper.py[line:159] - ERROR: Spider error processing <GET https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83> (referer: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83)
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/middlewares.py", line 45, in process_spider_output
    for i in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 203, in parse_movie_info
    text = json.loads(data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 61 column 57 (char 1181)
2020-04-30 00:40:12,746 -  movie_spider.py[line:167] - INFO: movie_name = 大路朝天 and movie_year = 2019-04-30 and tpp_id = 1249315
2020-04-30 00:40:12,746 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:12,746 -  movie_spider.py[line:173] - INFO: len of text is 5
2020-04-30 00:40:12,746 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26662337/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:14,675 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/30402752/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:14,676 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:40:14,715 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:14,716 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:14,716 -  movie_spider.py[line:223] - CRITICAL: items = ['权相宇', '李凡秀', '李宝英', '郑爱延', '李瀚伟', '申贤俊', '池大汉', '杨知元', '金正碧', '金景龙']
2020-04-30 00:40:14,718 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:14,719 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:14,719 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:14,719 -  scraper.py[line:236] - ERROR: Error processing {'actors': '权相宇/李凡秀/李宝英/郑爱延/李瀚伟/申贤俊/池大汉/杨知元/金正碧/金景龙',
 'area': ' 韩国',
 'dbMovieID': ['3805946'],
 'directors': '元泰渊',
 'doubanRate': ['7.7'],
 'duration': [105],
 'genre': '爱情',
 'movieName': ['比悲伤更悲伤的故事 슬픔보다 더 슬픈 이야기'],
 'publishedDate': ['2009-03-12'],
 'rateCount': ['82996'],
 'tppMovieID': [1216383],
 'writers': '元泰渊'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:18,428 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/30402752/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:18,442 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26662337/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:19,507 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26575878/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:20,561 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 00:40:20,583 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:20,584 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:20,584 -  movie_spider.py[line:223] - CRITICAL: items = ['陈意涵', '刘以豪', '张书豪', '陈庭妮', '吴映洁', '禾浩辰', '游大庆', '石知田', '黄丽玲', '姚爱宁']
2020-04-30 00:40:20,586 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:20,586 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:20,586 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:20,586 -  scraper.py[line:236] - ERROR: Error processing {'actors': '陈意涵/刘以豪/张书豪/陈庭妮/吴映洁/禾浩辰/游大庆/石知田/黄丽玲/姚爱宁',
 'area': ' 中国台湾',
 'dbMovieID': ['27624661'],
 'directors': '林孝谦',
 'doubanRate': ['4.8'],
 'duration': [105],
 'genre': '爱情',
 'movieName': ['比悲伤更悲伤的故事 比悲傷更悲傷的故事'],
 'publishedDate': ['2018-11-30'],
 'rateCount': ['142458'],
 'tppMovieID': [1216383],
 'writers': '吕安弦'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:20,587 -  movie_spider.py[line:167] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-04-30 and tpp_id = 1167831
2020-04-30 00:40:20,587 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 00:40:20,587 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 00:40:20,587 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 00:40:22,107 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 00:40:22,132 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:22,132 -  movie_spider.py[line:201] - ERROR: json decode error Invalid control character at: line 44 column 54 (char 810) in url = https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 00:40:22,133 -  scraper.py[line:159] - ERROR: Spider error processing <GET https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C> (referer: https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C)
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/middlewares.py", line 45, in process_spider_output
    for i in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 203, in parse_movie_info
    text = json.loads(data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 44 column 54 (char 810)
2020-04-30 00:40:22,134 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 00:40:22,141 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26575878/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:22,148 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:40:22,157 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:22,157 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:22,157 -  movie_spider.py[line:223] - CRITICAL: items = ['戴韩安妮', '刘冠男', '马卉', '陈亮', '张流畅', '陈强生']
2020-04-30 00:40:22,159 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30378898
{'actors': '戴韩安妮/刘冠男/马卉/陈亮/张流畅/陈强生',
 'area': ' 中国大陆',
 'dbMovieID': ['30378898'],
 'directors': '汪小白',
 'doubanRate': [''],
 'duration': [89],
 'genre': '爱情',
 'movieName': ['我们的爱情'],
 'publishedDate': ['2019-03-08'],
 'rateCount': ['0'],
 'tppMovieID': [1238926],
 'writers': '王子豪'}
2020-04-30 00:40:22,159 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30378898/?suggest=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 00:40:22,168 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:22,169 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:22,169 -  movie_spider.py[line:223] - CRITICAL: items = ['戴韩安妮', '刘冠男', '马卉', '陈亮', '张流畅', '陈强生']
2020-04-30 00:40:22,170 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30378898
{'actors': '戴韩安妮/刘冠男/马卉/陈亮/张流畅/陈强生',
 'area': ' 中国大陆',
 'dbMovieID': ['30378898'],
 'directors': '汪小白',
 'doubanRate': [''],
 'duration': [89],
 'genre': '爱情',
 'movieName': ['我们的爱情'],
 'publishedDate': ['2019-03-08'],
 'rateCount': ['0'],
 'tppMovieID': [1238926],
 'writers': '王子豪'}
2020-04-30 00:40:22,171 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-04-30 00:40:22,182 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:22,183 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:22,183 -  movie_spider.py[line:223] - CRITICAL: items = ['屈楚萧', '吴京', '李光洁', '吴孟达', '赵今麦', '隋凯', '屈菁菁', '张亦驰', '杨皓宇', '阿尔卡基·沙罗格拉茨基']
2020-04-30 00:40:22,185 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:22,185 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:22,185 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:22,185 -  scraper.py[line:236] - ERROR: Error processing {'actors': '屈楚萧/吴京/李光洁/吴孟达/赵今麦/隋凯/屈菁菁/张亦驰/杨皓宇/阿尔卡基·沙罗格拉茨基',
 'area': ' 中国大陆',
 'dbMovieID': ['26266893'],
 'directors': '郭帆',
 'doubanRate': ['7.9'],
 'duration': [125],
 'genre': '科幻/冒险/灾难',
 'movieName': ['流浪地球'],
 'publishedDate': ['2019-02-05'],
 'rateCount': ['1517211'],
 'tppMovieID': [248906],
 'writers': '龚格尔/严东旭/郭帆/叶俊策/杨治学/吴荑/叶濡畅/沈晶晶/刘慈欣'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:31,165 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26662337/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9)
2020-04-30 00:40:31,269 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26662337/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:31,285 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:31,286 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:31,287 -  movie_spider.py[line:223] - CRITICAL: items = ['']
2020-04-30 00:40:31,294 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:31,294 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:31,296 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:31,297 -  scraper.py[line:236] - ERROR: Error processing {'actors': '',
 'area': ' 中国大陆',
 'dbMovieID': ['26662337'],
 'directors': '张赞波',
 'doubanRate': [''],
 'duration': [95],
 'genre': '纪录片',
 'movieName': ['大路朝天'],
 'publishedDate': ['2015-11-19'],
 'rateCount': ['0'],
 'tppMovieID': [1249315],
 'writers': ''}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:32,557 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30402752/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9)
2020-04-30 00:40:32,559 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26575878/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9)
2020-04-30 00:40:32,560 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2)
2020-04-30 00:40:32,661 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/30402752/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:32,693 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:32,693 -  movie_spider.py[line:205] - ERROR: len of movie info = 13
2020-04-30 00:40:32,693 -  movie_spider.py[line:223] - CRITICAL: items = ['李保田', '陈瑾', '巴登西绕', '张政勇', '孙敏', '白威', '郭晓峰', '孙艺杨']
2020-04-30 00:40:32,695 -  pipelines.py[line:50] - INFO: item is new
2020-04-30 00:40:32,695 -  pipelines.py[line:74] - CRITICAL: type of item is <class 'movie.items.MovieInfoItem'>
2020-04-30 00:40:32,695 -  pipelines.py[line:83] - WARNING: insert database finished
2020-04-30 00:40:32,696 -  scraper.py[line:236] - ERROR: Error processing {'actors': '李保田/陈瑾/巴登西绕/张政勇/孙敏/白威/郭晓峰/孙艺杨',
 'area': ' 中国大陆',
 'dbMovieID': ['30402752'],
 'directors': '苗月',
 'doubanRate': ['6.0'],
 'duration': [120],
 'genre': '剧情',
 'movieName': ['大路朝天'],
 'publishedDate': ['2018-12-22'],
 'rateCount': ['749'],
 'tppMovieID': [1249315],
 'writers': '苗月'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 84, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 501, in commit
    self._assert_active(prepared_ok=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 295, in _assert_active
    code="7s2a",
sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26879542', 'tppMovieID': 1189325, 'movieName': '捉妖学院', 'directors': '田梓橙', 'writers': '方岚/田梓橙', 'actors': '王泽宗/慈婉彤/周海媚/胡昌霖', 'genre': '奇幻/冒险', 'area': ' 中国大陆', 'duration': 96, 'publishedDate': '2019-04-30', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h) (Background on this error at: http://sqlalche.me/e/7s2a)
2020-04-30 00:40:33,965 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26575878/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:33,983 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:33,984 -  movie_spider.py[line:201] - ERROR: json decode error Invalid control character at: line 22 column 38 (char 363) in url = https://movie.douban.com/subject/26575878/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 00:40:33,984 -  scraper.py[line:159] - ERROR: Spider error processing <GET https://movie.douban.com/subject/26575878/?suggest=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9)
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/middlewares.py", line 45, in process_spider_output
    for i in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 203, in parse_movie_info
    text = json.loads(data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 22 column 38 (char 363)
2020-04-30 00:40:33,984 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 00:40:33,997 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 00:40:33,998 -  movie_spider.py[line:201] - ERROR: json decode error Invalid control character at: line 271 column 71 (char 5320) in url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 00:40:33,998 -  scraper.py[line:159] - ERROR: Spider error processing <GET https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2)
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/middlewares.py", line 45, in process_spider_output
    for i in result:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 203, in parse_movie_info
    text = json.loads(data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 271 column 71 (char 5320)
2020-04-30 00:40:34,001 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-04-30 00:40:34,002 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 104269,
 'downloader/request_count': 82,
 'downloader/request_method_count/GET': 82,
 'downloader/response_bytes': 1186225,
 'downloader/response_count': 82,
 'downloader/response_status_count/200': 82,
 'elapsed_time_seconds': 168.367028,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 29, 16, 40, 34, 2168),
 'item_dropped_count': 28,
 'item_dropped_reasons_count/DropItem': 28,
 'item_scraped_count': 20,
 'log_count/CRITICAL': 194,
 'log_count/ERROR': 213,
 'log_count/WARNING': 105,
 'memusage/max': 132972544,
 'memusage/startup': 73551872,
 'request_depth_max': 2,
 'response_received_count': 82,
 'scheduler/dequeued': 82,
 'scheduler/dequeued/memory': 82,
 'scheduler/enqueued': 82,
 'scheduler/enqueued/memory': 82,
 'spider_exceptions/JSONDecodeError': 6,
 'start_time': datetime.datetime(2020, 4, 29, 16, 37, 45, 635140)}
2020-04-30 00:40:34,002 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-04-30 01:04:31,566 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-04-30 01:04:31,584 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-04-30 01:04:31,595 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-04-30 01:04:31,612 -  telnet.py[line:60] - INFO: Telnet Password: 7a90f15ef22bdce4
2020-04-30 01:04:31,624 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-30 01:04:31,770 -  middlewares.py[line:135] - ERROR: start to use judge duplicate
2020-04-30 01:04:31,776 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-30 01:04:31,778 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-30 01:04:31,788 -  pipelines.py[line:18] - ERROR: start to use judge duplicate
2020-04-30 01:04:31,788 -  pipelines.py[line:64] - ERROR: setting: custom boxOffice setting
2020-04-30 01:04:31,853 -  pipelines.py[line:60] - ERROR: pipeline init
2020-04-30 01:04:31,853 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.BoxOfficePipeline', 'movie.pipelines.MySQLPipeline']
2020-04-30 01:04:31,853 -  engine.py[line:257] - INFO: Spider opened
2020-04-30 01:04:31,857 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-30 01:04:31,858 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6024
2020-04-30 01:04:31,863 -  movie_spider.py[line:96] - ERROR: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-04-30 01:04:31,866 -  middlewares.py[line:145] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430 has been crawled
2020-04-30 01:04:31,867 -  middlewares.py[line:147] - ERROR: url = http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430
2020-04-30 01:04:32,105 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430> (referer: None)
2020-04-30 01:04:32,875 -  movie_spider.py[line:115] - ERROR: now crawl url : http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430
2020-04-30 01:04:32,880 -  movie_spider.py[line:143] - WARNING: get 1 movie info, named .
2020-04-30 01:04:32,884 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#1
{'boxInfo': ['25633.43'],
 'boxRate': ['89.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [248172],
 'movieName': ['复仇者联盟4：终局之战'],
 'releaseInfo': ['上映7天'],
 'seatRate': ['20.3%'],
 'showInfo': [196869],
 'showRate': ['67.7%'],
 'showView': ['28'],
 'splitBoxInfo': ['24376.14'],
 'splitSumBoxInfo': ['248400.0'],
 'sumBoxInfo': ['261400.0'],
 'yearRate': ['2019-04-30#1']}
2020-04-30 01:04:33,033 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled
2020-04-30 01:04:33,034 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 01:04:33,062 -  movie_spider.py[line:143] - WARNING: get 2 movie info, named .
2020-04-30 01:04:33,064 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#2
{'boxInfo': ['1532.82'],
 'boxRate': ['5.3%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1218727],
 'movieName': ['何以为家'],
 'releaseInfo': ['重映2天'],
 'seatRate': ['17.1%'],
 'showInfo': [33430],
 'showRate': ['11.5%'],
 'showView': ['16'],
 'splitBoxInfo': ['1410.52'],
 'splitSumBoxInfo': ['2615.2'],
 'sumBoxInfo': ['2852.7'],
 'yearRate': ['2019-04-30#2']}
2020-04-30 01:04:33,082 -  movie_spider.py[line:143] - WARNING: get 3 movie info, named .
2020-04-30 01:04:33,083 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#3
{'boxInfo': ['518.13'],
 'boxRate': ['1.8%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [672279],
 'movieName': ['雪暴'],
 'releaseInfo': ['上映首日'],
 'seatRate': ['7.8%'],
 'showInfo': [25016],
 'showRate': ['8.6%'],
 'showView': ['7'],
 'splitBoxInfo': ['495.67'],
 'splitSumBoxInfo': ['519.1'],
 'sumBoxInfo': ['541.8'],
 'yearRate': ['2019-04-30#3']}
2020-04-30 01:04:33,729 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled
2020-04-30 01:04:33,729 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-04-30 01:04:33,758 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled
2020-04-30 01:04:33,758 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-04-30 01:04:33,772 -  movie_spider.py[line:143] - WARNING: get 4 movie info, named .
2020-04-30 01:04:33,773 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#4
{'boxInfo': ['307.56'],
 'boxRate': ['1.0%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1228776],
 'movieName': ['下一任：前任'],
 'releaseInfo': ['零点场'],
 'seatRate': ['42.4%'],
 'showInfo': [1756],
 'showRate': ['0.6%'],
 'showView': ['52'],
 'splitBoxInfo': ['279.29'],
 'splitSumBoxInfo': ['279.2'],
 'sumBoxInfo': ['307.5'],
 'yearRate': ['2019-04-30#4']}
2020-04-30 01:04:34,641 -  movie_spider.py[line:143] - WARNING: get 5 movie info, named .
2020-04-30 01:04:34,644 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#5
{'boxInfo': ['170.74'],
 'boxRate': ['0.5%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1243904],
 'movieName': ['动物出击'],
 'releaseInfo': ['上映首日'],
 'seatRate': ['10.3%'],
 'showInfo': [9806],
 'showRate': ['3.3%'],
 'showView': ['6'],
 'splitBoxInfo': ['168.29'],
 'splitSumBoxInfo': ['174.7'],
 'sumBoxInfo': ['177.2'],
 'yearRate': ['2019-04-30#5']}
2020-04-30 01:04:35,544 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled
2020-04-30 01:04:35,545 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-04-30 01:04:35,572 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled
2020-04-30 01:04:35,572 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-04-30 01:04:35,587 -  movie_spider.py[line:143] - WARNING: get 6 movie info, named .
2020-04-30 01:04:35,588 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#6
{'boxInfo': ['128.25'],
 'boxRate': ['0.4%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1211727],
 'movieName': ['反贪风暴4'],
 'releaseInfo': ['上映27天'],
 'seatRate': ['7.7%'],
 'showInfo': [6052],
 'showRate': ['2.0%'],
 'showView': ['7'],
 'splitBoxInfo': ['119.37'],
 'splitSumBoxInfo': ['72300.0'],
 'sumBoxInfo': ['78300.0'],
 'yearRate': ['2019-04-30#6']}
2020-04-30 01:04:36,517 -  movie_spider.py[line:143] - WARNING: get 7 movie info, named .
2020-04-30 01:04:36,520 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#7
{'boxInfo': ['96.69'],
 'boxRate': ['0.3%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1230152],
 'movieName': ['撞死了一只羊'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['8.0%'],
 'showInfo': [3094],
 'showRate': ['1.0%'],
 'showView': ['9'],
 'splitBoxInfo': ['94.05'],
 'splitSumBoxInfo': ['674.5'],
 'sumBoxInfo': ['701.1'],
 'yearRate': ['2019-04-30#7']}
2020-04-30 01:04:36,678 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled
2020-04-30 01:04:36,678 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-04-30 01:04:36,705 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled
2020-04-30 01:04:36,706 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-04-30 01:04:36,722 -  movie_spider.py[line:143] - WARNING: get 8 movie info, named .
2020-04-30 01:04:36,723 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#8
{'boxInfo': ['81.45'],
 'boxRate': ['0.2%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1239544],
 'movieName': ['调音师'],
 'releaseInfo': ['上映28天'],
 'seatRate': ['11.6%'],
 'showInfo': [2678],
 'showRate': ['0.9%'],
 'showView': ['10'],
 'splitBoxInfo': ['74.25'],
 'splitSumBoxInfo': ['28400.0'],
 'sumBoxInfo': ['31500.0'],
 'yearRate': ['2019-04-30#8']}
2020-04-30 01:04:37,280 -  movie_spider.py[line:143] - WARNING: get 9 movie info, named .
2020-04-30 01:04:37,283 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#9
{'boxInfo': ['38.32'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1211412],
 'movieName': ['神奇乐园历险记'],
 'releaseInfo': ['上映12天'],
 'seatRate': ['6.5%'],
 'showInfo': [2274],
 'showRate': ['0.7%'],
 'showView': ['6'],
 'splitBoxInfo': ['36.31'],
 'splitSumBoxInfo': ['2668.2'],
 'sumBoxInfo': ['2863.7'],
 'yearRate': ['2019-04-30#9']}
2020-04-30 01:04:37,322 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled
2020-04-30 01:04:37,322 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 01:04:37,349 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled
2020-04-30 01:04:37,349 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 01:04:37,360 -  movie_spider.py[line:143] - WARNING: get 10 movie info, named .
2020-04-30 01:04:37,362 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#10
{'boxInfo': ['24.05'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [330115],
 'movieName': ['我和神马查干'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [154],
 'showRate': ['<0.1%'],
 'showView': ['51'],
 'splitBoxInfo': ['23.94'],
 'splitSumBoxInfo': ['1982.0'],
 'sumBoxInfo': ['1988.9'],
 'yearRate': ['2019-04-30#10']}
2020-04-30 01:04:38,360 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:38,363 -  movie_spider.py[line:143] - WARNING: get 11 movie info, named .
2020-04-30 01:04:38,365 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#11
{'boxInfo': ['23.76'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1189325],
 'movieName': ['捉妖学院'],
 'releaseInfo': ['上映首日'],
 'seatRate': ['4.0%'],
 'showInfo': [285],
 'showRate': ['<0.1%'],
 'showView': ['9'],
 'splitBoxInfo': ['23.73'],
 'splitSumBoxInfo': ['23.7'],
 'sumBoxInfo': ['23.7'],
 'yearRate': ['2019-04-30#11']}
2020-04-30 01:04:38,677 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled
2020-04-30 01:04:38,677 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-04-30 01:04:38,682 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled
2020-04-30 01:04:38,682 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-04-30 01:04:38,710 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:38,721 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:38,725 -  movie_spider.py[line:143] - WARNING: get 12 movie info, named .
2020-04-30 01:04:38,726 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#12
{'boxInfo': ['20.58'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [476263],
 'movieName': ['天上再见'],
 'releaseInfo': ['上映首日'],
 'seatRate': ['8.4%'],
 'showInfo': [2292],
 'showRate': ['0.7%'],
 'showView': ['3'],
 'splitBoxInfo': ['19.00'],
 'splitSumBoxInfo': ['34.8'],
 'sumBoxInfo': ['36.5'],
 'yearRate': ['2019-04-30#12']}
2020-04-30 01:04:38,852 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled
2020-04-30 01:04:38,852 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-04-30 01:04:38,880 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:38,882 -  movie_spider.py[line:143] - WARNING: get 13 movie info, named .
2020-04-30 01:04:38,883 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#13
{'boxInfo': ['19.35'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1228750],
 'movieName': ['照相师'],
 'releaseInfo': [''],
 'seatRate': ['70.4%'],
 'showInfo': [58],
 'showRate': ['<0.1%'],
 'showView': ['83'],
 'splitBoxInfo': ['19.35'],
 'splitSumBoxInfo': ['2046.6'],
 'sumBoxInfo': ['2059.1'],
 'yearRate': ['2019-04-30#13']}
2020-04-30 01:04:39,579 -  movie_spider.py[line:167] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-04-30 and tpp_id = 248172
2020-04-30 01:04:39,579 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 01:04:39,579 -  movie_spider.py[line:173] - INFO: len of text is 1
2020-04-30 01:04:39,580 -  movie_spider.py[line:187] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 01:04:40,700 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled
2020-04-30 01:04:40,701 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 01:04:40,708 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled
2020-04-30 01:04:40,708 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 01:04:40,737 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:40,748 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:40,750 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:40,751 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:40,753 -  movie_spider.py[line:143] - WARNING: get 14 movie info, named .
2020-04-30 01:04:40,753 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#14
{'boxInfo': ['16.08'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1212492],
 'movieName': ['老师·好'],
 'releaseInfo': ['重映40天'],
 'seatRate': ['9.0%'],
 'showInfo': [570],
 'showRate': ['0.1%'],
 'showView': ['9'],
 'splitBoxInfo': ['15.52'],
 'splitSumBoxInfo': ['32600.0'],
 'sumBoxInfo': ['35300.0'],
 'yearRate': ['2019-04-30#14']}
2020-04-30 01:04:41,469 -  movie_spider.py[line:167] - INFO: movie_name = 何以为家 and movie_year = 2019-04-30 and tpp_id = 1218727
2020-04-30 01:04:41,469 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-04-30 01:04:41,469 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:41,469 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:41,475 -  movie_spider.py[line:167] - INFO: movie_name = 雪暴 and movie_year = 2019-04-30 and tpp_id = 672279
2020-04-30 01:04:41,476 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-04-30 01:04:41,476 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:41,476 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:41,483 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled
2020-04-30 01:04:41,484 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 01:04:41,505 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:41,507 -  movie_spider.py[line:143] - WARNING: get 15 movie info, named .
2020-04-30 01:04:41,508 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#15
{'boxInfo': ['14.79'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1236912],
 'movieName': ['远去的牧歌'],
 'releaseInfo': [''],
 'seatRate': ['32.3%'],
 'showInfo': [48],
 'showRate': ['<0.1%'],
 'showView': ['74'],
 'splitBoxInfo': ['14.79'],
 'splitSumBoxInfo': ['933.7'],
 'sumBoxInfo': ['938.3'],
 'yearRate': ['2019-04-30#15']}
2020-04-30 01:04:41,683 -  movie_spider.py[line:167] - INFO: movie_name = 调音师 and movie_year = 2019-04-30 and tpp_id = 1239544
2020-04-30 01:04:41,683 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-04-30 01:04:41,683 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:41,684 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:41,688 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C has been crawled
2020-04-30 01:04:41,688 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C
2020-04-30 01:04:41,713 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:41,715 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:41,716 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:41,717 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:41,718 -  movie_spider.py[line:143] - WARNING: get 16 movie info, named .
2020-04-30 01:04:41,720 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#16
{'boxInfo': ['13.97'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1229702],
 'movieName': ['青蛙王子历险记'],
 'releaseInfo': ['上映26天'],
 'seatRate': ['15.1%'],
 'showInfo': [84],
 'showRate': ['<0.1%'],
 'showView': ['22'],
 'splitBoxInfo': ['13.97'],
 'splitSumBoxInfo': ['1009.4'],
 'sumBoxInfo': ['1065.7'],
 'yearRate': ['2019-04-30#16']}
2020-04-30 01:04:41,844 -  movie_spider.py[line:167] - INFO: movie_name = 下一任：前任 and movie_year = 2019-04-30 and tpp_id = 1228776
2020-04-30 01:04:41,844 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-04-30 01:04:41,845 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:41,845 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:41,848 -  movie_spider.py[line:167] - INFO: movie_name = 动物出击 and movie_year = 2019-04-30 and tpp_id = 1243904
2020-04-30 01:04:41,849 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-04-30 01:04:41,849 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:41,849 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:41,852 -  movie_spider.py[line:167] - INFO: movie_name = 捉妖学院 and movie_year = 2019-04-30 and tpp_id = 1189325
2020-04-30 01:04:41,853 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-04-30 01:04:41,853 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:41,853 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:41,856 -  movie_spider.py[line:167] - INFO: movie_name = 我和神马查干 and movie_year = 2019-04-30 and tpp_id = 330115
2020-04-30 01:04:41,857 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-04-30 01:04:41,857 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:41,857 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:41,861 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled
2020-04-30 01:04:41,862 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 01:04:41,883 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:41,884 -  movie_spider.py[line:143] - WARNING: get 17 movie info, named .
2020-04-30 01:04:41,885 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#17
{'boxInfo': ['13.52'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1217701],
 'movieName': ['九克拉战栗'],
 'releaseInfo': ['重映首日'],
 'seatRate': ['8.4%'],
 'showInfo': [1395],
 'showRate': ['0.4%'],
 'showView': ['4'],
 'splitBoxInfo': ['12.69'],
 'splitSumBoxInfo': ['12.9'],
 'sumBoxInfo': ['13.8'],
 'yearRate': ['2019-04-30#17']}
2020-04-30 01:04:42,770 -  movie_spider.py[line:167] - INFO: movie_name = 天上再见 and movie_year = 2019-04-30 and tpp_id = 476263
2020-04-30 01:04:42,770 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-04-30 01:04:42,770 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:42,770 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:42,775 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled
2020-04-30 01:04:42,775 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 01:04:42,798 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:42,800 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:42,803 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98)
2020-04-30 01:04:42,804 -  movie_spider.py[line:143] - WARNING: get 18 movie info, named .
2020-04-30 01:04:42,806 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#18
{'boxInfo': ['13.45'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [643506],
 'movieName': ['古镇画情'],
 'releaseInfo': ['展映'],
 'seatRate': ['--'],
 'showInfo': [67],
 'showRate': ['<0.1%'],
 'showView': ['50'],
 'splitBoxInfo': ['13.41'],
 'splitSumBoxInfo': ['1097.5'],
 'sumBoxInfo': ['1100.3'],
 'yearRate': ['2019-04-30#18']}
2020-04-30 01:04:43,166 -  movie_spider.py[line:167] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-04-30 and tpp_id = 1211727
2020-04-30 01:04:43,166 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-04-30 01:04:43,167 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:43,167 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:43,170 -  movie_spider.py[line:167] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-04-30 and tpp_id = 1230152
2020-04-30 01:04:43,170 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-04-30 01:04:43,171 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:43,171 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:43,174 -  movie_spider.py[line:167] - INFO: movie_name = 照相师 and movie_year = 2019-04-30 and tpp_id = 1228750
2020-04-30 01:04:43,174 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-04-30 01:04:43,175 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:43,175 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:43,178 -  movie_spider.py[line:167] - INFO: movie_name = 老师·好 and movie_year = 2019-04-30 and tpp_id = 1212492
2020-04-30 01:04:43,178 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-04-30 01:04:43,179 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:43,179 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:43,183 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled
2020-04-30 01:04:43,183 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-04-30 01:04:43,201 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:43,203 -  movie_spider.py[line:143] - WARNING: get 19 movie info, named .
2020-04-30 01:04:43,204 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#19
{'boxInfo': ['12.10'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1205909],
 'movieName': ['祈祷落幕时'],
 'releaseInfo': ['上映19天'],
 'seatRate': ['9.8%'],
 'showInfo': [442],
 'showRate': ['0.1%'],
 'showView': ['8'],
 'splitBoxInfo': ['11.08'],
 'splitSumBoxInfo': ['5996.1'],
 'sumBoxInfo': ['6631.6'],
 'yearRate': ['2019-04-30#19']}
2020-04-30 01:04:43,415 -  movie_spider.py[line:167] - INFO: movie_name = 远去的牧歌 and movie_year = 2019-04-30 and tpp_id = 1236912
2020-04-30 01:04:43,415 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%BF%9C%E5%8E%BB%E7%9A%84%E7%89%A7%E6%AD%8C
2020-04-30 01:04:43,416 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:43,416 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:43,420 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled
2020-04-30 01:04:43,421 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-04-30 01:04:43,445 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:43,446 -  movie_spider.py[line:143] - WARNING: get 20 movie info, named .
2020-04-30 01:04:43,447 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#20
{'boxInfo': ['9.57'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1213175],
 'movieName': ['在乎你'],
 'releaseInfo': ['上映19天'],
 'seatRate': ['11.1%'],
 'showInfo': [36],
 'showRate': ['<0.1%'],
 'showView': ['39'],
 'splitBoxInfo': ['9.57'],
 'splitSumBoxInfo': ['681.3'],
 'sumBoxInfo': ['713.1'],
 'yearRate': ['2019-04-30#20']}
2020-04-30 01:04:43,978 -  movie_spider.py[line:167] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-04-30 and tpp_id = 1211412
2020-04-30 01:04:43,978 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 01:04:43,978 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:43,978 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:43,984 -  movie_spider.py[line:167] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-04-30 and tpp_id = 1229702
2020-04-30 01:04:43,985 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-04-30 01:04:43,985 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:43,985 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:43,988 -  movie_spider.py[line:193] - CRITICAL: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-04-30 01:04:44,022 -  movie_spider.py[line:197] - CRITICAL: type of data is <class 'str'>
2020-04-30 01:04:44,022 -  movie_spider.py[line:206] - ERROR: len of movie info = 13
2020-04-30 01:04:44,023 -  movie_spider.py[line:224] - CRITICAL: items = ['小罗伯特·唐尼', '克里斯·埃文斯', '马克·鲁弗洛', '克里斯·海姆斯沃斯', '斯嘉丽·约翰逊', '杰瑞米·雷纳', '保罗·路德', '凯伦·吉兰', '唐·钱德尔', '布丽·拉尔森']
2020-04-30 01:04:44,025 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['831481'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-04-30 01:04:44,026 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled
2020-04-30 01:04:44,026 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 01:04:44,033 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:44,033 -  movie_spider.py[line:143] - WARNING: get 21 movie info, named .
2020-04-30 01:04:44,034 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#21
{'boxInfo': ['7.07'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1238926],
 'movieName': ['我们的爱情'],
 'releaseInfo': ['上映54天'],
 'seatRate': ['45.7%'],
 'showInfo': [32],
 'showRate': ['<0.1%'],
 'showView': ['74'],
 'splitBoxInfo': ['7.07'],
 'splitSumBoxInfo': ['76.9'],
 'sumBoxInfo': ['77.2'],
 'yearRate': ['2019-04-30#21']}
2020-04-30 01:04:44,295 -  movie_spider.py[line:167] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-04-30 and tpp_id = 1217701
2020-04-30 01:04:44,295 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-04-30 01:04:44,295 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:44,295 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:46,179 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85 has been crawled
2020-04-30 01:04:46,180 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 01:04:46,208 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:46,210 -  movie_spider.py[line:143] - WARNING: get 22 movie info, named .
2020-04-30 01:04:46,211 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#22
{'boxInfo': ['7.06'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1238775],
 'movieName': ['特别追踪'],
 'releaseInfo': [''],
 'seatRate': ['35.4%'],
 'showInfo': [29],
 'showRate': ['<0.1%'],
 'showView': ['49'],
 'splitBoxInfo': ['7.05'],
 'splitSumBoxInfo': ['459.1'],
 'sumBoxInfo': ['459.3'],
 'yearRate': ['2019-04-30#22']}
2020-04-30 01:04:46,758 -  movie_spider.py[line:167] - INFO: movie_name = 古镇画情 and movie_year = 2019-04-30 and tpp_id = 643506
2020-04-30 01:04:46,759 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-04-30 01:04:46,759 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:46,759 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:46,766 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA has been crawled
2020-04-30 01:04:46,766 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA
2020-04-30 01:04:46,791 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:46,793 -  movie_spider.py[line:143] - WARNING: get 23 movie info, named .
2020-04-30 01:04:46,794 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#23
{'boxInfo': ['6.68'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1263355],
 'movieName': ['狗眼看人心'],
 'releaseInfo': ['上映11天'],
 'seatRate': ['3.9%'],
 'showInfo': [878],
 'showRate': ['0.3%'],
 'showView': ['3'],
 'splitBoxInfo': ['6.28'],
 'splitSumBoxInfo': ['1682.7'],
 'sumBoxInfo': ['1812.6'],
 'yearRate': ['2019-04-30#23']}
2020-04-30 01:04:47,089 -  movie_spider.py[line:167] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-04-30 and tpp_id = 1205909
2020-04-30 01:04:47,090 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-04-30 01:04:47,090 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:47,090 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:47,094 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled
2020-04-30 01:04:47,095 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-04-30 01:04:47,121 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:47,122 -  movie_spider.py[line:143] - WARNING: get 24 movie info, named .
2020-04-30 01:04:47,124 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#24
{'boxInfo': ['4.71'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [836],
 'movieName': ['毕业那年'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [26],
 'showRate': ['<0.1%'],
 'showView': ['55'],
 'splitBoxInfo': ['4.71'],
 'splitSumBoxInfo': ['1002.1'],
 'sumBoxInfo': ['1003.6'],
 'yearRate': ['2019-04-30#24']}
2020-04-30 01:04:48,029 -  movie_spider.py[line:167] - INFO: movie_name = 在乎你 and movie_year = 2019-04-30 and tpp_id = 1213175
2020-04-30 01:04:48,030 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-04-30 01:04:48,030 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:48,030 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:48,034 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled
2020-04-30 01:04:48,034 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 01:04:48,063 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:48,064 -  movie_spider.py[line:143] - WARNING: get 25 movie info, named .
2020-04-30 01:04:48,066 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#25
{'boxInfo': ['3.89'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [342568],
 'movieName': ['诡梦凶铃'],
 'releaseInfo': [''],
 'seatRate': ['63.2%'],
 'showInfo': [7],
 'showRate': ['<0.1%'],
 'showView': ['213'],
 'splitBoxInfo': ['3.89'],
 'splitSumBoxInfo': ['1115.7'],
 'sumBoxInfo': ['1115.7'],
 'yearRate': ['2019-04-30#25']}
2020-04-30 01:04:48,277 -  movie_spider.py[line:167] - INFO: movie_name = 我们的爱情 and movie_year = 2019-04-30 and tpp_id = 1238926
2020-04-30 01:04:48,278 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E4%BB%AC%E7%9A%84%E7%88%B1%E6%83%85
2020-04-30 01:04:48,278 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:48,278 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:48,284 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled
2020-04-30 01:04:48,284 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 01:04:48,310 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:48,312 -  movie_spider.py[line:143] - WARNING: get 26 movie info, named .
2020-04-30 01:04:48,313 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#26
{'boxInfo': ['3.73'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1216383],
 'movieName': ['比悲伤更悲伤的故事'],
 'releaseInfo': ['上映48天'],
 'seatRate': ['6.6%'],
 'showInfo': [301],
 'showRate': ['0.1%'],
 'showView': ['5'],
 'splitBoxInfo': ['3.50'],
 'splitSumBoxInfo': ['85800.0'],
 'sumBoxInfo': ['95700.0'],
 'yearRate': ['2019-04-30#26']}
2020-04-30 01:04:48,718 -  movie_spider.py[line:167] - INFO: movie_name = 特别追踪 and movie_year = 2019-04-30 and tpp_id = 1238775
2020-04-30 01:04:48,719 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%89%B9%E5%88%AB%E8%BF%BD%E8%B8%AA
2020-04-30 01:04:48,720 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:48,720 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:48,724 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled
2020-04-30 01:04:48,724 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 01:04:48,750 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:48,752 -  movie_spider.py[line:143] - WARNING: get 27 movie info, named .
2020-04-30 01:04:48,754 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#27
{'boxInfo': ['3.00'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [319904],
 'movieName': ['盛世秧歌'],
 'releaseInfo': ['展映'],
 'seatRate': ['--'],
 'showInfo': [3],
 'showRate': ['<0.1%'],
 'showView': ['100'],
 'splitBoxInfo': ['3.00'],
 'splitSumBoxInfo': ['1376.1'],
 'sumBoxInfo': ['1377.7'],
 'yearRate': ['2019-04-30#27']}
2020-04-30 01:04:49,510 -  movie_spider.py[line:167] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-04-30 and tpp_id = 1263355
2020-04-30 01:04:49,510 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-04-30 01:04:49,510 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:49,511 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:49,515 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C has been crawled
2020-04-30 01:04:49,515 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 01:04:49,542 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:49,544 -  movie_spider.py[line:143] - WARNING: get 28 movie info, named .
2020-04-30 01:04:49,545 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#28
{'boxInfo': ['2.82'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [248906],
 'movieName': ['流浪地球'],
 'releaseInfo': [''],
 'seatRate': ['10.0%'],
 'showInfo': [140],
 'showRate': ['<0.1%'],
 'showView': ['7'],
 'splitBoxInfo': ['2.65'],
 'splitSumBoxInfo': ['435400.0'],
 'sumBoxInfo': ['468000.0'],
 'yearRate': ['2019-04-30#28']}
2020-04-30 01:04:49,938 -  movie_spider.py[line:167] - INFO: movie_name = 毕业那年 and movie_year = 2019-04-30 and tpp_id = 836
2020-04-30 01:04:49,938 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-04-30 01:04:49,939 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:49,939 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:49,943 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled
2020-04-30 01:04:49,943 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-04-30 01:04:49,970 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:49,972 -  movie_spider.py[line:143] - WARNING: get 29 movie info, named .
2020-04-30 01:04:49,973 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#29
{'boxInfo': ['2.78'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1249315],
 'movieName': ['大路朝天'],
 'releaseInfo': [''],
 'seatRate': ['82.6%'],
 'showInfo': [18],
 'showRate': ['<0.1%'],
 'showView': ['78'],
 'splitBoxInfo': ['2.78'],
 'splitSumBoxInfo': ['2594.3'],
 'sumBoxInfo': ['2595.5'],
 'yearRate': ['2019-04-30#29']}
2020-04-30 01:04:50,678 -  movie_spider.py[line:167] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-04-30 and tpp_id = 342568
2020-04-30 01:04:50,679 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-04-30 01:04:50,679 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:50,679 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:50,684 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9 has been crawled
2020-04-30 01:04:50,684 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 01:04:50,711 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:50,713 -  movie_spider.py[line:143] - WARNING: get 30 movie info, named .
2020-04-30 01:04:50,714 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-04-30#30
{'boxInfo': ['2.22'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-04-30'],
 'movieID': [1167831],
 'movieName': ['波西米亚狂想曲'],
 'releaseInfo': ['上映40天'],
 'seatRate': ['8.8%'],
 'showInfo': [82],
 'showRate': ['<0.1%'],
 'showView': ['8'],
 'splitBoxInfo': ['2.04'],
 'splitSumBoxInfo': ['8931.1'],
 'sumBoxInfo': ['9855.1'],
 'yearRate': ['2019-04-30#30']}
2020-04-30 01:04:50,740 -  movie_spider.py[line:167] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-04-30 and tpp_id = 1216383
2020-04-30 01:04:50,740 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-04-30 01:04:50,740 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:50,740 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:50,742 -  middlewares.py[line:145] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled
2020-04-30 01:04:50,742 -  middlewares.py[line:147] - ERROR: url = https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 01:04:50,751 -  movie_spider.py[line:156] - ERROR: boxOffice start parse
2020-04-30 01:04:50,752 -  movie_spider.py[line:167] - INFO: movie_name = 盛世秧歌 and movie_year = 2019-04-30 and tpp_id = 319904
2020-04-30 01:04:50,752 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-04-30 01:04:50,752 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:50,752 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:50,768 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:50,811 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430)
2020-04-30 01:04:50,814 -  movie_spider.py[line:167] - INFO: movie_name = 流浪地球 and movie_year = 2019-04-30 and tpp_id = 248906
2020-04-30 01:04:50,814 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-04-30 01:04:50,814 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:50,815 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:50,871 -  movie_spider.py[line:167] - INFO: movie_name = 大路朝天 and movie_year = 2019-04-30 and tpp_id = 1249315
2020-04-30 01:04:50,872 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A7%E8%B7%AF%E6%9C%9D%E5%A4%A9
2020-04-30 01:04:50,872 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:50,872 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:50,914 -  movie_spider.py[line:167] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-04-30 and tpp_id = 1167831
2020-04-30 01:04:50,914 -  movie_spider.py[line:172] - INFO: the url is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-04-30 01:04:50,914 -  movie_spider.py[line:173] - INFO: len of text is 0
2020-04-30 01:04:50,915 -  movie_spider.py[line:175] - ERROR: not response scraped
2020-04-30 01:04:50,918 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-04-30 01:04:50,920 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 39775,
 'downloader/request_count': 32,
 'downloader/request_method_count/GET': 32,
 'downloader/response_bytes': 41808,
 'downloader/response_count': 32,
 'downloader/response_status_count/200': 32,
 'elapsed_time_seconds': 19.062412,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 29, 17, 4, 50, 919433),
 'item_dropped_count': 31,
 'item_dropped_reasons_count/DropItem': 31,
 'log_count/CRITICAL': 3,
 'log_count/ERROR': 101,
 'log_count/WARNING': 61,
 'memusage/max': 73773056,
 'memusage/startup': 73773056,
 'request_depth_max': 2,
 'response_received_count': 32,
 'scheduler/dequeued': 32,
 'scheduler/dequeued/memory': 32,
 'scheduler/enqueued': 32,
 'scheduler/enqueued/memory': 32,
 'start_time': datetime.datetime(2020, 4, 29, 17, 4, 31, 857021)}
2020-04-30 01:04:50,920 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-04-30 01:07:59,920 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-04-30 01:07:59,924 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-04-30 01:07:59,926 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-04-30 01:07:59,934 -  telnet.py[line:60] - INFO: Telnet Password: 48380363d7c9f04c
2020-04-30 01:07:59,944 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-30 01:08:00,051 -  middlewares.py[line:135] - ERROR: start to use judge duplicate
2020-04-30 01:08:00,054 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-30 01:08:00,056 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-30 01:08:00,063 -  pipelines.py[line:18] - ERROR: start to use judge duplicate
2020-04-30 01:08:00,063 -  pipelines.py[line:64] - ERROR: setting: custom boxOffice setting
2020-04-30 01:08:00,077 -  pipelines.py[line:60] - ERROR: pipeline init
2020-04-30 01:08:00,077 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.BoxOfficePipeline', 'movie.pipelines.MySQLPipeline']
2020-04-30 01:08:00,077 -  engine.py[line:257] - INFO: Spider opened
2020-04-30 01:08:00,078 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-30 01:08:00,079 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6024
2020-04-30 01:08:00,081 -  movie_spider.py[line:96] - ERROR: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-04-30 01:08:00,084 -  middlewares.py[line:145] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190430 has been crawled
2020-04-30 01:08:00,285 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-04-30 01:08:00,287 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 1,
 'elapsed_time_seconds': 0.208222,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 29, 17, 8, 0, 286784),
 'log_count/ERROR': 6,
 'memusage/max': 73629696,
 'memusage/startup': 73629696,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 29, 17, 8, 0, 78562)}
2020-04-30 01:08:00,288 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-05-01 00:19:58,502 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-01 00:19:58,606 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-01 00:19:58,619 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-01 00:19:58,660 -  telnet.py[line:60] - INFO: Telnet Password: c9c30ed8df705d50
2020-05-01 00:19:58,709 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-01 00:20:03,769 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-01 00:20:03,819 -  utils.py[line:88] - DEBUG: Sleeping for 0.1 seconds
2020-05-01 00:20:08,949 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-01 00:20:08,950 -  utils.py[line:184] - WARNING: Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2020-05-01 00:20:15,266 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://fake-useragent.herokuapp.com/browsers/0.1.11
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1422, in connect
    server_hostname=server_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1059: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>
2020-05-01 00:20:15,287 -  utils.py[line:88] - DEBUG: Sleeping for 0.1 seconds
2020-05-01 00:20:21,696 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://fake-useragent.herokuapp.com/browsers/0.1.11
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1422, in connect
    server_hostname=server_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1059: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>
2020-05-01 00:20:21,739 -  _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2020-05-01 00:20:21,814 -  _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1422, in connect
    server_hostname=server_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1059: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 85, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 108, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 62, in __init__
    self.headers = get_random_headers()
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 50, in get_random_headers
    return {'User-Agent': str(UserAgent().random)}
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 69, in __init__
    self.load()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 78, in load
    verify_ssl=self.verify_ssl,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 250, in load_cached
    update(path, use_cache_server=use_cache_server, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 245, in update
    write(path, load(use_cache_server=use_cache_server, verify_ssl=verify_ssl))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 189, in load
    verify_ssl=verify_ssl,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2020-05-02 13:13:22,824 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-02 13:13:22,917 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-02 13:13:22,929 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-02 13:13:22,973 -  telnet.py[line:60] - INFO: Telnet Password: d8834f0277f2eb3d
2020-05-02 13:13:23,051 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-02 13:13:28,138 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-02 13:13:28,203 -  utils.py[line:88] - DEBUG: Sleeping for 0.1 seconds
2020-05-02 13:13:33,317 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-02 13:13:33,356 -  _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2020-05-02 13:13:33,397 -  _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 85, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 108, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 55, in __init__
    self.headers = get_random_headers()
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 43, in get_random_headers
    return {'User-Agent': str(UserAgent(use_cache_server=False).random)}
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 69, in __init__
    self.load()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 78, in load
    verify_ssl=self.verify_ssl,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 250, in load_cached
    update(path, use_cache_server=use_cache_server, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 245, in update
    write(path, load(use_cache_server=use_cache_server, verify_ssl=verify_ssl))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 178, in load
    raise exc
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2020-05-02 13:15:30,665 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-02 13:15:30,668 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-02 13:15:30,671 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-02 13:15:30,678 -  telnet.py[line:60] - INFO: Telnet Password: e326de73d3688853
2020-05-02 13:15:30,687 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-02 13:15:35,696 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-02 13:15:35,700 -  utils.py[line:88] - DEBUG: Sleeping for 0.1 seconds
2020-05-02 13:15:40,830 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-02 13:15:40,846 -  _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2020-05-02 13:15:40,847 -  _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 85, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 108, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 55, in __init__
    self.headers = get_random_headers()
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 43, in get_random_headers
    return {'User-Agent': str(UserAgent(use_cache_server=False).random)}
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 69, in __init__
    self.load()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 78, in load
    verify_ssl=self.verify_ssl,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 250, in load_cached
    update(path, use_cache_server=use_cache_server, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 245, in update
    write(path, load(use_cache_server=use_cache_server, verify_ssl=verify_ssl))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 178, in load
    raise exc
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2020-05-02 13:28:31,308 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-02 13:28:31,518 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-02 13:28:31,544 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-02 13:28:32,048 -  telnet.py[line:60] - INFO: Telnet Password: 9ef7a9ff26cf1328
2020-05-02 13:28:32,497 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-02 13:28:40,372 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:28:40,372 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:28:40,372 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:28:40,372 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:28:40,522 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-02 13:28:40,579 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-02 13:28:40,959 -  _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2020-05-02 13:28:41,111 -  _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/misc.py", line 49, in load_object
    obj = getattr(mod, name)
AttributeError: module 'movie.pipelines' has no attribute 'BoxOfficePipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/utils/misc.py", line 51, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'movie.pipelines' doesn't define any object named 'BoxOfficePipeline'
2020-05-02 13:31:57,211 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-02 13:31:57,323 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-02 13:31:57,341 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-02 13:31:57,525 -  telnet.py[line:60] - INFO: Telnet Password: 0a13972898be729f
2020-05-02 13:31:57,673 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-02 13:32:04,653 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:32:04,653 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:32:04,653 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:32:04,653 -  middlewares.py[line:136] - INFO: start to use judge duplicate url
2020-05-02 13:32:04,764 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.RefererMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-02 13:32:04,807 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-02 13:32:04,881 -  pipelines.py[line:20] - INFO: start to use judge duplicate item
2020-05-02 13:32:04,881 -  pipelines.py[line:20] - INFO: start to use judge duplicate item
2020-05-02 13:32:04,881 -  pipelines.py[line:20] - INFO: start to use judge duplicate item
2020-05-02 13:32:04,881 -  pipelines.py[line:20] - INFO: start to use judge duplicate item
2020-05-02 13:32:04,881 -  pipelines.py[line:20] - INFO: start to use judge duplicate item
2020-05-02 13:32:04,881 -  pipelines.py[line:20] - INFO: start to use judge duplicate item
2020-05-02 13:32:05,589 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.ItemPipeline', 'movie.pipelines.MySQLPipeline']
2020-05-02 13:32:05,589 -  engine.py[line:257] - INFO: Spider opened
2020-05-02 13:32:05,608 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-02 13:32:05,611 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6023
2020-05-02 13:32:05,765 -  movie_spider.py[line:89] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 13:32:05,765 -  movie_spider.py[line:89] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 13:32:05,765 -  movie_spider.py[line:89] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 13:32:05,765 -  movie_spider.py[line:89] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 13:32:05,765 -  movie_spider.py[line:89] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 13:32:05,765 -  movie_spider.py[line:89] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 13:32:06,103 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502> (referer: https://movie.douban.com/)
2020-05-02 13:32:07,251 -  movie_spider.py[line:108] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 13:32:07,251 -  movie_spider.py[line:108] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 13:32:07,251 -  movie_spider.py[line:108] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 13:32:07,251 -  movie_spider.py[line:108] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 13:32:07,251 -  movie_spider.py[line:108] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 13:32:07,251 -  movie_spider.py[line:108] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 13:32:07,326 -  movie_spider.py[line:136] - INFO: get 1 boxOffice, named .
2020-05-02 13:32:07,326 -  movie_spider.py[line:136] - INFO: get 1 boxOffice, named .
2020-05-02 13:32:07,326 -  movie_spider.py[line:136] - INFO: get 1 boxOffice, named .
2020-05-02 13:32:07,326 -  movie_spider.py[line:136] - INFO: get 1 boxOffice, named .
2020-05-02 13:32:07,326 -  movie_spider.py[line:136] - INFO: get 1 boxOffice, named .
2020-05-02 13:32:07,326 -  movie_spider.py[line:136] - INFO: get 1 boxOffice, named .
2020-05-02 13:32:07,330 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:07,330 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:07,330 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:07,330 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:07,330 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:07,330 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:07,332 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:07,332 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:07,332 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:07,332 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:07,332 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:07,332 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:07,340 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:07,340 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:07,340 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:07,340 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:07,340 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:07,340 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:09,704 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'sql_mode'
2020-05-02 13:32:09,705 -  log.py[line:110] - INFO: {}
2020-05-02 13:32:10,946 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'lower_case_table_names'
2020-05-02 13:32:10,947 -  log.py[line:110] - INFO: {}
2020-05-02 13:32:10,989 -  log.py[line:110] - INFO: SELECT DATABASE()
2020-05-02 13:32:10,989 -  log.py[line:110] - INFO: {}
2020-05-02 13:32:11,010 -  log.py[line:110] - INFO: show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'
2020-05-02 13:32:11,010 -  log.py[line:110] - INFO: {}
2020-05-02 13:32:11,422 -  log.py[line:110] - INFO: SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1
2020-05-02 13:32:11,423 -  log.py[line:110] - INFO: {}
2020-05-02 13:32:11,425 -  log.py[line:110] - INFO: SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1
2020-05-02 13:32:11,425 -  log.py[line:110] - INFO: {}
2020-05-02 13:32:11,427 -  log.py[line:110] - INFO: SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1
2020-05-02 13:32:11,427 -  log.py[line:110] - INFO: {}
2020-05-02 13:32:11,959 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:11,964 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:11,964 -  log.py[line:110] - INFO: {'movieID': 248172, 'movieName': '复仇者联盟4：终局之战', 'seatRate': '27.2%', 'boxInfo': '34056.84', 'boxRate': '81.4%', 'releaseInfo': '上映9天', 'showInfo': 193371, 'showRate': '60.9%', 'splitBoxInfo': '32298.48', 'splitSumBoxInfo': '328300.0', 'sumBoxInfo': '345700.0', 'showView': '38', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#1'}
2020-05-02 13:32:13,083 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:14,452 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:14,677 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:14,677 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:14,677 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:14,677 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:14,677 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:14,677 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:14,701 -  movie_spider.py[line:136] - INFO: get 2 boxOffice, named .
2020-05-02 13:32:14,701 -  movie_spider.py[line:136] - INFO: get 2 boxOffice, named .
2020-05-02 13:32:14,701 -  movie_spider.py[line:136] - INFO: get 2 boxOffice, named .
2020-05-02 13:32:14,701 -  movie_spider.py[line:136] - INFO: get 2 boxOffice, named .
2020-05-02 13:32:14,701 -  movie_spider.py[line:136] - INFO: get 2 boxOffice, named .
2020-05-02 13:32:14,701 -  movie_spider.py[line:136] - INFO: get 2 boxOffice, named .
2020-05-02 13:32:14,703 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:14,703 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:14,703 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:14,703 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:14,703 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:14,703 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:14,703 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:14,703 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:14,703 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:14,703 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:14,703 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:14,703 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:14,704 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:14,704 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:14,704 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:14,704 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:14,704 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:14,704 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:14,704 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:14,705 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:14,705 -  log.py[line:110] - INFO: {'movieID': 1218727, 'movieName': '何以为家', 'seatRate': '29.7%', 'boxInfo': '3180.66', 'boxRate': '7.6%', 'releaseInfo': '重映4天', 'showInfo': 36046, 'showRate': '11.3%', 'splitBoxInfo': '2892.66', 'splitSumBoxInfo': '7958.7', 'sumBoxInfo': '8707.5', 'showView': '28', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#2'}
2020-05-02 13:32:15,596 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:16,359 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:17,016 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:17,016 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:17,016 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:17,016 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:17,016 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:17,016 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:17,037 -  movie_spider.py[line:136] - INFO: get 3 boxOffice, named .
2020-05-02 13:32:17,037 -  movie_spider.py[line:136] - INFO: get 3 boxOffice, named .
2020-05-02 13:32:17,037 -  movie_spider.py[line:136] - INFO: get 3 boxOffice, named .
2020-05-02 13:32:17,037 -  movie_spider.py[line:136] - INFO: get 3 boxOffice, named .
2020-05-02 13:32:17,037 -  movie_spider.py[line:136] - INFO: get 3 boxOffice, named .
2020-05-02 13:32:17,037 -  movie_spider.py[line:136] - INFO: get 3 boxOffice, named .
2020-05-02 13:32:17,038 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:17,038 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:17,038 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:17,038 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:17,038 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:17,038 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:17,039 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:17,039 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:17,039 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:17,039 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:17,039 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:17,039 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:17,039 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:17,039 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:17,039 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:17,039 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:17,039 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:17,039 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:17,040 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:17,040 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:17,040 -  log.py[line:110] - INFO: {'movieID': 1228776, 'movieName': '下一任：前任', 'seatRate': '19.0%', 'boxInfo': '2425.92', 'boxRate': '5.8%', 'releaseInfo': '上映2天', 'showInfo': 41142, 'showRate': '12.9%', 'splitBoxInfo': '2236.43', 'splitSumBoxInfo': '6979.6', 'sumBoxInfo': '7606.2', 'showView': '18', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#3'}
2020-05-02 13:32:17,322 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:17,625 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:18,040 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:18,040 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:18,040 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:18,040 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:18,040 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:18,040 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:18,068 -  movie_spider.py[line:136] - INFO: get 4 boxOffice, named .
2020-05-02 13:32:18,068 -  movie_spider.py[line:136] - INFO: get 4 boxOffice, named .
2020-05-02 13:32:18,068 -  movie_spider.py[line:136] - INFO: get 4 boxOffice, named .
2020-05-02 13:32:18,068 -  movie_spider.py[line:136] - INFO: get 4 boxOffice, named .
2020-05-02 13:32:18,068 -  movie_spider.py[line:136] - INFO: get 4 boxOffice, named .
2020-05-02 13:32:18,068 -  movie_spider.py[line:136] - INFO: get 4 boxOffice, named .
2020-05-02 13:32:18,071 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,071 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,071 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,071 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,071 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,071 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,072 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,072 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,072 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,072 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,072 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,072 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,073 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:18,074 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:18,074 -  log.py[line:110] - INFO: {'movieID': 1211412, 'movieName': '神奇乐园历险记', 'seatRate': '20.8%', 'boxInfo': '463.93', 'boxRate': '1.1%', 'releaseInfo': '上映14天', 'showInfo': 6985, 'showRate': '2.2%', 'splitBoxInfo': '426.89', 'splitSumBoxInfo': '3367.4', 'sumBoxInfo': '3622.1', 'showView': '20', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#4'}
2020-05-02 13:32:18,075 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:18,500 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:18,904 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:18,904 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:18,904 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:18,904 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:18,904 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:18,904 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:18,933 -  movie_spider.py[line:136] - INFO: get 5 boxOffice, named .
2020-05-02 13:32:18,933 -  movie_spider.py[line:136] - INFO: get 5 boxOffice, named .
2020-05-02 13:32:18,933 -  movie_spider.py[line:136] - INFO: get 5 boxOffice, named .
2020-05-02 13:32:18,933 -  movie_spider.py[line:136] - INFO: get 5 boxOffice, named .
2020-05-02 13:32:18,933 -  movie_spider.py[line:136] - INFO: get 5 boxOffice, named .
2020-05-02 13:32:18,933 -  movie_spider.py[line:136] - INFO: get 5 boxOffice, named .
2020-05-02 13:32:18,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:18,935 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,935 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,935 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,935 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,935 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,935 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:18,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:18,936 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:18,937 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:18,937 -  log.py[line:110] - INFO: {'movieID': 672379, 'movieName': '悟空奇遇记', 'seatRate': '12.7%', 'boxInfo': '460.75', 'boxRate': '1.1%', 'releaseInfo': '上映2天', 'showInfo': 13623, 'showRate': '4.2%', 'splitBoxInfo': '428.07', 'splitSumBoxInfo': '1030.4', 'sumBoxInfo': '1108.8', 'showView': '12', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#5'}
2020-05-02 13:32:18,938 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:19,835 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:20,039 -  movie_spider.py[line:136] - INFO: get 6 boxOffice, named .
2020-05-02 13:32:20,039 -  movie_spider.py[line:136] - INFO: get 6 boxOffice, named .
2020-05-02 13:32:20,039 -  movie_spider.py[line:136] - INFO: get 6 boxOffice, named .
2020-05-02 13:32:20,039 -  movie_spider.py[line:136] - INFO: get 6 boxOffice, named .
2020-05-02 13:32:20,039 -  movie_spider.py[line:136] - INFO: get 6 boxOffice, named .
2020-05-02 13:32:20,039 -  movie_spider.py[line:136] - INFO: get 6 boxOffice, named .
2020-05-02 13:32:20,041 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:20,041 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:20,041 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:20,041 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:20,041 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:20,041 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:20,041 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:20,041 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:20,041 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:20,041 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:20,041 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:20,041 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:20,042 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:20,042 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:20,042 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:20,042 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:20,042 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:20,042 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:20,043 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:20,044 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:20,044 -  log.py[line:110] - INFO: {'movieID': 672279, 'movieName': '雪暴', 'seatRate': '12.6%', 'boxInfo': '317.05', 'boxRate': '0.7%', 'releaseInfo': '上映3天', 'showInfo': 8365, 'showRate': '2.6%', 'splitBoxInfo': '292.74', 'splitSumBoxInfo': '1171.2', 'sumBoxInfo': '1246.2', 'showView': '11', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#6'}
2020-05-02 13:32:20,045 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:21,075 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:21,413 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:21,413 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:21,413 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:21,413 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:21,413 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:21,413 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:21,446 -  movie_spider.py[line:136] - INFO: get 7 boxOffice, named .
2020-05-02 13:32:21,446 -  movie_spider.py[line:136] - INFO: get 7 boxOffice, named .
2020-05-02 13:32:21,446 -  movie_spider.py[line:136] - INFO: get 7 boxOffice, named .
2020-05-02 13:32:21,446 -  movie_spider.py[line:136] - INFO: get 7 boxOffice, named .
2020-05-02 13:32:21,446 -  movie_spider.py[line:136] - INFO: get 7 boxOffice, named .
2020-05-02 13:32:21,446 -  movie_spider.py[line:136] - INFO: get 7 boxOffice, named .
2020-05-02 13:32:21,448 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:21,448 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:21,448 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:21,448 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:21,448 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:21,448 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:21,448 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:21,448 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:21,448 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:21,448 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:21,448 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:21,448 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:21,449 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:21,449 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:21,449 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:21,449 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:21,449 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:21,449 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:21,449 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:21,450 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:21,450 -  log.py[line:110] - INFO: {'movieID': 1239544, 'movieName': '调音师', 'seatRate': '25.9%', 'boxInfo': '169.34', 'boxRate': '0.4%', 'releaseInfo': '上映30天', 'showInfo': 2141, 'showRate': '0.6%', 'splitBoxInfo': '154.12', 'splitSumBoxInfo': '28700.0', 'sumBoxInfo': '31800.0', 'showView': '23', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#7'}
2020-05-02 13:32:21,451 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:21,790 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:22,614 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:22,614 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:22,614 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:22,614 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:22,614 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:22,614 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:22,620 -  movie_spider.py[line:136] - INFO: get 8 boxOffice, named .
2020-05-02 13:32:22,620 -  movie_spider.py[line:136] - INFO: get 8 boxOffice, named .
2020-05-02 13:32:22,620 -  movie_spider.py[line:136] - INFO: get 8 boxOffice, named .
2020-05-02 13:32:22,620 -  movie_spider.py[line:136] - INFO: get 8 boxOffice, named .
2020-05-02 13:32:22,620 -  movie_spider.py[line:136] - INFO: get 8 boxOffice, named .
2020-05-02 13:32:22,620 -  movie_spider.py[line:136] - INFO: get 8 boxOffice, named .
2020-05-02 13:32:22,621 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:22,621 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:22,621 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:22,621 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:22,621 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:22,621 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:22,622 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:22,622 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:22,622 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:22,622 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:22,622 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:22,622 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:22,622 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:22,622 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:22,622 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:22,622 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:22,622 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:22,622 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:22,623 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:22,623 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:22,623 -  log.py[line:110] - INFO: {'movieID': 1211727, 'movieName': '反贪风暴4', 'seatRate': '17.9%', 'boxInfo': '148.54', 'boxRate': '0.3%', 'releaseInfo': '上映29天', 'showInfo': 2651, 'showRate': '0.8%', 'splitBoxInfo': '136.84', 'splitSumBoxInfo': '72600.0', 'sumBoxInfo': '78600.0', 'showView': '16', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#8'}
2020-05-02 13:32:22,624 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:23,118 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:23,745 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 13:32:23,753 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:23,753 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:23,753 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:23,753 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:23,753 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:23,753 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:23,780 -  movie_spider.py[line:136] - INFO: get 9 boxOffice, named .
2020-05-02 13:32:23,780 -  movie_spider.py[line:136] - INFO: get 9 boxOffice, named .
2020-05-02 13:32:23,780 -  movie_spider.py[line:136] - INFO: get 9 boxOffice, named .
2020-05-02 13:32:23,780 -  movie_spider.py[line:136] - INFO: get 9 boxOffice, named .
2020-05-02 13:32:23,780 -  movie_spider.py[line:136] - INFO: get 9 boxOffice, named .
2020-05-02 13:32:23,780 -  movie_spider.py[line:136] - INFO: get 9 boxOffice, named .
2020-05-02 13:32:23,781 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:23,781 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:23,781 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:23,781 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:23,781 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:23,781 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:23,782 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:23,782 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:23,782 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:23,782 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:23,782 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:23,782 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:23,782 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:23,782 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:23,782 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:23,782 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:23,782 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:23,782 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:23,783 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:23,784 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:23,784 -  log.py[line:110] - INFO: {'movieID': 1189325, 'movieName': '捉妖学院', 'seatRate': '4.2%', 'boxInfo': '99.02', 'boxRate': '0.2%', 'releaseInfo': '上映3天', 'showInfo': 169, 'showRate': '<0.1%', 'splitBoxInfo': '98.99', 'splitSumBoxInfo': '211.3', 'sumBoxInfo': '211.4', 'showView': '36', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#9'}
2020-05-02 13:32:23,785 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:24,498 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:24,499 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-02 13:32:25,437 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:25,437 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:25,437 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:25,437 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:25,437 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:25,437 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:25,470 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 13:32:25,475 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-02 13:32:25,475 -  movie_spider.py[line:158] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 13:32:25,475 -  movie_spider.py[line:158] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 13:32:25,475 -  movie_spider.py[line:158] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 13:32:25,475 -  movie_spider.py[line:158] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 13:32:25,475 -  movie_spider.py[line:158] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 13:32:25,475 -  movie_spider.py[line:158] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 13:32:25,476 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,476 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,476 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,476 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,476 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,476 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,476 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:25,476 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:25,476 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:25,476 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:25,476 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:25,476 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:25,477 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,477 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,477 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,477 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,477 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:25,477 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:26,898 -  movie_spider.py[line:136] - INFO: get 10 boxOffice, named .
2020-05-02 13:32:26,898 -  movie_spider.py[line:136] - INFO: get 10 boxOffice, named .
2020-05-02 13:32:26,898 -  movie_spider.py[line:136] - INFO: get 10 boxOffice, named .
2020-05-02 13:32:26,898 -  movie_spider.py[line:136] - INFO: get 10 boxOffice, named .
2020-05-02 13:32:26,898 -  movie_spider.py[line:136] - INFO: get 10 boxOffice, named .
2020-05-02 13:32:26,898 -  movie_spider.py[line:136] - INFO: get 10 boxOffice, named .
2020-05-02 13:32:26,902 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:26,902 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:26,902 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:26,902 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:26,902 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:26,902 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:26,902 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:26,902 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:26,902 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:26,902 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:26,902 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:26,902 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:26,904 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:26,904 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:26,904 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:26,904 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:26,904 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:26,904 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:26,905 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:26,906 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:26,907 -  log.py[line:110] - INFO: {'movieID': 1230152, 'movieName': '撞死了一只羊', 'seatRate': '12.2%', 'boxInfo': '78.11', 'boxRate': '0.1%', 'releaseInfo': '上映7天', 'showInfo': 1662, 'showRate': '0.5%', 'splitBoxInfo': '75.66', 'splitSumBoxInfo': '832.4', 'sumBoxInfo': '864.4', 'showView': '12', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#10'}
2020-05-02 13:32:26,909 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:27,313 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:27,314 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:27,314 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:27,314 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:27,314 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:27,314 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:27,314 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:32:27,343 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-02 13:32:27,345 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-02 13:32:27,347 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-02 13:32:27,352 -  movie_spider.py[line:158] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 13:32:27,352 -  movie_spider.py[line:158] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 13:32:27,352 -  movie_spider.py[line:158] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 13:32:27,352 -  movie_spider.py[line:158] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 13:32:27,352 -  movie_spider.py[line:158] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 13:32:27,352 -  movie_spider.py[line:158] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 13:32:27,352 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,352 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,352 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,352 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,352 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,352 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,352 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:27,352 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:27,352 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:27,352 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:27,352 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:27,352 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:27,353 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,353 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,353 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,353 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,353 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:27,353 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:29,483 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:29,483 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:29,483 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:29,483 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:29,483 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:29,483 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:29,503 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:29,503 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:29,503 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:29,503 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:29,503 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:29,503 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 13:32:29,514 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-02 13:32:29,518 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 13:32:29,518 -  movie_spider.py[line:158] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 13:32:29,518 -  movie_spider.py[line:158] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 13:32:29,518 -  movie_spider.py[line:158] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 13:32:29,518 -  movie_spider.py[line:158] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 13:32:29,518 -  movie_spider.py[line:158] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 13:32:29,518 -  movie_spider.py[line:158] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 13:32:29,518 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,518 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,518 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,518 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,518 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,518 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,519 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:29,519 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:29,519 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:29,519 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:29,519 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:29,519 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:29,519 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,519 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,519 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,519 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,519 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:29,519 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:30,792 -  movie_spider.py[line:158] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 13:32:30,792 -  movie_spider.py[line:158] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 13:32:30,792 -  movie_spider.py[line:158] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 13:32:30,792 -  movie_spider.py[line:158] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 13:32:30,792 -  movie_spider.py[line:158] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 13:32:30,792 -  movie_spider.py[line:158] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 13:32:30,794 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,794 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,794 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,794 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,794 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,794 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,795 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:30,795 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:30,795 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:30,795 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:30,795 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:30,795 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:30,796 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,796 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,796 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,796 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,796 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:30,796 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:32,015 -  movie_spider.py[line:136] - INFO: get 11 boxOffice, named .
2020-05-02 13:32:32,015 -  movie_spider.py[line:136] - INFO: get 11 boxOffice, named .
2020-05-02 13:32:32,015 -  movie_spider.py[line:136] - INFO: get 11 boxOffice, named .
2020-05-02 13:32:32,015 -  movie_spider.py[line:136] - INFO: get 11 boxOffice, named .
2020-05-02 13:32:32,015 -  movie_spider.py[line:136] - INFO: get 11 boxOffice, named .
2020-05-02 13:32:32,015 -  movie_spider.py[line:136] - INFO: get 11 boxOffice, named .
2020-05-02 13:32:32,018 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:32,018 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:32,018 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:32,018 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:32,018 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:32,018 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:32,019 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:32,019 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:32,019 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:32,019 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:32,019 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:32,019 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:32,020 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:32,020 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:32,020 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:32,020 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:32,020 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:32,020 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:32,022 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:32,022 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:32,023 -  log.py[line:110] - INFO: {'movieID': 330115, 'movieName': '我和神马查干', 'seatRate': '--', 'boxInfo': '73.22', 'boxRate': '0.1%', 'releaseInfo': '', 'showInfo': 219, 'showRate': '<0.1%', 'splitBoxInfo': '73.04', 'splitSumBoxInfo': '2169.6', 'sumBoxInfo': '2177.2', 'showView': '103', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#11'}
2020-05-02 13:32:32,025 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:32,780 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:32,781 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:32,781 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:32,781 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:32,781 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:32,781 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:32,781 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 13:32:32,804 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-02 13:32:32,806 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-02 13:32:32,810 -  movie_spider.py[line:158] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 13:32:32,810 -  movie_spider.py[line:158] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 13:32:32,810 -  movie_spider.py[line:158] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 13:32:32,810 -  movie_spider.py[line:158] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 13:32:32,810 -  movie_spider.py[line:158] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 13:32:32,810 -  movie_spider.py[line:158] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 13:32:32,811 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:32,811 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:32,811 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:32,811 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:32,811 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:32,811 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:32,811 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:32,811 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:34,234 -  movie_spider.py[line:158] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 13:32:34,234 -  movie_spider.py[line:158] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 13:32:34,234 -  movie_spider.py[line:158] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 13:32:34,234 -  movie_spider.py[line:158] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 13:32:34,234 -  movie_spider.py[line:158] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 13:32:34,234 -  movie_spider.py[line:158] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 13:32:34,235 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,235 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,235 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,235 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,235 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,235 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,236 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:34,236 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:34,236 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:34,236 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:34,236 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:34,236 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:34,237 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,237 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,237 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,237 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,237 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:34,237 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:35,513 -  movie_spider.py[line:158] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 13:32:35,513 -  movie_spider.py[line:158] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 13:32:35,513 -  movie_spider.py[line:158] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 13:32:35,513 -  movie_spider.py[line:158] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 13:32:35,513 -  movie_spider.py[line:158] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 13:32:35,513 -  movie_spider.py[line:158] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 13:32:35,514 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,514 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,514 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,514 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,514 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,514 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,515 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:35,515 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:35,515 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:35,515 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:35,515 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:35,515 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:35,516 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,516 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,516 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,516 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,516 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:35,516 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:37,082 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:37,082 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:37,082 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:37,082 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:37,082 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:37,082 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:37,109 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:37,109 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:37,109 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:37,109 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:37,109 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:37,109 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 13:32:37,120 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:37,120 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:37,120 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:37,120 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:37,120 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:37,120 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 13:32:37,129 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:37,129 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:37,129 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:37,129 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:37,129 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:37,129 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 13:32:37,137 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:32:37,139 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-02 13:32:37,141 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 13:32:37,141 -  movie_spider.py[line:158] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 13:32:37,141 -  movie_spider.py[line:158] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 13:32:37,141 -  movie_spider.py[line:158] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 13:32:37,141 -  movie_spider.py[line:158] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 13:32:37,141 -  movie_spider.py[line:158] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 13:32:37,141 -  movie_spider.py[line:158] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 13:32:37,141 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,141 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,141 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,141 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,141 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,141 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,142 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:32:37,142 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:32:37,142 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:32:37,142 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:32:37,142 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:32:37,142 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:32:37,142 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,142 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,142 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,142 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,142 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:37,142 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:38,259 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:38,259 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:38,259 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:38,259 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:38,259 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:38,259 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:38,260 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:38,260 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:38,260 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:38,260 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:38,260 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:38,260 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:32:38,338 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:38,338 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:38,338 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:38,338 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:38,338 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:38,338 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:38,543 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26662282
{'actors': '索菲亚·玛丽/詹妮弗·加纳/肯·哈德森·坎贝尔/基南·汤普森/米拉·库尼斯/约翰·奥利弗/郑肯/诺贝特·里奥·布茨/马修·布罗德里克/凯特·麦克格雷格-斯图尔特',
 'area': ' 美国 / 西班牙',
 'dbMovieID': ['26662282'],
 'directors': '迪兰·布朗',
 'doubanRate': ['6.3'],
 'duration': [86],
 'genre': '喜剧/动画/奇幻/冒险',
 'movieName': ['神奇乐园历险记 Wonder Park'],
 'publishedDate': ['2019-03-15'],
 'rateCount': ['2947'],
 'tppMovieID': [1211412],
 'writers': '乔什·阿佩尔鲍姆/安德烈·内梅克/罗伯特·戈登'}
2020-05-02 13:32:38,561 -  movie_spider.py[line:136] - INFO: get 12 boxOffice, named .
2020-05-02 13:32:38,561 -  movie_spider.py[line:136] - INFO: get 12 boxOffice, named .
2020-05-02 13:32:38,561 -  movie_spider.py[line:136] - INFO: get 12 boxOffice, named .
2020-05-02 13:32:38,561 -  movie_spider.py[line:136] - INFO: get 12 boxOffice, named .
2020-05-02 13:32:38,561 -  movie_spider.py[line:136] - INFO: get 12 boxOffice, named .
2020-05-02 13:32:38,561 -  movie_spider.py[line:136] - INFO: get 12 boxOffice, named .
2020-05-02 13:32:38,565 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:38,565 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:38,565 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:38,565 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:38,565 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:38,565 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:38,565 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:38,565 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:38,565 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:38,565 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:38,565 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:38,565 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:38,567 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:38,567 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:38,567 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:38,567 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:38,567 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:38,567 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:38,568 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:38,569 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:38,569 -  log.py[line:110] - INFO: {'movieID': 1243904, 'movieName': '动物出击', 'seatRate': '10.9%', 'boxInfo': '40.69', 'boxRate': '<0.1%', 'releaseInfo': '上映3天', 'showInfo': 1826, 'showRate': '0.5%', 'splitBoxInfo': '38.50', 'splitSumBoxInfo': '262.3', 'sumBoxInfo': '269.7', 'showView': '7', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#12'}
2020-05-02 13:32:38,570 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:40,165 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:40,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,193 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,193 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,193 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,193 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,193 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,193 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 13:32:40,206 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-02 13:32:40,208 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-02 13:32:40,211 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-02 13:32:40,212 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-02 13:32:43,315 -  movie_spider.py[line:158] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 13:32:43,315 -  movie_spider.py[line:158] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 13:32:43,315 -  movie_spider.py[line:158] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 13:32:43,315 -  movie_spider.py[line:158] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 13:32:43,315 -  movie_spider.py[line:158] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 13:32:43,315 -  movie_spider.py[line:158] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 13:32:43,318 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,318 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,318 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,318 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,318 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,318 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,318 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:43,318 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:43,318 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:43,318 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:43,318 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:43,318 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:43,319 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,319 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,319 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,319 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,319 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:43,319 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:32:44,617 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:44,617 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:44,617 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:44,617 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:44,617 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:44,617 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 13:32:44,664 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:44,664 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:44,664 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:44,664 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:44,664 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:44,664 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:44,667 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['832512'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-05-02 13:32:45,259 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:32:45,259 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:32:45,259 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:32:45,259 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:32:45,259 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:32:45,259 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:32:45,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:45,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:45,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:45,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:45,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:45,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 13:32:45,301 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-02 13:32:45,304 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-02 13:32:45,304 -  movie_spider.py[line:158] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 13:32:45,304 -  movie_spider.py[line:158] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 13:32:45,304 -  movie_spider.py[line:158] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 13:32:45,304 -  movie_spider.py[line:158] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 13:32:45,304 -  movie_spider.py[line:158] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 13:32:45,304 -  movie_spider.py[line:158] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 13:32:45,304 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,304 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,304 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,304 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,304 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,304 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,304 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:32:45,304 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:32:45,304 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:32:45,304 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:32:45,304 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:32:45,304 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:32:45,305 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,305 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,305 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,305 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,305 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:45,305 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:46,970 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:46,970 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:46,970 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:46,970 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:46,970 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:46,970 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:46,972 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:46,972 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:46,972 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:46,972 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:46,972 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:46,972 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 13:32:47,009 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,009 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,009 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,009 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,009 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,009 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,011 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26311974
{'actors': '郭采洁/郑恺/李东学/谢依霖/刘心悠/邱欣怡/李荣浩/蓝心湄/林辰唏/林美秀',
 'area': ' 中国台湾 / 中国大陆',
 'dbMovieID': ['26311974'],
 'directors': '陈鸿仪',
 'doubanRate': ['2.8'],
 'duration': [99],
 'genre': '爱情',
 'movieName': ['下一任：前任'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['23783'],
 'tppMovieID': [1228776],
 'writers': '陈鸿仪'}
2020-05-02 13:32:47,012 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:47,012 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:47,012 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:47,012 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:47,012 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:47,012 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 13:32:47,026 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,026 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,026 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,026 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,026 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,026 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:47,027 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:47,027 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:47,027 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:47,027 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:47,027 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:47,027 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:47,027 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:32:47,027 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:32:47,027 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:32:47,027 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:32:47,027 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:32:47,027 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:32:47,028 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:47,028 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:47,028 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:47,028 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:47,028 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:47,028 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:47,028 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:47,029 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:32:47,029 -  log.py[line:110] - INFO: {'dbMovieID': '26878827', 'tppMovieID': 672379, 'movieName': '悟空奇遇记', 'directors': '殷玉麒', 'writers': '殷玉麒', 'actors': '张震/李姗姗/元气纣/宝木中阳/叮当/李璐', 'genre': '喜剧/动画', 'area': ' 中国大陆', 'duration': 88, 'publishedDate': '2019-05-01', 'rateCount': '710', 'doubanRate': '2.8'}
2020-05-02 13:32:47,243 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:47,763 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-02 13:32:49,639 -  movie_spider.py[line:136] - INFO: get 13 boxOffice, named .
2020-05-02 13:32:49,639 -  movie_spider.py[line:136] - INFO: get 13 boxOffice, named .
2020-05-02 13:32:49,639 -  movie_spider.py[line:136] - INFO: get 13 boxOffice, named .
2020-05-02 13:32:49,639 -  movie_spider.py[line:136] - INFO: get 13 boxOffice, named .
2020-05-02 13:32:49,639 -  movie_spider.py[line:136] - INFO: get 13 boxOffice, named .
2020-05-02 13:32:49,639 -  movie_spider.py[line:136] - INFO: get 13 boxOffice, named .
2020-05-02 13:32:49,645 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:49,645 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:49,645 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:49,645 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:49,645 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:49,645 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:32:49,646 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:49,646 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:49,646 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:49,646 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:49,646 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:49,646 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:32:49,648 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:49,648 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:49,648 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:49,648 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:49,648 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:49,648 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:32:49,649 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:32:49,650 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:32:49,651 -  log.py[line:110] - INFO: {'movieID': 1228750, 'movieName': '照相师', 'seatRate': '91.6%', 'boxInfo': '25.57', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 47, 'showRate': '<0.1%', 'splitBoxInfo': '25.57', 'splitSumBoxInfo': '2095.6', 'sumBoxInfo': '2108.1', 'showView': '124', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#13'}
2020-05-02 13:32:49,653 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:32:50,286 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:32:50,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,287 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,321 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,321 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,321 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,321 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,321 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,321 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:50,338 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-02 13:32:50,341 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-02 13:32:51,423 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:51,423 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:51,423 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:51,423 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:51,423 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:51,423 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:54,334 -  movie_spider.py[line:158] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 13:32:54,334 -  movie_spider.py[line:158] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 13:32:54,334 -  movie_spider.py[line:158] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 13:32:54,334 -  movie_spider.py[line:158] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 13:32:54,334 -  movie_spider.py[line:158] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 13:32:54,334 -  movie_spider.py[line:158] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 13:32:54,336 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:54,336 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:54,336 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:54,336 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:54,336 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:54,336 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:32:54,336 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:54,336 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:32:55,836 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:55,836 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:55,836 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:55,836 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:55,836 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:55,836 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 13:32:55,877 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,877 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,877 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,877 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,877 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,877 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,880 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27202819
{'actors': '古天乐/郑嘉颖/林峯/林家栋/周秀娜/张智霖/谭耀文/张继聪/蔡瀚亿/廖启智',
 'area': ' 中国香港 / 中国大陆',
 'dbMovieID': ['27202819'],
 'directors': '林德禄',
 'doubanRate': ['6.0'],
 'duration': [96],
 'genre': '动作/犯罪',
 'movieName': ['反贪风暴4 P風暴'],
 'publishedDate': ['2019-04-04'],
 'rateCount': ['131779'],
 'tppMovieID': [1211727],
 'writers': '黄浩华/何文龙'}
2020-05-02 13:32:55,880 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:55,880 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:55,880 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:55,880 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:55,880 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:55,880 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 13:32:55,895 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,895 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,895 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,895 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,895 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,895 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,897 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30170448
{'actors': '赞恩·阿尔·拉菲亚/约丹诺斯·希费罗/博鲁瓦蒂夫·特雷杰·班科尔/卡萨尔·艾尔·哈达德/法迪·尤瑟夫/海塔·塞德拉·伊扎姆/阿拉·乔什涅/娜丁·拉巴基/埃利亚斯·库利/努尔·艾尔·侯赛尼',
 'area': ' 黎巴嫩 / 法国 / 美国',
 'dbMovieID': ['30170448'],
 'directors': '娜丁·拉巴基',
 'doubanRate': ['9.1'],
 'duration': [126],
 'genre': '剧情',
 'movieName': ['何以为家 كفرناحوم'],
 'publishedDate': ['2018-05-17'],
 'rateCount': ['637485'],
 'tppMovieID': [1218727],
 'writers': '娜丁·拉巴基/吉哈德·霍加里/米歇尔·凯斯沃尼/乔治斯·哈巴兹/哈立德·穆扎纳'}
2020-05-02 13:32:55,898 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:55,898 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:55,898 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:55,898 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:55,898 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:55,898 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 13:32:55,906 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,906 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,906 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,906 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,906 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,906 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,908 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26879542
{'actors': '王泽宗/慈婉彤/周海媚/胡昌霖',
 'area': ' 中国大陆',
 'dbMovieID': ['26879542'],
 'directors': '田梓橙',
 'doubanRate': [''],
 'duration': [96],
 'genre': '奇幻/冒险',
 'movieName': ['捉妖学院'],
 'publishedDate': ['2019-04-30'],
 'rateCount': ['0'],
 'tppMovieID': [1189325],
 'writers': '方岚/田梓橙'}
2020-05-02 13:32:55,944 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,944 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,944 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,944 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,944 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,944 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,951 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:55,951 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:55,951 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:55,951 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:55,951 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:55,951 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 13:32:55,960 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,960 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,960 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,960 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,960 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,960 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:32:55,968 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:32:55,970 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:32:55,970 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,970 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,970 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,970 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,970 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,970 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,983 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,983 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,983 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,983 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,983 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,983 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,985 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26899146
{'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利',
 'area': ' 中国大陆',
 'dbMovieID': ['26899146'],
 'directors': '崔斯韦',
 'doubanRate': ['6.2'],
 'duration': [111],
 'genre': '动作/犯罪/悬疑',
 'movieName': ['雪暴'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['52301'],
 'tppMovieID': [672279],
 'writers': '崔斯韦'}
2020-05-02 13:32:55,985 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,985 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,985 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,985 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,985 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,985 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-02 13:32:55,998 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,998 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,998 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,998 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,998 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:55,998 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:32:56,000 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26899146
{'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利',
 'area': ' 中国大陆',
 'dbMovieID': ['26899146'],
 'directors': '崔斯韦',
 'doubanRate': ['6.2'],
 'duration': [111],
 'genre': '动作/犯罪/悬疑',
 'movieName': ['雪暴'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['52301'],
 'tppMovieID': [672279],
 'writers': '崔斯韦'}
2020-05-02 13:32:57,482 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:57,482 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:57,482 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:57,482 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:57,482 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:32:57,482 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:01,845 -  movie_spider.py[line:136] - INFO: get 14 boxOffice, named .
2020-05-02 13:33:01,845 -  movie_spider.py[line:136] - INFO: get 14 boxOffice, named .
2020-05-02 13:33:01,845 -  movie_spider.py[line:136] - INFO: get 14 boxOffice, named .
2020-05-02 13:33:01,845 -  movie_spider.py[line:136] - INFO: get 14 boxOffice, named .
2020-05-02 13:33:01,845 -  movie_spider.py[line:136] - INFO: get 14 boxOffice, named .
2020-05-02 13:33:01,845 -  movie_spider.py[line:136] - INFO: get 14 boxOffice, named .
2020-05-02 13:33:01,849 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:01,849 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:01,849 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:01,849 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:01,849 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:01,849 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:01,850 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:01,850 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:01,850 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:01,850 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:01,850 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:01,850 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:01,851 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:01,851 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:01,851 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:01,851 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:01,851 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:01,851 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:01,852 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:01,853 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:33:01,853 -  log.py[line:110] - INFO: {'movieID': 1234116, 'movieName': '猫公主苏菲', 'seatRate': '5.2%', 'boxInfo': '23.68', 'boxRate': '<0.1%', 'releaseInfo': '上映2天', 'showInfo': 2204, 'showRate': '0.6%', 'splitBoxInfo': '22.11', 'splitSumBoxInfo': '61.8', 'sumBoxInfo': '66.3', 'showView': '4', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#14'}
2020-05-02 13:33:01,855 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:33:02,337 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:02,337 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:02,337 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:02,337 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:02,337 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:02,337 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:02,337 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:02,345 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:33:02,346 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-02 13:33:02,348 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:33:05,344 -  movie_spider.py[line:158] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 13:33:05,344 -  movie_spider.py[line:158] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 13:33:05,344 -  movie_spider.py[line:158] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 13:33:05,344 -  movie_spider.py[line:158] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 13:33:05,344 -  movie_spider.py[line:158] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 13:33:05,344 -  movie_spider.py[line:158] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 13:33:05,348 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:05,348 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:05,348 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:05,348 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:05,348 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:05,348 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:05,348 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:05,348 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:06,613 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:33:06,613 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:33:06,613 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:33:06,613 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:33:06,613 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:33:06,613 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 13:33:06,652 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:06,652 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:06,652 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:06,652 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:06,652 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:06,652 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:06,654 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30283179
{'actors': '金巴/更登彭措/索朗旺姆/加华草',
 'area': ' 中国大陆',
 'dbMovieID': ['30283179'],
 'directors': '万玛才旦',
 'doubanRate': ['7.2'],
 'duration': [87],
 'genre': '剧情',
 'movieName': ['撞死了一只羊'],
 'publishedDate': ['2018-09-04'],
 'rateCount': ['40902'],
 'tppMovieID': [1230152],
 'writers': '万玛才旦/次仁罗布'}
2020-05-02 13:33:08,606 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:08,606 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:08,606 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:08,606 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:08,606 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:08,606 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:08,693 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:08,693 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:08,693 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:08,693 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:08,693 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:08,693 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:08,713 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:33:08,713 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:33:08,713 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:33:08,713 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:33:08,713 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:33:08,713 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 13:33:08,724 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:33:08,729 -  logstats.py[line:48] - INFO: Crawled 29 pages (at 29 pages/min), scraped 15 items (at 15 items/min)
2020-05-02 13:33:10,410 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,410 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,410 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,410 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,410 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,410 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,441 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,441 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,441 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,441 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,441 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,441 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,443 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30334073
{'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼',
 'area': ' 印度',
 'dbMovieID': ['30334073'],
 'directors': '斯里兰姆·拉格万',
 'doubanRate': ['8.3'],
 'duration': [139],
 'genre': '喜剧/犯罪/悬疑/惊悚',
 'movieName': ['调音师 Andhadhun'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['656014'],
 'tppMovieID': [1239544],
 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内'}
2020-05-02 13:33:10,444 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,444 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,444 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,444 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,444 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,444 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:10,457 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,457 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,457 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,457 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,457 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,457 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:10,459 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30334073
{'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼',
 'area': ' 印度',
 'dbMovieID': ['30334073'],
 'directors': '斯里兰姆·拉格万',
 'doubanRate': ['8.3'],
 'duration': [139],
 'genre': '喜剧/犯罪/悬疑/惊悚',
 'movieName': ['调音师 Andhadhun'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['656014'],
 'tppMovieID': [1239544],
 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内'}
2020-05-02 13:33:12,113 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:12,113 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:12,113 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:12,113 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:12,113 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:12,113 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:12,114 -  movie_spider.py[line:136] - INFO: get 15 boxOffice, named .
2020-05-02 13:33:12,114 -  movie_spider.py[line:136] - INFO: get 15 boxOffice, named .
2020-05-02 13:33:12,114 -  movie_spider.py[line:136] - INFO: get 15 boxOffice, named .
2020-05-02 13:33:12,114 -  movie_spider.py[line:136] - INFO: get 15 boxOffice, named .
2020-05-02 13:33:12,114 -  movie_spider.py[line:136] - INFO: get 15 boxOffice, named .
2020-05-02 13:33:12,114 -  movie_spider.py[line:136] - INFO: get 15 boxOffice, named .
2020-05-02 13:33:12,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:12,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:12,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:12,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:12,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:12,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:12,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:12,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:12,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:12,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:12,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:12,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:12,116 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:12,116 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:12,116 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:12,116 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:12,116 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:12,116 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:12,116 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:12,116 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:33:12,116 -  log.py[line:110] - INFO: {'movieID': 1205909, 'movieName': '祈祷落幕时', 'seatRate': '21.8%', 'boxInfo': '21.99', 'boxRate': '<0.1%', 'releaseInfo': '上映21天', 'showInfo': 346, 'showRate': '0.1%', 'splitBoxInfo': '20.08', 'splitSumBoxInfo': '6032.5', 'sumBoxInfo': '6671.5', 'showView': '18', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#15'}
2020-05-02 13:33:12,117 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:33:12,480 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:12,480 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:12,480 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:12,480 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:12,480 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:12,480 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:12,480 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:12,488 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2> (referer: https://movie.douban.com/)
2020-05-02 13:33:12,490 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:33:12,491 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-02 13:33:12,492 -  movie_spider.py[line:158] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 13:33:12,492 -  movie_spider.py[line:158] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 13:33:12,492 -  movie_spider.py[line:158] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 13:33:12,492 -  movie_spider.py[line:158] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 13:33:12,492 -  movie_spider.py[line:158] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 13:33:12,492 -  movie_spider.py[line:158] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 13:33:12,492 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:12,492 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:12,492 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:12,492 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:12,492 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:12,492 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:12,492 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:12,492 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:14,483 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:14,483 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:14,483 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:14,483 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:14,483 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:14,483 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:14,484 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:33:14,484 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:33:14,484 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:33:14,484 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:33:14,484 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:33:14,484 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 13:33:14,493 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,493 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,493 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,493 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,493 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,493 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,494 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :20438453
{'actors': '',
 'area': ' 中国大陆',
 'dbMovieID': ['20438453'],
 'directors': '侯克明/刘珅',
 'doubanRate': ['5.3'],
 'duration': [90],
 'genre': '剧情/儿童',
 'movieName': ['我和神马查干'],
 'publishedDate': ['2012-12-05'],
 'rateCount': ['54'],
 'tppMovieID': [330115],
 'writers': '刘珅'}
2020-05-02 13:33:14,495 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:14,495 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:14,495 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:14,495 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:14,495 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:14,495 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:14,504 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,504 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,504 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,504 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,504 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,504 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:14,506 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-02 13:33:20,254 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:20,254 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:20,254 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:20,254 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:20,254 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:20,254 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:20,280 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,280 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,280 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,280 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,280 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,280 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,291 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,291 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,291 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,291 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,291 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,291 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 13:33:20,300 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:33:24,071 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:24,071 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:24,071 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:24,071 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:24,071 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:24,071 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:24,108 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:24,108 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:24,108 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:24,108 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:24,108 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:24,108 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:24,111 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-02 13:33:24,116 -  movie_spider.py[line:136] - INFO: get 16 boxOffice, named .
2020-05-02 13:33:24,116 -  movie_spider.py[line:136] - INFO: get 16 boxOffice, named .
2020-05-02 13:33:24,116 -  movie_spider.py[line:136] - INFO: get 16 boxOffice, named .
2020-05-02 13:33:24,116 -  movie_spider.py[line:136] - INFO: get 16 boxOffice, named .
2020-05-02 13:33:24,116 -  movie_spider.py[line:136] - INFO: get 16 boxOffice, named .
2020-05-02 13:33:24,116 -  movie_spider.py[line:136] - INFO: get 16 boxOffice, named .
2020-05-02 13:33:24,117 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:24,117 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:24,117 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:24,117 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:24,117 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:24,117 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:24,117 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:24,117 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:24,117 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:24,117 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:24,117 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:24,117 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:24,117 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:24,117 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:24,117 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:24,117 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:24,117 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:24,117 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:24,118 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:24,118 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:33:24,118 -  log.py[line:110] - INFO: {'movieID': 1212492, 'movieName': '老师·好', 'seatRate': '19.9%', 'boxInfo': '20.51', 'boxRate': '<0.1%', 'releaseInfo': '重映42天', 'showInfo': 363, 'showRate': '0.1%', 'splitBoxInfo': '19.25', 'splitSumBoxInfo': '32600.0', 'sumBoxInfo': '35300.0', 'showView': '17', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#16'}
2020-05-02 13:33:24,119 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:33:24,678 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:24,682 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/)
2020-05-02 13:33:24,687 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:33:24,695 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 13:33:24,696 -  movie_spider.py[line:158] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 13:33:24,696 -  movie_spider.py[line:158] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 13:33:24,696 -  movie_spider.py[line:158] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 13:33:24,696 -  movie_spider.py[line:158] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 13:33:24,696 -  movie_spider.py[line:158] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 13:33:24,696 -  movie_spider.py[line:158] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 13:33:24,697 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,697 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,697 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,697 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,697 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,697 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,698 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:24,698 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:24,698 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:24,698 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:24,698 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:24,698 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:24,698 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,698 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,698 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,698 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,698 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:24,698 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:26,660 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:26,660 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:26,660 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:26,660 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:26,660 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:26,660 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:26,696 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,696 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,696 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,696 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,696 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,696 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,700 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-02 13:33:26,701 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:26,701 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:26,701 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:26,701 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:26,701 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:26,701 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 13:33:26,718 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,718 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,718 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,718 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,718 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,718 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:26,720 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30345341
{'actors': '景熙童/宝德/冯冯/冯薇朵/陈长海/李浩轩',
 'area': ' 中国大陆',
 'dbMovieID': ['30345341'],
 'directors': '冯小宁',
 'doubanRate': ['3.5'],
 'duration': [105],
 'genre': '科幻/冒险',
 'movieName': ['动物出击'],
 'publishedDate': ['2019-04-30'],
 'rateCount': ['1952'],
 'tppMovieID': [1243904],
 'writers': '冯小宁'}
2020-05-02 13:33:28,704 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:28,704 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:28,704 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:28,704 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:28,704 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:28,704 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:32,316 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:32,316 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:32,316 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:32,316 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:32,316 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:32,316 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 13:33:32,352 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:32,352 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:32,352 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:32,352 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:32,352 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:32,352 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:32,356 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-02 13:33:32,359 -  movie_spider.py[line:136] - INFO: get 17 boxOffice, named .
2020-05-02 13:33:32,359 -  movie_spider.py[line:136] - INFO: get 17 boxOffice, named .
2020-05-02 13:33:32,359 -  movie_spider.py[line:136] - INFO: get 17 boxOffice, named .
2020-05-02 13:33:32,359 -  movie_spider.py[line:136] - INFO: get 17 boxOffice, named .
2020-05-02 13:33:32,359 -  movie_spider.py[line:136] - INFO: get 17 boxOffice, named .
2020-05-02 13:33:32,359 -  movie_spider.py[line:136] - INFO: get 17 boxOffice, named .
2020-05-02 13:33:32,360 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:32,360 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:32,360 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:32,360 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:32,360 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:32,360 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:32,360 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:32,360 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:32,360 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:32,360 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:32,360 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:32,360 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:32,361 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:32,361 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:32,361 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:32,361 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:32,361 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:32,361 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:32,362 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:32,362 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:33:32,362 -  log.py[line:110] - INFO: {'movieID': 836, 'movieName': '毕业那年', 'seatRate': '--', 'boxInfo': '17.18', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 50, 'showRate': '<0.1%', 'splitBoxInfo': '17.13', 'splitSumBoxInfo': '1039.8', 'sumBoxInfo': '1041.5', 'showView': '107', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#17'}
2020-05-02 13:33:32,363 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:33:32,552 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:32,556 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 13:33:32,562 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2> (referer: https://movie.douban.com/)
2020-05-02 13:33:32,563 -  movie_spider.py[line:158] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 13:33:32,563 -  movie_spider.py[line:158] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 13:33:32,563 -  movie_spider.py[line:158] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 13:33:32,563 -  movie_spider.py[line:158] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 13:33:32,563 -  movie_spider.py[line:158] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 13:33:32,563 -  movie_spider.py[line:158] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 13:33:32,564 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,564 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,564 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,564 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,564 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,564 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,565 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:32,565 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:32,565 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:32,565 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:32,565 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:32,565 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:33:32,566 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,566 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,566 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,566 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,566 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:32,566 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:33,996 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:33,996 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:33,996 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:33,996 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:33,996 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:33,996 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:34,021 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,021 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,021 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,021 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,021 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,021 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,026 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :34970135
{'actors': '',
 'area': ' 中国大陆',
 'dbMovieID': ['34970135'],
 'directors': '',
 'doubanRate': [''],
 'duration': [4],
 'genre': '短片',
 'movieName': ['照相师'],
 'publishedDate': [''],
 'rateCount': ['0'],
 'tppMovieID': [1228750],
 'writers': ''}
2020-05-02 13:33:34,027 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:34,027 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:34,027 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:34,027 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:34,027 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:34,027 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 13:33:34,046 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,046 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,046 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,046 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,046 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,046 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:34,048 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30258232
{'actors': '谢钢/刘牧/康磊/涓子/秦楚明/马东延/于卉怡/上泽/张优/方子怡',
 'area': ' 中国大陆',
 'dbMovieID': ['30258232'],
 'directors': '张唯',
 'doubanRate': ['5.2'],
 'duration': [112],
 'genre': '剧情/历史',
 'movieName': ['照相师'],
 'publishedDate': ['2018-12-12'],
 'rateCount': ['927'],
 'tppMovieID': [1228750],
 'writers': '张敏'}
2020-05-02 13:33:34,049 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:34,049 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:34,049 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:34,049 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:34,049 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:34,049 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 13:33:37,973 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:37,973 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:37,973 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:37,973 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:37,973 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:37,973 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:38,004 -  movie_spider.py[line:136] - INFO: get 18 boxOffice, named .
2020-05-02 13:33:38,004 -  movie_spider.py[line:136] - INFO: get 18 boxOffice, named .
2020-05-02 13:33:38,004 -  movie_spider.py[line:136] - INFO: get 18 boxOffice, named .
2020-05-02 13:33:38,004 -  movie_spider.py[line:136] - INFO: get 18 boxOffice, named .
2020-05-02 13:33:38,004 -  movie_spider.py[line:136] - INFO: get 18 boxOffice, named .
2020-05-02 13:33:38,004 -  movie_spider.py[line:136] - INFO: get 18 boxOffice, named .
2020-05-02 13:33:38,005 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:38,005 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:38,005 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:38,005 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:38,005 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:38,005 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:38,006 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:38,006 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:38,006 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:38,006 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:38,006 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:38,006 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:38,006 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:38,006 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:38,006 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:38,006 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:38,006 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:38,006 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:38,007 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:38,007 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:33:38,008 -  log.py[line:110] - INFO: {'movieID': 1239281, 'movieName': '港珠澳大桥', 'seatRate': '4.5%', 'boxInfo': '16.06', 'boxRate': '<0.1%', 'releaseInfo': '上映2天', 'showInfo': 2033, 'showRate': '0.6%', 'splitBoxInfo': '15.11', 'splitSumBoxInfo': '64.3', 'sumBoxInfo': '67.3', 'showView': '3', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#18'}
2020-05-02 13:33:38,009 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:33:38,276 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:38,283 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/)
2020-05-02 13:33:38,284 -  movie_spider.py[line:158] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 13:33:38,284 -  movie_spider.py[line:158] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 13:33:38,284 -  movie_spider.py[line:158] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 13:33:38,284 -  movie_spider.py[line:158] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 13:33:38,284 -  movie_spider.py[line:158] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 13:33:38,284 -  movie_spider.py[line:158] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 13:33:38,285 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,285 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,285 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,285 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,285 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,285 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,286 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:33:38,286 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:33:38,286 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:33:38,286 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:33:38,286 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:33:38,286 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:33:38,286 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,286 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,286 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,286 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,286 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:38,286 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:40,032 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:40,032 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:40,032 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:40,032 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:40,032 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:40,032 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:40,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:40,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:40,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:40,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:40,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:40,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30320371/?suggest=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 13:33:40,067 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:40,067 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:40,067 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:40,067 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:40,067 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:40,067 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:40,070 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:40,070 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:40,070 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:40,070 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:40,070 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:40,070 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:40,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:33:40,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:33:40,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:33:40,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:33:40,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:33:40,071 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:33:40,071 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:40,071 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:40,071 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:40,071 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:40,071 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:40,071 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:40,072 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:40,072 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:33:40,072 -  log.py[line:110] - INFO: {'dbMovieID': '30320371', 'tppMovieID': 1234116, 'movieName': '猫公主苏菲', 'directors': '潘智超/郭攀/钟声', 'writers': '李布衣', 'actors': '吟良犬/张帆/漆凯/绿绮', 'genre': '动画/冒险', 'area': ' 中国大陆', 'duration': 78, 'publishedDate': '2019-05-01', 'rateCount': '0', 'doubanRate': ''}
2020-05-02 13:33:40,098 -  log.py[line:110] - INFO: ROLLBACK
2020-05-02 13:33:40,099 -  scraper.py[line:236] - ERROR: Error processing {'actors': '吟良犬/张帆/漆凯/绿绮',
 'area': ' 中国大陆',
 'dbMovieID': ['30320371'],
 'directors': '潘智超/郭攀/钟声',
 'doubanRate': [''],
 'duration': [78],
 'genre': '动画/冒险',
 'movieName': ['猫公主苏菲'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['0'],
 'tppMovieID': [1234116],
 'writers': '李布衣'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1265, "Data truncated for column 'doubanRate' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 87, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '30320371', 'tppMovieID': 1234116, 'movieName': '猫公主苏菲', 'directors': '潘智超/郭攀/钟声', 'writers': '李布衣', 'actors': '吟良犬/张帆/漆凯/绿绮', 'genre': '动画/冒险', 'area': ' 中国大陆', 'duration': 78, 'publishedDate': '2019-05-01', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-02 13:33:40,501 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,501 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,501 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,501 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,501 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,501 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,533 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,533 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,533 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,533 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,533 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,533 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:40,856 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-02 13:33:42,470 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:42,470 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:42,470 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:42,470 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:42,470 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:42,470 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:44,297 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:44,297 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:44,297 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:44,297 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:44,297 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:44,297 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:44,327 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 13:33:44,327 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 13:33:44,327 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 13:33:44,327 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 13:33:44,327 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 13:33:44,327 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 13:33:44,341 -  movie_spider.py[line:136] - INFO: get 19 boxOffice, named .
2020-05-02 13:33:44,341 -  movie_spider.py[line:136] - INFO: get 19 boxOffice, named .
2020-05-02 13:33:44,341 -  movie_spider.py[line:136] - INFO: get 19 boxOffice, named .
2020-05-02 13:33:44,341 -  movie_spider.py[line:136] - INFO: get 19 boxOffice, named .
2020-05-02 13:33:44,341 -  movie_spider.py[line:136] - INFO: get 19 boxOffice, named .
2020-05-02 13:33:44,341 -  movie_spider.py[line:136] - INFO: get 19 boxOffice, named .
2020-05-02 13:33:44,342 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:44,342 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:44,342 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:44,342 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:44,342 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:44,342 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:44,342 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:44,342 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:44,342 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:44,342 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:44,342 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:44,342 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:44,342 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:44,342 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:44,342 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:44,342 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:44,342 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:44,342 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:44,343 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:33:44,343 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:33:44,343 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:33:44,343 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:33:44,343 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:33:44,343 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:33:44,343 -  warnings.py[line:110] - WARNING: /home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py:561: SAWarning: Session's state has been changed on a non-active transaction - this state will be discarded.
  "Session's state has been changed on "

2020-05-02 13:33:44,343 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:44,990 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 13:33:44,997 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 13:33:44,998 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:44,998 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:44,998 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:44,998 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:44,998 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:44,998 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27040737/?suggest=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 13:33:45,030 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:45,030 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:45,030 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:45,030 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:45,030 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:45,030 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:45,032 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27040737
{'actors': '阿部宽/松岛菜菜子/沟端淳平/田中丽奈/木村绿子/乌丸节子/春风亭升太/音尾琢真/饭丰万理江/上杉祥三',
 'area': ' 日本',
 'dbMovieID': ['27040737'],
 'directors': '福泽克雄',
 'doubanRate': ['8.0'],
 'duration': [119],
 'genre': '剧情/悬疑',
 'movieName': ['祈祷落幕时 祈りの幕が下りる時'],
 'publishedDate': ['2018-01-27'],
 'rateCount': ['123814'],
 'tppMovieID': [1205909],
 'writers': '李正美/东野圭吾'}
2020-05-02 13:33:46,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:46,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:46,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:46,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:46,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:46,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:46,577 -  movie_spider.py[line:136] - INFO: get 20 boxOffice, named .
2020-05-02 13:33:46,577 -  movie_spider.py[line:136] - INFO: get 20 boxOffice, named .
2020-05-02 13:33:46,577 -  movie_spider.py[line:136] - INFO: get 20 boxOffice, named .
2020-05-02 13:33:46,577 -  movie_spider.py[line:136] - INFO: get 20 boxOffice, named .
2020-05-02 13:33:46,577 -  movie_spider.py[line:136] - INFO: get 20 boxOffice, named .
2020-05-02 13:33:46,577 -  movie_spider.py[line:136] - INFO: get 20 boxOffice, named .
2020-05-02 13:33:46,580 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:46,580 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:46,580 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:46,580 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:46,580 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:46,580 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:46,581 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:46,581 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:46,581 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:46,581 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:46,581 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:46,581 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:46,582 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:46,582 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:46,582 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:46,582 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:46,582 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:46,582 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:46,583 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:46,584 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:33:46,585 -  log.py[line:110] - INFO: {'movieID': 1229702, 'movieName': '青蛙王子历险记', 'seatRate': '13.1%', 'boxInfo': '14.85', 'boxRate': '<0.1%', 'releaseInfo': '上映28天', 'showInfo': 95, 'showRate': '<0.1%', 'splitBoxInfo': '14.81', 'splitSumBoxInfo': '1041.3', 'sumBoxInfo': '1097.7', 'showView': '22', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#20'}
2020-05-02 13:33:46,587 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:33:46,913 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:46,915 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:46,915 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:46,915 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:46,915 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:46,915 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:46,915 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 13:33:46,942 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:33:46,942 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:33:46,942 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:33:46,942 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:33:46,942 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:33:46,942 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:33:46,954 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 13:33:46,955 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-02 13:33:48,544 -  movie_spider.py[line:158] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 13:33:48,544 -  movie_spider.py[line:158] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 13:33:48,544 -  movie_spider.py[line:158] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 13:33:48,544 -  movie_spider.py[line:158] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 13:33:48,544 -  movie_spider.py[line:158] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 13:33:48,544 -  movie_spider.py[line:158] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 13:33:48,549 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,549 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,549 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,549 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,549 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,549 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,549 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:48,549 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:48,549 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:48,549 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:48,549 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:48,549 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:48,550 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,550 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,550 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,550 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,550 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:48,550 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:50,266 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:50,266 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:50,266 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:50,266 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:50,266 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:50,266 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:33:52,133 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:33:52,133 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:33:52,133 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:33:52,133 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:33:52,133 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:33:52,133 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:33:52,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,167 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 13:33:52,190 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 13:33:52,191 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-02 13:33:53,642 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,642 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,642 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,642 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,642 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,642 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,687 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216360'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 13:33:53,688 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,688 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,688 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,688 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,688 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,688 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,702 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,702 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,702 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,702 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,702 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,702 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,705 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216360'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 13:33:53,707 -  movie_spider.py[line:136] - INFO: get 21 boxOffice, named .
2020-05-02 13:33:53,707 -  movie_spider.py[line:136] - INFO: get 21 boxOffice, named .
2020-05-02 13:33:53,707 -  movie_spider.py[line:136] - INFO: get 21 boxOffice, named .
2020-05-02 13:33:53,707 -  movie_spider.py[line:136] - INFO: get 21 boxOffice, named .
2020-05-02 13:33:53,707 -  movie_spider.py[line:136] - INFO: get 21 boxOffice, named .
2020-05-02 13:33:53,707 -  movie_spider.py[line:136] - INFO: get 21 boxOffice, named .
2020-05-02 13:33:53,707 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:53,707 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:53,707 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:53,707 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:53,707 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:53,707 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:33:53,708 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:53,708 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:53,708 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:53,708 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:53,708 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:53,708 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:33:53,708 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:53,708 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:53,708 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:53,708 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:53,708 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:53,708 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:33:53,708 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:33:53,708 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:33:53,708 -  log.py[line:110] - INFO: {'movieID': 643506, 'movieName': '古镇画情', 'seatRate': '--', 'boxInfo': '14.69', 'boxRate': '<0.1%', 'releaseInfo': '展映', 'showInfo': 75, 'showRate': '<0.1%', 'splitBoxInfo': '14.67', 'splitSumBoxInfo': '1137.6', 'sumBoxInfo': '1140.4', 'showView': '48', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#21'}
2020-05-02 13:33:53,709 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:33:53,911 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:33:53,915 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 13:33:53,921 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-02 13:33:53,929 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-02 13:33:53,930 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,930 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,930 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,930 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,930 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,930 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:33:53,960 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,960 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,960 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,960 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,960 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,960 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:33:53,963 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216360'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 13:33:53,963 -  movie_spider.py[line:158] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 13:33:53,963 -  movie_spider.py[line:158] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 13:33:53,963 -  movie_spider.py[line:158] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 13:33:53,963 -  movie_spider.py[line:158] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 13:33:53,963 -  movie_spider.py[line:158] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 13:33:53,963 -  movie_spider.py[line:158] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 13:33:53,963 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,963 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,963 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,963 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,963 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,963 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,964 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:53,964 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:53,964 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:53,964 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:53,964 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:53,964 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:33:53,964 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,964 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,964 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,964 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,964 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:53,964 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:33:58,997 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:33:58,997 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:33:58,997 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:33:58,997 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:33:58,997 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:33:58,997 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:34:00,848 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:34:00,848 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:34:00,848 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:34:00,848 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:34:00,848 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:34:00,848 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 13:34:00,885 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:00,885 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:00,885 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:00,885 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:00,885 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:00,885 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:00,888 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216360'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 13:34:00,888 -  movie_spider.py[line:158] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 13:34:00,888 -  movie_spider.py[line:158] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 13:34:00,888 -  movie_spider.py[line:158] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 13:34:00,888 -  movie_spider.py[line:158] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 13:34:00,888 -  movie_spider.py[line:158] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 13:34:00,888 -  movie_spider.py[line:158] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 13:34:00,889 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:00,889 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:00,889 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:00,889 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:00,889 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:00,889 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:00,889 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:00,889 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:02,697 -  movie_spider.py[line:136] - INFO: get 22 boxOffice, named .
2020-05-02 13:34:02,697 -  movie_spider.py[line:136] - INFO: get 22 boxOffice, named .
2020-05-02 13:34:02,697 -  movie_spider.py[line:136] - INFO: get 22 boxOffice, named .
2020-05-02 13:34:02,697 -  movie_spider.py[line:136] - INFO: get 22 boxOffice, named .
2020-05-02 13:34:02,697 -  movie_spider.py[line:136] - INFO: get 22 boxOffice, named .
2020-05-02 13:34:02,697 -  movie_spider.py[line:136] - INFO: get 22 boxOffice, named .
2020-05-02 13:34:02,700 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:02,700 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:02,700 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:02,700 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:02,700 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:02,700 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:02,700 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:02,700 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:02,700 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:02,700 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:02,700 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:02,700 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:02,701 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:02,701 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:02,701 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:02,701 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:02,701 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:02,701 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:02,703 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:02,703 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:02,703 -  log.py[line:110] - INFO: {'movieID': 245881, 'movieName': '麦兜我和我妈妈', 'seatRate': '10.8%', 'boxInfo': '13.98', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 512, 'showRate': '0.1%', 'splitBoxInfo': '12.30', 'splitSumBoxInfo': '4624.7', 'sumBoxInfo': '4643.7', 'showView': '9', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#22'}
2020-05-02 13:34:02,705 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:02,868 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:02,873 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/)
2020-05-02 13:34:02,880 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-02 13:34:02,885 -  movie_spider.py[line:158] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 13:34:02,885 -  movie_spider.py[line:158] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 13:34:02,885 -  movie_spider.py[line:158] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 13:34:02,885 -  movie_spider.py[line:158] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 13:34:02,885 -  movie_spider.py[line:158] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 13:34:02,885 -  movie_spider.py[line:158] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 13:34:02,886 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,886 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,886 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,886 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,886 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,886 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,887 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:02,887 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:02,887 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:02,887 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:02,887 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:02,887 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:02,888 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,888 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,888 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,888 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,888 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:02,888 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:04,170 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,170 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,170 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,170 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,170 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,170 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,210 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,210 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,210 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,210 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,210 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,210 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,213 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :10759842
{'actors': '顾莉雅/朱文超/叶青青/王仲欣/丁汀/飞龙/龙泽',
 'area': ' 中国大陆',
 'dbMovieID': ['10759842'],
 'directors': '姚宇',
 'doubanRate': ['3.8'],
 'duration': [88],
 'genre': '剧情/音乐',
 'movieName': ['毕业那年'],
 'publishedDate': ['2012-09-21'],
 'rateCount': ['1972'],
 'tppMovieID': [836],
 'writers': '仧縯'}
2020-05-02 13:34:04,214 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,214 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,214 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,214 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,214 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,214 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 13:34:04,229 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,229 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,229 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,229 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,229 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,229 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:04,231 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :10759842
{'actors': '顾莉雅/朱文超/叶青青/王仲欣/丁汀/飞龙/龙泽',
 'area': ' 中国大陆',
 'dbMovieID': ['10759842'],
 'directors': '姚宇',
 'doubanRate': ['3.8'],
 'duration': [88],
 'genre': '剧情/音乐',
 'movieName': ['毕业那年'],
 'publishedDate': ['2012-09-21'],
 'rateCount': ['1972'],
 'tppMovieID': [836],
 'writers': '仧縯'}
2020-05-02 13:34:04,232 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:34:04,232 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:34:04,232 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:34:04,232 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:34:04,232 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:34:04,232 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 13:34:04,239 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:34:04,239 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:34:04,239 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:34:04,239 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:34:04,239 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:34:04,239 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 13:34:08,933 -  logstats.py[line:48] - INFO: Crawled 51 pages (at 22 pages/min), scraped 23 items (at 8 items/min)
2020-05-02 13:34:08,934 -  movie_spider.py[line:136] - INFO: get 23 boxOffice, named .
2020-05-02 13:34:08,934 -  movie_spider.py[line:136] - INFO: get 23 boxOffice, named .
2020-05-02 13:34:08,934 -  movie_spider.py[line:136] - INFO: get 23 boxOffice, named .
2020-05-02 13:34:08,934 -  movie_spider.py[line:136] - INFO: get 23 boxOffice, named .
2020-05-02 13:34:08,934 -  movie_spider.py[line:136] - INFO: get 23 boxOffice, named .
2020-05-02 13:34:08,934 -  movie_spider.py[line:136] - INFO: get 23 boxOffice, named .
2020-05-02 13:34:08,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:08,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:08,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:08,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:08,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:08,935 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:08,936 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:08,936 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:08,936 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:08,936 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:08,936 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:08,936 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:08,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:08,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:08,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:08,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:08,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:08,936 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:08,936 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:08,937 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:08,937 -  log.py[line:110] - INFO: {'movieID': 1213175, 'movieName': '在乎你', 'seatRate': '0.5%', 'boxInfo': '11.71', 'boxRate': '<0.1%', 'releaseInfo': '上映21天', 'showInfo': 28, 'showRate': '<0.1%', 'splitBoxInfo': '11.71', 'splitSumBoxInfo': '713.9', 'sumBoxInfo': '745.7', 'showView': '65', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#23'}
2020-05-02 13:34:08,938 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:09,218 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:09,225 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 13:34:09,232 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-02 13:34:09,233 -  movie_spider.py[line:158] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 13:34:09,233 -  movie_spider.py[line:158] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 13:34:09,233 -  movie_spider.py[line:158] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 13:34:09,233 -  movie_spider.py[line:158] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 13:34:09,233 -  movie_spider.py[line:158] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 13:34:09,233 -  movie_spider.py[line:158] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 13:34:09,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:09,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:09,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:09,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:09,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:09,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:09,235 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,235 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,235 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,235 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,235 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:09,235 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:10,812 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:34:10,812 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:34:10,812 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:34:10,812 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:34:10,812 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:34:10,812 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 13:34:10,852 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:10,852 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:10,852 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:10,852 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:10,852 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:10,852 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:10,854 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:10,854 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:10,854 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:10,854 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:10,854 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:10,854 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:10,855 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:10,855 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:10,855 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:10,855 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:10,855 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:10,855 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:10,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:10,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:10,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:10,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:10,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:10,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:10,855 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:10,856 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:34:10,856 -  log.py[line:110] - INFO: {'dbMovieID': '30230160', 'tppMovieID': 1239281, 'movieName': '港珠澳大桥', 'directors': '闫东', 'writers': '李凯/张艺宰', 'actors': '李立宏', 'genre': '纪录片', 'area': ' 中国大陆', 'duration': 70, 'publishedDate': '2019-05-01', 'rateCount': '3710', 'doubanRate': '6.7'}
2020-05-02 13:34:10,856 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:11,072 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5>
None
2020-05-02 13:34:11,080 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:34:11,080 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:34:11,080 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:34:11,080 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:34:11,080 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:34:11,080 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 13:34:11,887 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88> (referer: https://movie.douban.com/)
2020-05-02 13:34:13,471 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:13,471 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:13,471 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:13,471 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:13,471 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:13,471 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:13,498 -  movie_spider.py[line:136] - INFO: get 24 boxOffice, named .
2020-05-02 13:34:13,498 -  movie_spider.py[line:136] - INFO: get 24 boxOffice, named .
2020-05-02 13:34:13,498 -  movie_spider.py[line:136] - INFO: get 24 boxOffice, named .
2020-05-02 13:34:13,498 -  movie_spider.py[line:136] - INFO: get 24 boxOffice, named .
2020-05-02 13:34:13,498 -  movie_spider.py[line:136] - INFO: get 24 boxOffice, named .
2020-05-02 13:34:13,498 -  movie_spider.py[line:136] - INFO: get 24 boxOffice, named .
2020-05-02 13:34:13,500 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,500 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,500 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,500 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,500 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,500 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,500 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:13,500 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:13,500 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:13,500 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:13,500 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:13,500 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:13,501 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,501 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,501 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,501 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,501 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,501 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,502 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:13,502 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:13,502 -  log.py[line:110] - INFO: {'movieID': 248906, 'movieName': '流浪地球', 'seatRate': '21.1%', 'boxInfo': '10.61', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 183, 'showRate': '<0.1%', 'splitBoxInfo': '9.76', 'splitSumBoxInfo': '435400.0', 'sumBoxInfo': '468000.0', 'showView': '18', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#24'}
2020-05-02 13:34:13,504 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:13,645 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:13,651 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/)
2020-05-02 13:34:13,652 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:13,652 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:13,652 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:13,652 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:13,652 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:13,652 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30288751/?suggest=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 13:34:13,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,684 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,688 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,688 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,688 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,688 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,688 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,688 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:13,688 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:13,688 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:13,688 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:13,688 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:13,688 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:13,688 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:13,689 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,689 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,689 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,689 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,689 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,689 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:13,689 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:13,689 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:34:13,690 -  log.py[line:110] - INFO: {'dbMovieID': '30288751', 'tppMovieID': 1229702, 'movieName': '青蛙王子历险记', 'directors': '蒋叶峰', 'writers': '夏晋', 'actors': '', 'genre': '喜剧/动画/冒险', 'area': ' 中国大陆', 'duration': 82, 'publishedDate': '2019-04-05', 'rateCount': '0', 'doubanRate': ''}
2020-05-02 13:34:13,690 -  log.py[line:110] - INFO: ROLLBACK
2020-05-02 13:34:13,691 -  scraper.py[line:236] - ERROR: Error processing {'actors': '',
 'area': ' 中国大陆',
 'dbMovieID': ['30288751'],
 'directors': '蒋叶峰',
 'doubanRate': [''],
 'duration': [82],
 'genre': '喜剧/动画/冒险',
 'movieName': ['青蛙王子历险记'],
 'publishedDate': ['2019-04-05'],
 'rateCount': ['0'],
 'tppMovieID': [1229702],
 'writers': '夏晋'}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1265, "Data truncated for column 'doubanRate' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 87, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '30288751', 'tppMovieID': 1229702, 'movieName': '青蛙王子历险记', 'directors': '蒋叶峰', 'writers': '夏晋', 'actors': '', 'genre': '喜剧/动画/冒险', 'area': ' 中国大陆', 'duration': 82, 'publishedDate': '2019-04-05', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-02 13:34:13,692 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:13,692 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:13,692 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:13,692 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:13,692 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:13,692 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 13:34:13,707 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,707 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,707 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,707 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,707 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,707 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:13,709 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26731376
{'actors': '纳威尔·佩雷兹·毕斯卡亚特/阿尔贝·杜邦泰尔/罗兰·拉斐特/尼尔斯·阿贺斯图普/艾米莉·德奎恩/梅兰尼·蒂埃里/埃洛伊兹·巴尔斯特/菲利普·乌禅/安德烈·马尔孔/米歇尔·维耶尔莫',
 'area': ' 法国 / 加拿大',
 'dbMovieID': ['26731376'],
 'directors': '阿尔贝·杜邦泰尔',
 'doubanRate': ['8.1'],
 'duration': [117],
 'genre': '喜剧/战争/犯罪',
 'movieName': ['天上再见 Au revoir là-haut'],
 'publishedDate': ['2017-10-25'],
 'rateCount': ['27396'],
 'tppMovieID': [476263],
 'writers': '阿尔贝·杜邦泰尔/皮耶尔·勒迈特'}
2020-05-02 13:34:14,472 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:14,472 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:14,472 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:14,472 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:14,472 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:14,472 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:14,503 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-02 13:34:18,386 -  movie_spider.py[line:158] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 13:34:18,386 -  movie_spider.py[line:158] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 13:34:18,386 -  movie_spider.py[line:158] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 13:34:18,386 -  movie_spider.py[line:158] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 13:34:18,386 -  movie_spider.py[line:158] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 13:34:18,386 -  movie_spider.py[line:158] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 13:34:18,392 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 13:34:18,392 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 13:34:18,392 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 13:34:18,392 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 13:34:18,392 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 13:34:18,392 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 13:34:18,393 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:18,393 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:18,393 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:18,393 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:18,393 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:18,393 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:18,394 -  movie_spider.py[line:176] - ERROR: url wrong that url = 
2020-05-02 13:34:18,394 -  movie_spider.py[line:176] - ERROR: url wrong that url = 
2020-05-02 13:34:18,394 -  movie_spider.py[line:176] - ERROR: url wrong that url = 
2020-05-02 13:34:18,394 -  movie_spider.py[line:176] - ERROR: url wrong that url = 
2020-05-02 13:34:18,394 -  movie_spider.py[line:176] - ERROR: url wrong that url = 
2020-05-02 13:34:18,394 -  movie_spider.py[line:176] - ERROR: url wrong that url = 
2020-05-02 13:34:18,400 -  movie_spider.py[line:136] - INFO: get 25 boxOffice, named .
2020-05-02 13:34:18,400 -  movie_spider.py[line:136] - INFO: get 25 boxOffice, named .
2020-05-02 13:34:18,400 -  movie_spider.py[line:136] - INFO: get 25 boxOffice, named .
2020-05-02 13:34:18,400 -  movie_spider.py[line:136] - INFO: get 25 boxOffice, named .
2020-05-02 13:34:18,400 -  movie_spider.py[line:136] - INFO: get 25 boxOffice, named .
2020-05-02 13:34:18,400 -  movie_spider.py[line:136] - INFO: get 25 boxOffice, named .
2020-05-02 13:34:18,405 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:18,405 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:18,405 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:18,405 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:18,405 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:18,405 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:18,406 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:18,406 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:18,406 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:18,406 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:18,406 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:18,406 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:18,407 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:18,407 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:18,407 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:18,407 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:18,407 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:18,407 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:18,408 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:34:18,408 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:34:18,408 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:34:18,408 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:34:18,408 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:34:18,408 -  pipelines.py[line:89] - ERROR: something wrong occur, session rollback
2020-05-02 13:34:18,410 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:18,413 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/)
2020-05-02 13:34:18,422 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:18,422 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:18,422 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:18,422 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:18,422 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:18,422 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/4006324/?suggest=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 13:34:18,432 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:18,432 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:18,432 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:18,432 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:18,432 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:18,432 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:18,435 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :4006324
{'actors': '韩夫一',
 'area': ' 中国',
 'dbMovieID': ['4006324'],
 'directors': '',
 'doubanRate': [''],
 'duration': [0],
 'genre': '剧情',
 'movieName': ['古镇画情'],
 'publishedDate': [''],
 'rateCount': ['0'],
 'tppMovieID': [643506],
 'writers': ''}
2020-05-02 13:34:18,540 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:18,540 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:18,540 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:18,540 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:18,540 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:18,540 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:18,567 -  movie_spider.py[line:158] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 13:34:18,567 -  movie_spider.py[line:158] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 13:34:18,567 -  movie_spider.py[line:158] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 13:34:18,567 -  movie_spider.py[line:158] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 13:34:18,567 -  movie_spider.py[line:158] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 13:34:18,567 -  movie_spider.py[line:158] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 13:34:18,568 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,568 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,568 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,568 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,568 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,568 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,569 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:34:18,569 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:34:18,569 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:34:18,569 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:34:18,569 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:34:18,569 -  movie_spider.py[line:164] - INFO: len of text is 6
2020-05-02 13:34:18,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:18,569 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:19,855 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:19,855 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:19,855 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:19,855 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:19,855 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:19,855 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:21,785 -  movie_spider.py[line:136] - INFO: get 26 boxOffice, named .
2020-05-02 13:34:21,785 -  movie_spider.py[line:136] - INFO: get 26 boxOffice, named .
2020-05-02 13:34:21,785 -  movie_spider.py[line:136] - INFO: get 26 boxOffice, named .
2020-05-02 13:34:21,785 -  movie_spider.py[line:136] - INFO: get 26 boxOffice, named .
2020-05-02 13:34:21,785 -  movie_spider.py[line:136] - INFO: get 26 boxOffice, named .
2020-05-02 13:34:21,785 -  movie_spider.py[line:136] - INFO: get 26 boxOffice, named .
2020-05-02 13:34:21,788 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:21,788 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:21,788 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:21,788 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:21,788 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:21,788 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:21,789 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:21,789 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:21,789 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:21,789 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:21,789 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:21,789 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:21,791 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:21,791 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:21,791 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:21,791 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:21,791 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:21,791 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:21,792 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:21,793 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:21,793 -  log.py[line:110] - INFO: {'movieID': 1167831, 'movieName': '波西米亚狂想曲', 'seatRate': '23.2%', 'boxInfo': '5.80', 'boxRate': '<0.1%', 'releaseInfo': '上映42天', 'showInfo': 71, 'showRate': '<0.1%', 'splitBoxInfo': '5.34', 'splitSumBoxInfo': '8939.8', 'sumBoxInfo': '9864.5', 'showView': '20', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#26'}
2020-05-02 13:34:21,795 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:21,901 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:21,905 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/)
2020-05-02 13:34:21,907 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,907 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,907 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,907 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,907 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,907 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,976 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,976 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,976 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,976 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,976 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:21,976 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:23,227 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:23,227 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:23,227 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:23,227 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:23,227 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:23,227 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:23,232 -  movie_spider.py[line:158] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 13:34:23,232 -  movie_spider.py[line:158] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 13:34:23,232 -  movie_spider.py[line:158] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 13:34:23,232 -  movie_spider.py[line:158] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 13:34:23,232 -  movie_spider.py[line:158] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 13:34:23,232 -  movie_spider.py[line:158] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 13:34:23,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,234 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:23,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:23,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:23,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:23,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:23,235 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:23,236 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,236 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,236 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,236 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,236 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:23,236 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:25,157 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:25,157 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:25,157 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:25,157 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:25,157 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:25,157 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:25,187 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:25,187 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:25,187 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:25,187 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:25,187 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:25,187 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 13:34:25,201 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:25,201 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:25,201 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:25,201 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:25,201 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:25,201 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:26,843 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:26,843 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:26,843 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:26,843 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:26,843 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:26,843 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:26,850 -  movie_spider.py[line:136] - INFO: get 27 boxOffice, named .
2020-05-02 13:34:26,850 -  movie_spider.py[line:136] - INFO: get 27 boxOffice, named .
2020-05-02 13:34:26,850 -  movie_spider.py[line:136] - INFO: get 27 boxOffice, named .
2020-05-02 13:34:26,850 -  movie_spider.py[line:136] - INFO: get 27 boxOffice, named .
2020-05-02 13:34:26,850 -  movie_spider.py[line:136] - INFO: get 27 boxOffice, named .
2020-05-02 13:34:26,850 -  movie_spider.py[line:136] - INFO: get 27 boxOffice, named .
2020-05-02 13:34:26,853 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:26,853 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:26,853 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:26,853 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:26,853 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:26,853 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:26,854 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:26,854 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:26,854 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:26,854 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:26,854 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:26,854 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:26,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:26,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:26,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:26,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:26,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:26,855 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:26,856 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:26,857 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:26,858 -  log.py[line:110] - INFO: {'movieID': 883196, 'movieName': '一个母亲的复仇', 'seatRate': '98.7%', 'boxInfo': '5.61', 'boxRate': '<0.1%', 'releaseInfo': '点映', 'showInfo': 8, 'showRate': '<0.1%', 'splitBoxInfo': '5.18', 'splitSumBoxInfo': '6.5', 'sumBoxInfo': '6.9', 'showView': '171', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#27'}
2020-05-02 13:34:26,860 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:27,014 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:27,021 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-02 13:34:27,028 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-02 13:34:27,029 -  movie_spider.py[line:158] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 13:34:27,029 -  movie_spider.py[line:158] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 13:34:27,029 -  movie_spider.py[line:158] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 13:34:27,029 -  movie_spider.py[line:158] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 13:34:27,029 -  movie_spider.py[line:158] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 13:34:27,029 -  movie_spider.py[line:158] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 13:34:27,029 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,029 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,029 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,029 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,029 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,029 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,030 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:27,030 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:27,030 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:27,030 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:27,030 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:27,030 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:27,030 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,030 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,030 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,030 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,030 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:27,030 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:28,441 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:28,441 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:28,441 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:28,441 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:28,441 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:28,441 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 13:34:28,469 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:28,469 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:28,469 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:28,469 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:28,469 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:28,469 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 13:34:30,618 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-02 13:34:30,626 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/)
2020-05-02 13:34:30,632 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-02 13:34:30,655 -  movie_spider.py[line:136] - INFO: get 28 boxOffice, named .
2020-05-02 13:34:30,655 -  movie_spider.py[line:136] - INFO: get 28 boxOffice, named .
2020-05-02 13:34:30,655 -  movie_spider.py[line:136] - INFO: get 28 boxOffice, named .
2020-05-02 13:34:30,655 -  movie_spider.py[line:136] - INFO: get 28 boxOffice, named .
2020-05-02 13:34:30,655 -  movie_spider.py[line:136] - INFO: get 28 boxOffice, named .
2020-05-02 13:34:30,655 -  movie_spider.py[line:136] - INFO: get 28 boxOffice, named .
2020-05-02 13:34:30,656 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:30,656 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:30,656 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:30,656 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:30,656 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:30,656 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:30,656 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:30,656 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:30,656 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:30,656 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:30,656 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:30,656 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:30,657 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:30,657 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:30,657 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:30,657 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:30,657 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:30,657 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:30,657 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:30,657 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:30,658 -  log.py[line:110] - INFO: {'movieID': 1217701, 'movieName': '九克拉战栗', 'seatRate': '6.1%', 'boxInfo': '4.80', 'boxRate': '<0.1%', 'releaseInfo': '重映3天', 'showInfo': 471, 'showRate': '0.1%', 'splitBoxInfo': '4.36', 'splitSumBoxInfo': '23.5', 'sumBoxInfo': '25.4', 'showView': '4', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#28'}
2020-05-02 13:34:30,658 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:30,788 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:30,789 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,789 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,789 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,789 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,789 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,789 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,820 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,820 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,820 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,820 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,820 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,820 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,823 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4338'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-05-02 13:34:30,823 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,823 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,823 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,823 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,823 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,823 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:30,837 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,837 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,837 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,837 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,837 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,837 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:30,838 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4338'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-05-02 13:34:30,974 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87> (referer: https://movie.douban.com/)
2020-05-02 13:34:33,781 -  movie_spider.py[line:158] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 13:34:33,781 -  movie_spider.py[line:158] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 13:34:33,781 -  movie_spider.py[line:158] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 13:34:33,781 -  movie_spider.py[line:158] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 13:34:33,781 -  movie_spider.py[line:158] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 13:34:33,781 -  movie_spider.py[line:158] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 13:34:33,785 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,785 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,785 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,785 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,785 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,785 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,786 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:33,786 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:33,786 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:33,786 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:33,786 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:33,786 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:33,788 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,788 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,788 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,788 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,788 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:33,788 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:35,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:35,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:35,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:35,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:35,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:35,034 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26266893/?suggest=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 13:34:35,079 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,079 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,079 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,079 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,079 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,079 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,082 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26266893
{'actors': '屈楚萧/吴京/李光洁/吴孟达/赵今麦/隋凯/屈菁菁/张亦驰/杨皓宇/阿尔卡基·沙罗格拉茨基',
 'area': ' 中国大陆',
 'dbMovieID': ['26266893'],
 'directors': '郭帆',
 'doubanRate': ['7.9'],
 'duration': [125],
 'genre': '科幻/冒险/灾难',
 'movieName': ['流浪地球'],
 'publishedDate': ['2019-02-05'],
 'rateCount': ['1518326'],
 'tppMovieID': [248906],
 'writers': '龚格尔/严东旭/郭帆/叶俊策/杨治学/吴荑/叶濡畅/沈晶晶/刘慈欣'}
2020-05-02 13:34:35,082 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:35,082 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:35,082 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:35,082 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:35,082 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:35,082 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:35,096 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,096 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,096 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,096 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,096 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,096 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:35,099 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4338'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-05-02 13:34:35,100 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:35,100 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:35,100 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:35,100 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:35,100 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:35,100 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 13:34:35,108 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:35,108 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:35,108 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:35,108 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:35,108 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:35,108 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:35,114 -  movie_spider.py[line:136] - INFO: get 29 boxOffice, named .
2020-05-02 13:34:35,114 -  movie_spider.py[line:136] - INFO: get 29 boxOffice, named .
2020-05-02 13:34:35,114 -  movie_spider.py[line:136] - INFO: get 29 boxOffice, named .
2020-05-02 13:34:35,114 -  movie_spider.py[line:136] - INFO: get 29 boxOffice, named .
2020-05-02 13:34:35,114 -  movie_spider.py[line:136] - INFO: get 29 boxOffice, named .
2020-05-02 13:34:35,114 -  movie_spider.py[line:136] - INFO: get 29 boxOffice, named .
2020-05-02 13:34:35,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:35,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:35,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:35,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:35,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:35,115 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:35,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:35,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:35,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:35,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:35,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:35,115 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:35,115 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:35,115 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:35,115 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:35,115 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:35,115 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:35,115 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:35,116 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:35,116 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:35,116 -  log.py[line:110] - INFO: {'movieID': 342568, 'movieName': '诡梦凶铃', 'seatRate': '6.6%', 'boxInfo': '4.28', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 11, 'showRate': '<0.1%', 'splitBoxInfo': '4.28', 'splitSumBoxInfo': '1125.3', 'sumBoxInfo': '1125.3', 'showView': '147', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#29'}
2020-05-02 13:34:35,117 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:35,247 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:35,255 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-02 13:34:35,261 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/)
2020-05-02 13:34:38,061 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:38,061 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:38,061 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:38,061 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:38,061 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:38,061 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:38,091 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-02 13:34:38,093 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-02 13:34:38,093 -  movie_spider.py[line:158] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 13:34:38,093 -  movie_spider.py[line:158] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 13:34:38,093 -  movie_spider.py[line:158] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 13:34:38,093 -  movie_spider.py[line:158] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 13:34:38,093 -  movie_spider.py[line:158] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 13:34:38,093 -  movie_spider.py[line:158] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 13:34:38,094 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:38,094 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:38,094 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:38,094 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:38,094 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:38,094 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:38,094 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:38,094 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:39,164 -  movie_spider.py[line:136] - INFO: get 30 boxOffice, named .
2020-05-02 13:34:39,164 -  movie_spider.py[line:136] - INFO: get 30 boxOffice, named .
2020-05-02 13:34:39,164 -  movie_spider.py[line:136] - INFO: get 30 boxOffice, named .
2020-05-02 13:34:39,164 -  movie_spider.py[line:136] - INFO: get 30 boxOffice, named .
2020-05-02 13:34:39,164 -  movie_spider.py[line:136] - INFO: get 30 boxOffice, named .
2020-05-02 13:34:39,164 -  movie_spider.py[line:136] - INFO: get 30 boxOffice, named .
2020-05-02 13:34:39,167 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:39,167 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:39,167 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:39,167 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:39,167 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:39,167 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:39,168 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:39,168 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:39,168 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:39,168 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:39,168 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:39,168 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-02 13:34:39,169 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:39,169 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:39,169 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:39,169 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:39,169 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:39,169 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:39,170 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:39,171 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-02 13:34:39,171 -  log.py[line:110] - INFO: {'movieID': 1216383, 'movieName': '比悲伤更悲伤的故事', 'seatRate': '12.6%', 'boxInfo': '4.02', 'boxRate': '<0.1%', 'releaseInfo': '上映50天', 'showInfo': 193, 'showRate': '<0.1%', 'splitBoxInfo': '3.68', 'splitSumBoxInfo': '85800.0', 'sumBoxInfo': '95700.0', 'showView': '8', 'crawlDate': '2019-05-02', 'yearRate': '2019-05-02#30'}
2020-05-02 13:34:39,173 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:39,410 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502>
None
2020-05-02 13:34:39,437 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83> (referer: https://movie.douban.com/)
2020-05-02 13:34:39,442 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:39,442 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:39,442 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:39,442 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:39,442 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:39,442 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27185558/?suggest=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 13:34:39,458 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,458 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,458 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,458 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,458 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,458 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,460 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27185558
{'actors': '俞飞鸿/大泽隆夫/木下彩音/卢洋洋/前田公辉/星由里子',
 'area': ' 中国大陆 / 日本',
 'dbMovieID': ['27185558'],
 'directors': '毕国智',
 'doubanRate': ['5.7'],
 'duration': [120],
 'genre': '爱情',
 'movieName': ['在乎你'],
 'publishedDate': ['2019-04-12'],
 'rateCount': ['4338'],
 'tppMovieID': [1213175],
 'writers': '毕国智/贾佳薇/张莉莉'}
2020-05-02 13:34:39,460 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:39,460 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:39,460 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:39,460 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:39,460 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:39,460 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/30479973/?suggest=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 13:34:39,472 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,472 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,472 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,472 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,472 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,472 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:39,474 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30479973
{'actors': '黄磊/闫妮/韩童生/崔新琴/沙俊伯/丁嘉丽/冯嘉怡/沙溢/果靖霖/胡可',
 'area': ' 中国大陆',
 'dbMovieID': ['30479973'],
 'directors': '吴楠',
 'doubanRate': ['5.8'],
 'duration': [91],
 'genre': '剧情/家庭',
 'movieName': ['狗眼看人心'],
 'publishedDate': ['2019-04-20'],
 'rateCount': ['6299'],
 'tppMovieID': [1263355],
 'writers': '吴楠'}
2020-05-02 13:34:40,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:40,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:40,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:40,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:40,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:40,181 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:40,212 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:40,212 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:40,212 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:40,212 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:40,212 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:40,212 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 13:34:40,232 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:40,232 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:40,232 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:40,232 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:40,232 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:40,232 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:40,235 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:40,235 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:40,235 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:40,235 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:40,235 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:40,235 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:40,235 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:40,235 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:40,235 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:40,235 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:40,235 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:40,235 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:40,236 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:40,236 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:40,236 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:40,236 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:40,236 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:40,236 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:40,236 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:40,236 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:34:40,236 -  log.py[line:110] - INFO: {'dbMovieID': '5300054', 'tppMovieID': 1167831, 'movieName': '波西米亚狂想曲 Bohemian Rhapsody', 'directors': '布莱恩·辛格', 'writers': '安东尼·麦卡滕/皮特·摩根', 'actors': '拉米·马雷克/本·哈迪/约瑟夫·梅泽罗/格威利姆·李/艾伦·里奇/露西·宝通/艾丹·吉伦/汤姆·霍兰德/麦克·梅尔斯/阿隆·麦克卡斯克', 'genre': '剧情/传记/同性/音乐', 'area': ' 英国 / 美国', 'duration': 135, 'publishedDate': '2018-11-02', 'rateCount': '399442', 'doubanRate': '8.7'}
2020-05-02 13:34:40,237 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:40,386 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2>
None
2020-05-02 13:34:40,387 -  movie_spider.py[line:158] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 13:34:40,387 -  movie_spider.py[line:158] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 13:34:40,387 -  movie_spider.py[line:158] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 13:34:40,387 -  movie_spider.py[line:158] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 13:34:40,387 -  movie_spider.py[line:158] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 13:34:40,387 -  movie_spider.py[line:158] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 13:34:40,388 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,388 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,388 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,388 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,388 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,388 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,389 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:40,389 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:40,389 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:40,389 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:40,389 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:40,389 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:40,390 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,390 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,390 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,390 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,390 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:40,390 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:44,881 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/)
2020-05-02 13:34:44,887 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87> (referer: https://movie.douban.com/)
2020-05-02 13:34:46,224 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:46,224 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:46,224 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:46,224 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:46,224 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:46,224 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 13:34:46,261 -  movie_spider.py[line:158] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 13:34:46,261 -  movie_spider.py[line:158] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 13:34:46,261 -  movie_spider.py[line:158] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 13:34:46,261 -  movie_spider.py[line:158] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 13:34:46,261 -  movie_spider.py[line:158] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 13:34:46,261 -  movie_spider.py[line:158] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 13:34:46,261 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,261 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,261 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,261 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,261 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,261 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,261 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:46,261 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:46,261 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:46,261 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:46,261 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:46,261 -  movie_spider.py[line:164] - INFO: len of text is 1
2020-05-02 13:34:46,262 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,262 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,262 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,262 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,262 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:46,262 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:47,761 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:47,761 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:47,761 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:47,761 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:47,761 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:47,761 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 13:34:47,792 -  movie_spider.py[line:158] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 13:34:47,792 -  movie_spider.py[line:158] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 13:34:47,792 -  movie_spider.py[line:158] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 13:34:47,792 -  movie_spider.py[line:158] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 13:34:47,792 -  movie_spider.py[line:158] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 13:34:47,792 -  movie_spider.py[line:158] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 13:34:47,792 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,792 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,792 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,792 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,792 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,792 -  movie_spider.py[line:163] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,792 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:34:47,792 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:34:47,792 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:34:47,792 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:34:47,792 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:34:47,792 -  movie_spider.py[line:164] - INFO: len of text is 2
2020-05-02 13:34:47,793 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,793 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,793 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,793 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,793 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:47,793 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:49,775 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:49,775 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:49,775 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:49,775 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:49,775 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:49,775 -  movie_spider.py[line:178] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:49,778 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:49,778 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:49,778 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:49,778 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:49,778 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:49,778 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 13:34:49,812 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:49,812 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:49,812 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:49,812 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:49,812 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:49,812 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:49,815 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:49,815 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:49,815 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:49,815 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:49,815 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:49,815 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:49,815 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:49,815 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:49,815 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:49,815 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:49,815 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:49,815 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:49,815 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:49,815 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:49,815 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:49,815 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:49,815 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:49,815 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:49,816 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:49,816 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:34:49,816 -  log.py[line:110] - INFO: {'dbMovieID': '26996734', 'tppMovieID': 883196, 'movieName': '一个母亲的复仇 Mom', 'directors': '拉维·德耶瓦尔', 'writers': '吉里什·科赫利/拉维·德耶瓦尔', 'actors': '诗丽黛玮/阿克夏耶·坎纳/萨佳·阿里/阿德南·西德奎/纳瓦祖丁·席迪圭/乔伊·波德拉尼', 'genre': '剧情/犯罪', 'area': ' 印度', 'duration': 146, 'publishedDate': '2017-07-07', 'rateCount': '73166', 'doubanRate': '6.8'}
2020-05-02 13:34:49,817 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:49,966 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87>
None
2020-05-02 13:34:49,968 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,968 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,968 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,968 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,968 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,968 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,994 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,994 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,994 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,994 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,994 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:49,994 -  middlewares.py[line:146] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 13:34:50,009 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83> (referer: https://movie.douban.com/)
2020-05-02 13:34:50,011 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-02 13:34:53,307 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/)
2020-05-02 13:34:53,313 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/)
2020-05-02 13:34:53,324 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:53,324 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:53,324 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:53,324 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:53,324 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:53,324 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 13:34:53,343 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,343 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,343 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,343 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,343 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,343 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,345 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,345 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,345 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,345 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,345 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,345 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,345 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,345 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,345 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,345 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,345 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,345 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,345 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,345 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,345 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,345 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,345 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,345 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,346 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:53,346 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:34:53,346 -  log.py[line:110] - INFO: {'dbMovieID': '26582780', 'tppMovieID': 342568, 'movieName': '诡梦凶铃', 'directors': '邓安东', 'writers': '邓安东', 'actors': '方力申/李斯丹妮/何映桥/王馨彤/刘小东', 'genre': '犯罪/悬疑/惊悚', 'area': ' 中国大陆', 'duration': 90, 'publishedDate': '2016-09-23', 'rateCount': '534', 'doubanRate': '2.4'}
2020-05-02 13:34:53,347 -  log.py[line:110] - INFO: COMMIT
2020-05-02 13:34:53,545 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26582780/?suggest=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83>
None
2020-05-02 13:34:53,545 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:53,545 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:53,545 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:53,545 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:53,545 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:53,545 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 13:34:53,576 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,576 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,576 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,576 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,576 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,576 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:53,579 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,579 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,579 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,579 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,579 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,579 -  pipelines.py[line:54] - INFO: item is new
2020-05-02 13:34:53,580 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,580 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,580 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,580 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,580 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,580 -  pipelines.py[line:76] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-02 13:34:53,580 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,580 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,580 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,580 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,580 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,580 -  pipelines.py[line:85] - INFO: insert database finished
2020-05-02 13:34:53,581 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-02 13:34:53,581 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-02 13:34:53,581 -  log.py[line:110] - INFO: {'dbMovieID': '26989671', 'tppMovieID': 1217701, 'movieName': '九克拉战栗', 'directors': '林峻兆', 'writers': '', 'actors': '付然/于非/陆妍淇/鞠帛展', 'genre': '悬疑', 'area': ' 中国大陆', 'duration': 86, 'publishedDate': '2019-12-18', 'rateCount': '0', 'doubanRate': ''}
2020-05-02 13:34:53,582 -  log.py[line:110] - INFO: ROLLBACK
2020-05-02 13:34:53,583 -  scraper.py[line:236] - ERROR: Error processing {'actors': '付然/于非/陆妍淇/鞠帛展',
 'area': ' 中国大陆',
 'dbMovieID': ['26989671'],
 'directors': '林峻兆',
 'doubanRate': [''],
 'duration': [86],
 'genre': '悬疑',
 'movieName': ['九克拉战栗'],
 'publishedDate': ['2019-12-18'],
 'rateCount': ['0'],
 'tppMovieID': [1217701],
 'writers': ''}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1265, "Data truncated for column 'doubanRate' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 87, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1265, "Data truncated for column 'doubanRate' at row 1")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '26989671', 'tppMovieID': 1217701, 'movieName': '九克拉战栗', 'directors': '林峻兆', 'writers': '', 'actors': '付然/于非/陆妍淇/鞠帛展', 'genre': '悬疑', 'area': ' 中国大陆', 'duration': 86, 'publishedDate': '2019-12-18', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-02 13:34:56,819 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,819 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,819 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,819 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,819 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,819 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,856 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,856 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,856 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,856 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,856 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,856 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,860 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3805946
{'actors': '权相宇/李凡秀/李宝英/郑爱延/李瀚伟/申贤俊/池大汉/杨知元/金正碧/金景龙',
 'area': ' 韩国',
 'dbMovieID': ['3805946'],
 'directors': '元泰渊',
 'doubanRate': ['7.7'],
 'duration': [105],
 'genre': '爱情',
 'movieName': ['比悲伤更悲伤的故事 슬픔보다 더 슬픈 이야기'],
 'publishedDate': ['2009-03-12'],
 'rateCount': ['83025'],
 'tppMovieID': [1216383],
 'writers': '元泰渊'}
2020-05-02 13:34:56,861 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,861 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,861 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,861 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,861 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,861 -  movie_spider.py[line:184] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 13:34:56,875 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,875 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,875 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,875 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,875 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,875 -  movie_spider.py[line:195] - INFO: len of movie info = 13
2020-05-02 13:34:56,877 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27624661
{'actors': '陈意涵/刘以豪/张书豪/陈庭妮/吴映洁/禾浩辰/游大庆/石知田/黄丽玲/姚爱宁',
 'area': ' 中国台湾',
 'dbMovieID': ['27624661'],
 'directors': '林孝谦',
 'doubanRate': ['4.8'],
 'duration': [105],
 'genre': '爱情',
 'movieName': ['比悲伤更悲伤的故事 比悲傷更悲傷的故事'],
 'publishedDate': ['2018-11-30'],
 'rateCount': ['142533'],
 'tppMovieID': [1216383],
 'writers': '吕安弦'}
2020-05-02 13:34:59,378 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-05-02 13:34:59,387 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 91511,
 'downloader/request_count': 75,
 'downloader/request_method_count/GET': 75,
 'downloader/response_bytes': 1069906,
 'downloader/response_count': 75,
 'downloader/response_status_count/200': 75,
 'elapsed_time_seconds': 173.777653,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 2, 5, 34, 59, 386244),
 'item_dropped_count': 36,
 'item_dropped_reasons_count/DropItem': 36,
 'item_scraped_count': 35,
 'log_count/ERROR': 72,
 'log_count/WARNING': 37,
 'memusage/max': 125276160,
 'memusage/startup': 73547776,
 'request_depth_max': 2,
 'response_received_count': 75,
 'scheduler/dequeued': 75,
 'scheduler/dequeued/memory': 75,
 'scheduler/enqueued': 75,
 'scheduler/enqueued/memory': 75,
 'start_time': datetime.datetime(2020, 5, 2, 5, 32, 5, 608591)}
2020-05-02 13:34:59,387 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-05-02 20:50:42,181 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-02 20:50:42,294 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-02 20:50:42,298 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-02 20:50:42,310 -  telnet.py[line:60] - INFO: Telnet Password: f90e15d8b95626d0
2020-05-02 20:50:42,320 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-02 20:50:42,553 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-02 20:50:42,553 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-02 20:50:42,558 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.RefererMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-02 20:50:42,561 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-02 20:50:42,692 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-02 20:50:42,692 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-02 20:50:42,724 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.ItemPipeline', 'movie.pipelines.MySQLPipeline']
2020-05-02 20:50:42,725 -  engine.py[line:257] - INFO: Spider opened
2020-05-02 20:50:42,727 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-02 20:50:42,729 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6023
2020-05-02 20:50:42,732 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 20:50:42,732 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-02 20:50:42,734 -  middlewares.py[line:144] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502 has been crawled, drop it
2020-05-02 20:50:42,734 -  middlewares.py[line:144] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502 has been crawled, drop it
2020-05-02 20:50:42,905 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502> (referer: https://movie.douban.com/)
2020-05-02 20:50:43,587 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 20:50:43,587 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190502
2020-05-02 20:50:43,593 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-02 20:50:43,593 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-02 20:50:43,598 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#1
{'boxInfo': ['34056.84'],
 'boxRate': ['81.4%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [248172],
 'movieName': ['复仇者联盟4：终局之战'],
 'releaseInfo': ['上映9天'],
 'seatRate': ['27.2%'],
 'showInfo': [193371],
 'showRate': ['60.9%'],
 'showView': ['38'],
 'splitBoxInfo': ['32298.48'],
 'splitSumBoxInfo': ['328300.0'],
 'sumBoxInfo': ['345700.0'],
 'yearRate': ['2019-05-02#1']}
2020-05-02 20:50:44,425 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 20:50:44,425 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 20:50:44,441 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-02 20:50:44,441 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-02 20:50:44,443 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#2
{'boxInfo': ['3180.66'],
 'boxRate': ['7.6%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1218727],
 'movieName': ['何以为家'],
 'releaseInfo': ['重映4天'],
 'seatRate': ['29.7%'],
 'showInfo': [36046],
 'showRate': ['11.3%'],
 'showView': ['28'],
 'splitBoxInfo': ['2892.66'],
 'splitSumBoxInfo': ['7958.7'],
 'sumBoxInfo': ['8707.5'],
 'yearRate': ['2019-05-02#2']}
2020-05-02 20:50:45,001 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-02 20:50:45,001 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-02 20:50:45,002 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#3
{'boxInfo': ['2425.92'],
 'boxRate': ['5.8%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1228776],
 'movieName': ['下一任：前任'],
 'releaseInfo': ['上映2天'],
 'seatRate': ['19.0%'],
 'showInfo': [41142],
 'showRate': ['12.9%'],
 'showView': ['18'],
 'splitBoxInfo': ['2236.43'],
 'splitSumBoxInfo': ['6979.6'],
 'sumBoxInfo': ['7606.2'],
 'yearRate': ['2019-05-02#3']}
2020-05-02 20:50:45,850 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 20:50:45,850 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 20:50:45,859 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 20:50:45,859 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 20:50:45,869 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-02 20:50:45,869 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-02 20:50:45,870 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#4
{'boxInfo': ['463.93'],
 'boxRate': ['1.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1211412],
 'movieName': ['神奇乐园历险记'],
 'releaseInfo': ['上映14天'],
 'seatRate': ['20.8%'],
 'showInfo': [6985],
 'showRate': ['2.2%'],
 'showView': ['20'],
 'splitBoxInfo': ['426.89'],
 'splitSumBoxInfo': ['3367.4'],
 'sumBoxInfo': ['3622.1'],
 'yearRate': ['2019-05-02#4']}
2020-05-02 20:50:46,817 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-02 20:50:46,817 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-02 20:50:46,818 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#5
{'boxInfo': ['460.75'],
 'boxRate': ['1.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [672379],
 'movieName': ['悟空奇遇记'],
 'releaseInfo': ['上映2天'],
 'seatRate': ['12.7%'],
 'showInfo': [13623],
 'showRate': ['4.2%'],
 'showView': ['12'],
 'splitBoxInfo': ['428.07'],
 'splitSumBoxInfo': ['1030.4'],
 'sumBoxInfo': ['1108.8'],
 'yearRate': ['2019-05-02#5']}
2020-05-02 20:50:47,018 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-02 20:50:47,018 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-02 20:50:47,033 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 20:50:47,033 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 20:50:47,054 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-02 20:50:47,054 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-02 20:50:47,056 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#6
{'boxInfo': ['317.05'],
 'boxRate': ['0.7%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [672279],
 'movieName': ['雪暴'],
 'releaseInfo': ['上映3天'],
 'seatRate': ['12.6%'],
 'showInfo': [8365],
 'showRate': ['2.6%'],
 'showView': ['11'],
 'splitBoxInfo': ['292.74'],
 'splitSumBoxInfo': ['1171.2'],
 'sumBoxInfo': ['1246.2'],
 'yearRate': ['2019-05-02#6']}
2020-05-02 20:50:47,268 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-02 20:50:47,268 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-02 20:50:47,270 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#7
{'boxInfo': ['169.34'],
 'boxRate': ['0.4%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1239544],
 'movieName': ['调音师'],
 'releaseInfo': ['上映30天'],
 'seatRate': ['25.9%'],
 'showInfo': [2141],
 'showRate': ['0.6%'],
 'showView': ['23'],
 'splitBoxInfo': ['154.12'],
 'splitSumBoxInfo': ['28700.0'],
 'sumBoxInfo': ['31800.0'],
 'yearRate': ['2019-05-02#7']}
2020-05-02 20:50:47,963 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 20:50:47,963 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-02 20:50:47,985 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 20:50:47,985 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-02 20:50:48,027 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-02 20:50:48,027 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-02 20:50:48,030 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#8
{'boxInfo': ['148.54'],
 'boxRate': ['0.3%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1211727],
 'movieName': ['反贪风暴4'],
 'releaseInfo': ['上映29天'],
 'seatRate': ['17.9%'],
 'showInfo': [2651],
 'showRate': ['0.8%'],
 'showView': ['16'],
 'splitBoxInfo': ['136.84'],
 'splitSumBoxInfo': ['72600.0'],
 'sumBoxInfo': ['78600.0'],
 'yearRate': ['2019-05-02#8']}
2020-05-02 20:50:48,775 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-02 20:50:48,775 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-02 20:50:48,776 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#9
{'boxInfo': ['99.02'],
 'boxRate': ['0.2%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1189325],
 'movieName': ['捉妖学院'],
 'releaseInfo': ['上映3天'],
 'seatRate': ['4.2%'],
 'showInfo': [169],
 'showRate': ['<0.1%'],
 'showView': ['36'],
 'splitBoxInfo': ['98.99'],
 'splitSumBoxInfo': ['211.3'],
 'sumBoxInfo': ['211.4'],
 'yearRate': ['2019-05-02#9']}
2020-05-02 20:50:49,669 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 20:50:49,669 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 20:50:49,694 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 20:50:49,694 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 20:50:49,710 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-02 20:50:49,710 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-02 20:50:49,714 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#10
{'boxInfo': ['78.11'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1230152],
 'movieName': ['撞死了一只羊'],
 'releaseInfo': ['上映7天'],
 'seatRate': ['12.2%'],
 'showInfo': [1662],
 'showRate': ['0.5%'],
 'showView': ['12'],
 'splitBoxInfo': ['75.66'],
 'splitSumBoxInfo': ['832.4'],
 'sumBoxInfo': ['864.4'],
 'yearRate': ['2019-05-02#10']}
2020-05-02 20:50:49,762 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-02 20:50:49,762 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-02 20:50:49,763 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#11
{'boxInfo': ['73.22'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [330115],
 'movieName': ['我和神马查干'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [219],
 'showRate': ['<0.1%'],
 'showView': ['103'],
 'splitBoxInfo': ['73.04'],
 'splitSumBoxInfo': ['2169.6'],
 'sumBoxInfo': ['2177.2'],
 'yearRate': ['2019-05-02#11']}
2020-05-02 20:50:49,958 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 20:50:49,958 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-02 20:50:49,961 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 20:50:49,961 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 20:50:49,974 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-02 20:50:49,986 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-02 20:50:50,000 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-02 20:50:50,003 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-02 20:50:50,003 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-02 20:50:50,005 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#12
{'boxInfo': ['40.69'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1243904],
 'movieName': ['动物出击'],
 'releaseInfo': ['上映3天'],
 'seatRate': ['10.9%'],
 'showInfo': [1826],
 'showRate': ['0.5%'],
 'showView': ['7'],
 'splitBoxInfo': ['38.50'],
 'splitSumBoxInfo': ['262.3'],
 'sumBoxInfo': ['269.7'],
 'yearRate': ['2019-05-02#12']}
2020-05-02 20:50:50,784 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 20:50:50,784 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-02 20:50:50,793 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-02 20:50:50,793 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-02 20:50:50,796 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#13
{'boxInfo': ['25.57'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1228750],
 'movieName': ['照相师'],
 'releaseInfo': [''],
 'seatRate': ['91.6%'],
 'showInfo': [47],
 'showRate': ['<0.1%'],
 'showView': ['124'],
 'splitBoxInfo': ['25.57'],
 'splitSumBoxInfo': ['2095.6'],
 'sumBoxInfo': ['2108.1'],
 'yearRate': ['2019-05-02#13']}
2020-05-02 20:50:51,734 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 20:50:51,734 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 20:50:51,736 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-02 20:50:51,738 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-02 20:50:51,739 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-02 20:50:51,740 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-02 20:50:51,740 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-02 20:50:51,742 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#14
{'boxInfo': ['23.68'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1234116],
 'movieName': ['猫公主苏菲'],
 'releaseInfo': ['上映2天'],
 'seatRate': ['5.2%'],
 'showInfo': [2204],
 'showRate': ['0.6%'],
 'showView': ['4'],
 'splitBoxInfo': ['22.11'],
 'splitSumBoxInfo': ['61.8'],
 'sumBoxInfo': ['66.3'],
 'yearRate': ['2019-05-02#14']}
2020-05-02 20:50:52,085 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-02 20:50:52,085 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-02 20:50:52,102 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 20:50:52,102 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-02 20:50:52,123 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 20:50:52,123 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-02 and tpp_id = 1218727
2020-05-02 20:50:52,124 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 20:50:52,124 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 20:50:52,124 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:52,124 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:52,125 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 20:50:52,125 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 20:50:53,808 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 20:50:53,808 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-02 and tpp_id = 1228776
2020-05-02 20:50:53,808 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 20:50:53,808 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 20:50:53,808 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:53,808 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:53,808 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 20:50:53,808 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 20:50:55,199 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 20:50:55,199 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-02 and tpp_id = 248172
2020-05-02 20:50:55,200 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 20:50:55,200 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 20:50:55,200 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:55,200 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:55,200 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 20:50:55,200 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 20:50:56,744 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-02 20:50:56,744 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-02 20:50:56,746 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#15
{'boxInfo': ['21.99'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1205909],
 'movieName': ['祈祷落幕时'],
 'releaseInfo': ['上映21天'],
 'seatRate': ['21.8%'],
 'showInfo': [346],
 'showRate': ['0.1%'],
 'showView': ['18'],
 'splitBoxInfo': ['20.08'],
 'splitSumBoxInfo': ['6032.5'],
 'sumBoxInfo': ['6671.5'],
 'yearRate': ['2019-05-02#15']}
2020-05-02 20:50:57,086 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 20:50:57,086 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-02 20:50:57,113 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 20:50:57,113 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-02 20:50:57,148 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 20:50:57,148 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-02 20:50:57,153 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 20:50:57,153 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-02 20:50:57,182 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 20:50:57,191 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-02 20:50:57,193 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-02 20:50:57,194 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2> (referer: https://movie.douban.com/)
2020-05-02 20:50:57,195 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-02 20:50:57,196 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-02 20:50:57,196 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-02 20:50:57,197 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#16
{'boxInfo': ['20.51'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1212492],
 'movieName': ['老师·好'],
 'releaseInfo': ['重映42天'],
 'seatRate': ['19.9%'],
 'showInfo': [363],
 'showRate': ['0.1%'],
 'showView': ['17'],
 'splitBoxInfo': ['19.25'],
 'splitSumBoxInfo': ['32600.0'],
 'sumBoxInfo': ['35300.0'],
 'yearRate': ['2019-05-02#16']}
2020-05-02 20:50:57,848 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 20:50:57,848 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-02 and tpp_id = 1211412
2020-05-02 20:50:57,848 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 20:50:57,848 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 20:50:57,849 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:50:57,849 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:50:57,849 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:50:57,849 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:50:57,851 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 20:50:57,851 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-02 and tpp_id = 672379
2020-05-02 20:50:57,851 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 20:50:57,851 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-02 20:50:57,852 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:50:57,852 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:50:57,852 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:50:57,852 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:50:57,855 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 20:50:57,855 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-02 and tpp_id = 1211727
2020-05-02 20:50:57,855 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 20:50:57,855 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 20:50:57,856 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:57,856 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:57,856 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 20:50:57,856 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 20:50:58,975 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 20:50:58,975 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-02 and tpp_id = 330115
2020-05-02 20:50:58,975 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 20:50:58,975 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-02 20:50:58,976 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:50:58,976 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:50:58,976 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:50:58,976 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:50:58,980 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 20:50:58,980 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-02 and tpp_id = 1230152
2020-05-02 20:50:58,981 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 20:50:58,981 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 20:50:58,981 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:58,981 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:50:58,982 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 20:50:58,982 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 20:51:00,688 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 20:51:00,688 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-02 20:51:00,699 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 20:51:00,699 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-02 20:51:00,710 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:00,710 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:00,719 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/)
2020-05-02 20:51:00,721 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-02 20:51:00,722 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-02 20:51:00,722 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-02 20:51:00,723 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#17
{'boxInfo': ['17.18'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [836],
 'movieName': ['毕业那年'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [50],
 'showRate': ['<0.1%'],
 'showView': ['107'],
 'splitBoxInfo': ['17.13'],
 'splitSumBoxInfo': ['1039.8'],
 'sumBoxInfo': ['1041.5'],
 'yearRate': ['2019-05-02#17']}
2020-05-02 20:51:01,212 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 20:51:01,212 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 20:51:01,225 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-02 20:51:01,227 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 20:51:01,228 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-02 20:51:01,228 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-02 20:51:01,229 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#18
{'boxInfo': ['16.06'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1239281],
 'movieName': ['港珠澳大桥'],
 'releaseInfo': ['上映2天'],
 'seatRate': ['4.5%'],
 'showInfo': [2033],
 'showRate': ['0.6%'],
 'showView': ['3'],
 'splitBoxInfo': ['15.11'],
 'splitSumBoxInfo': ['64.3'],
 'sumBoxInfo': ['67.3'],
 'yearRate': ['2019-05-02#18']}
2020-05-02 20:51:01,673 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 20:51:01,673 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-02 and tpp_id = 1239544
2020-05-02 20:51:01,673 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 20:51:01,673 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-02 20:51:01,673 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,673 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,673 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,673 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,674 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 20:51:01,674 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-02 and tpp_id = 672279
2020-05-02 20:51:01,675 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 20:51:01,675 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-02 20:51:01,675 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,675 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,675 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,675 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,676 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 20:51:01,676 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-02 and tpp_id = 1243904
2020-05-02 20:51:01,676 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 20:51:01,676 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-02 20:51:01,676 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,676 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,676 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,676 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,677 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 20:51:01,677 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-02 and tpp_id = 1234116
2020-05-02 20:51:01,677 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 20:51:01,677 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-02 20:51:01,677 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,677 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,677 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,677 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,678 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 20:51:01,678 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-02 and tpp_id = 1228750
2020-05-02 20:51:01,678 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 20:51:01,678 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-02 20:51:01,678 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,678 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:01,678 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,678 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:01,679 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 20:51:01,679 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 20:51:01,688 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-02 20:51:01,690 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-02 20:51:01,693 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-02 20:51:01,694 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-02 20:51:01,695 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-02 20:51:01,695 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-02 20:51:01,696 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#19
{'boxInfo': ['15.65'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [476263],
 'movieName': ['天上再见'],
 'releaseInfo': ['上映3天'],
 'seatRate': ['12.9%'],
 'showInfo': [490],
 'showRate': ['0.1%'],
 'showView': ['10'],
 'splitBoxInfo': ['14.35'],
 'splitSumBoxInfo': ['60.2'],
 'sumBoxInfo': ['64.2'],
 'yearRate': ['2019-05-02#19']}
2020-05-02 20:51:02,181 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 20:51:02,181 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-02 and tpp_id = 1205909
2020-05-02 20:51:02,181 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 20:51:02,181 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-02 20:51:02,182 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:02,182 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:02,182 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:02,182 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:02,184 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 20:51:02,184 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-02 20:51:02,218 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:02,218 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:02,221 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:02,221 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:02,221 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:02,221 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:02,222 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:02,222 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:02,222 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:02,222 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:02,223 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:02,223 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:02,267 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['832672'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-05-02 20:51:02,269 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 20:51:02,269 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 20:51:02,286 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-02 20:51:02,290 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-02 20:51:02,294 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-02 20:51:02,294 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-02 20:51:02,297 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#20
{'boxInfo': ['14.85'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1229702],
 'movieName': ['青蛙王子历险记'],
 'releaseInfo': ['上映28天'],
 'seatRate': ['13.1%'],
 'showInfo': [95],
 'showRate': ['<0.1%'],
 'showView': ['22'],
 'splitBoxInfo': ['14.81'],
 'splitSumBoxInfo': ['1041.3'],
 'sumBoxInfo': ['1097.7'],
 'yearRate': ['2019-05-02#20']}
2020-05-02 20:51:03,115 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 20:51:03,115 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-02 and tpp_id = 1189325
2020-05-02 20:51:03,115 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 20:51:03,115 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 20:51:03,115 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:51:03,115 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:51:03,116 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 20:51:03,116 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 20:51:04,933 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 20:51:04,933 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-02 and tpp_id = 1212492
2020-05-02 20:51:04,933 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:04,933 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:04,934 -  movie_spider.py[line:162] - INFO: len of text is 6
2020-05-02 20:51:04,934 -  movie_spider.py[line:162] - INFO: len of text is 6
2020-05-02 20:51:04,934 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:04,934 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:06,771 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:06,771 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:07,980 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:07,980 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:08,005 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:08,005 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:08,029 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 20:51:08,029 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-02 20:51:08,046 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 20:51:08,046 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-02 20:51:08,065 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-02 20:51:08,067 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-02 20:51:08,067 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-02 20:51:08,068 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#21
{'boxInfo': ['14.69'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [643506],
 'movieName': ['古镇画情'],
 'releaseInfo': ['展映'],
 'seatRate': ['--'],
 'showInfo': [75],
 'showRate': ['<0.1%'],
 'showView': ['48'],
 'splitBoxInfo': ['14.67'],
 'splitSumBoxInfo': ['1137.6'],
 'sumBoxInfo': ['1140.4'],
 'yearRate': ['2019-05-02#21']}
2020-05-02 20:51:08,350 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 20:51:08,350 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-02 and tpp_id = 836
2020-05-02 20:51:08,351 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:08,351 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:08,351 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-02 20:51:08,351 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-02 20:51:08,351 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:08,351 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:09,507 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:09,507 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:09,510 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 20:51:09,510 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-02 20:51:09,571 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:09,571 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:09,573 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:09,573 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:09,573 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:09,573 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:09,574 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,574 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,574 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,574 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,575 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,575 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,576 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30283179
{'actors': '金巴/更登彭措/索朗旺姆/加华草',
 'area': ' 中国大陆',
 'dbMovieID': ['30283179'],
 'directors': '万玛才旦',
 'doubanRate': ['7.2'],
 'duration': [87],
 'genre': '剧情',
 'movieName': ['撞死了一只羊'],
 'publishedDate': ['2018-09-04'],
 'rateCount': ['40906'],
 'tppMovieID': [1230152],
 'writers': '万玛才旦/次仁罗布'}
2020-05-02 20:51:09,577 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 20:51:09,577 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27202819/?suggest=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-02 20:51:09,604 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:09,604 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:09,607 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:09,607 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:09,608 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:09,608 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:09,608 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,608 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,608 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,608 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,609 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,609 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,611 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27202819
{'actors': '古天乐/郑嘉颖/林峯/林家栋/周秀娜/张智霖/谭耀文/张继聪/蔡瀚亿/廖启智',
 'area': ' 中国香港 / 中国大陆',
 'dbMovieID': ['27202819'],
 'directors': '林德禄',
 'doubanRate': ['6.0'],
 'duration': [96],
 'genre': '动作/犯罪',
 'movieName': ['反贪风暴4 P風暴'],
 'publishedDate': ['2019-04-04'],
 'rateCount': ['131790'],
 'tppMovieID': [1211727],
 'writers': '黄浩华/何文龙'}
2020-05-02 20:51:09,612 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 20:51:09,612 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-02 20:51:09,635 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:09,635 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:09,637 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:09,637 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:09,638 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:09,638 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:09,638 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,638 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,638 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,638 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,638 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,638 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:09,639 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30170448
{'actors': '赞恩·阿尔·拉菲亚/约丹诺斯·希费罗/博鲁瓦蒂夫·特雷杰·班科尔/卡萨尔·艾尔·哈达德/法迪·尤瑟夫/海塔·塞德拉·伊扎姆/阿拉·乔什涅/娜丁·拉巴基/埃利亚斯·库利/努尔·艾尔·侯赛尼',
 'area': ' 黎巴嫩 / 法国 / 美国',
 'dbMovieID': ['30170448'],
 'directors': '娜丁·拉巴基',
 'doubanRate': ['9.1'],
 'duration': [126],
 'genre': '剧情',
 'movieName': ['何以为家 كفرناحوم'],
 'publishedDate': ['2018-05-17'],
 'rateCount': ['637739'],
 'tppMovieID': [1218727],
 'writers': '娜丁·拉巴基/吉哈德·霍加里/米歇尔·凯斯沃尼/乔治斯·哈巴兹/哈立德·穆扎纳'}
2020-05-02 20:51:10,851 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:10,851 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:10,854 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:10,854 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:10,860 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 20:51:10,860 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 20:51:10,868 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 20:51:10,868 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-02 20:51:10,881 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 20:51:10,881 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-02 20:51:10,892 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 20:51:10,895 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 20:51:10,896 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-02 20:51:10,897 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-02 20:51:10,898 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-02 20:51:10,898 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-02 20:51:10,898 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#22
{'boxInfo': ['13.98'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [245881],
 'movieName': ['麦兜我和我妈妈'],
 'releaseInfo': [''],
 'seatRate': ['10.8%'],
 'showInfo': [512],
 'showRate': ['0.1%'],
 'showView': ['9'],
 'splitBoxInfo': ['12.30'],
 'splitSumBoxInfo': ['4624.7'],
 'sumBoxInfo': ['4643.7'],
 'yearRate': ['2019-05-02#22']}
2020-05-02 20:51:11,119 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 20:51:11,119 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-02 and tpp_id = 1239281
2020-05-02 20:51:11,120 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 20:51:11,120 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 20:51:11,120 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-02 20:51:11,120 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-02 20:51:11,120 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 20:51:11,120 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 20:51:12,644 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 20:51:12,644 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-02 20:51:12,661 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:12,661 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:12,663 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:12,663 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:12,663 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:12,663 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:12,663 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:12,663 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:12,663 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:12,663 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:12,663 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:12,663 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:12,665 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26311974
{'actors': '郭采洁/郑恺/李东学/谢依霖/刘心悠/邱欣怡/李荣浩/蓝心湄/林辰唏/林美秀',
 'area': ' 中国台湾 / 中国大陆',
 'dbMovieID': ['26311974'],
 'directors': '陈鸿仪',
 'doubanRate': ['2.8'],
 'duration': [99],
 'genre': '爱情',
 'movieName': ['下一任：前任'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['23785'],
 'tppMovieID': [1228776],
 'writers': '陈鸿仪'}
2020-05-02 20:51:19,285 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:19,285 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:19,292 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:19,292 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-02 20:51:19,313 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 20:51:19,313 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-02 20:51:19,337 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-02 20:51:19,337 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-02 20:51:19,359 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 20:51:19,362 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-02 20:51:19,366 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-02 20:51:19,368 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/)
2020-05-02 20:51:19,370 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-02 20:51:19,370 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-02 20:51:19,372 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#23
{'boxInfo': ['11.71'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1213175],
 'movieName': ['在乎你'],
 'releaseInfo': ['上映21天'],
 'seatRate': ['0.5%'],
 'showInfo': [28],
 'showRate': ['<0.1%'],
 'showView': ['65'],
 'splitBoxInfo': ['11.71'],
 'splitSumBoxInfo': ['713.9'],
 'sumBoxInfo': ['745.7'],
 'yearRate': ['2019-05-02#23']}
2020-05-02 20:51:20,356 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 20:51:20,356 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-02 and tpp_id = 476263
2020-05-02 20:51:20,357 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 20:51:20,357 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 20:51:20,357 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:51:20,357 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-02 20:51:20,357 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 20:51:20,357 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 20:51:24,482 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 20:51:24,482 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-02 20:51:24,492 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 20:51:24,492 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-02 20:51:24,504 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-02 20:51:24,507 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-02 20:51:24,509 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88> (referer: https://movie.douban.com/)
2020-05-02 20:51:24,510 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-02 20:51:24,510 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-02 20:51:24,511 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#24
{'boxInfo': ['10.61'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [248906],
 'movieName': ['流浪地球'],
 'releaseInfo': [''],
 'seatRate': ['21.1%'],
 'showInfo': [183],
 'showRate': ['<0.1%'],
 'showView': ['18'],
 'splitBoxInfo': ['9.76'],
 'splitSumBoxInfo': ['435400.0'],
 'sumBoxInfo': ['468000.0'],
 'yearRate': ['2019-05-02#24']}
2020-05-02 20:51:25,225 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:25,225 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:25,264 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,264 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,265 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,265 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,265 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,265 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,265 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,265 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,266 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,266 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,266 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,266 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,267 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216392'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 20:51:25,268 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:25,268 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:25,290 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,290 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,292 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,292 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,293 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,293 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,293 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,293 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,293 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,293 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,294 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,294 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,295 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216392'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 20:51:25,296 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 20:51:25,296 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-02 20:51:25,307 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,307 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,308 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,308 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,309 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,309 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,309 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,309 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,309 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,309 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,309 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,309 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,310 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26879542
{'actors': '王泽宗/慈婉彤/周海媚/胡昌霖',
 'area': ' 中国大陆',
 'dbMovieID': ['26879542'],
 'directors': '田梓橙',
 'doubanRate': [''],
 'duration': [96],
 'genre': '奇幻/冒险',
 'movieName': ['捉妖学院'],
 'publishedDate': ['2019-04-30'],
 'rateCount': ['0'],
 'tppMovieID': [1189325],
 'writers': '方岚/田梓橙'}
2020-05-02 20:51:25,311 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 20:51:25,311 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-02 and tpp_id = 1229702
2020-05-02 20:51:25,311 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 20:51:25,311 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-02 20:51:25,311 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:25,311 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:25,311 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:25,311 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:25,320 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 20:51:25,320 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-02 20:51:25,331 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-02 20:51:25,333 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-02 20:51:25,333 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-02 20:51:25,334 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#25
{'boxInfo': ['6.84'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1263355],
 'movieName': ['狗眼看人心'],
 'releaseInfo': ['上映13天'],
 'seatRate': ['6.5%'],
 'showInfo': [368],
 'showRate': ['0.1%'],
 'showView': ['6'],
 'splitBoxInfo': ['6.35'],
 'splitSumBoxInfo': ['1696.9'],
 'sumBoxInfo': ['1827.8'],
 'yearRate': ['2019-05-02#25']}
2020-05-02 20:51:25,638 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:25,638 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:25,656 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,656 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,659 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,659 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,659 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,659 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,659 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,659 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,660 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,660 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,660 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,660 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,661 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216392'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 20:51:25,662 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:25,662 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:25,682 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,682 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,683 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,683 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,683 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,683 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,684 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,684 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,684 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,684 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,684 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,684 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,685 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :10759842
{'actors': '顾莉雅/朱文超/叶青青/王仲欣/丁汀/飞龙/龙泽',
 'area': ' 中国大陆',
 'dbMovieID': ['10759842'],
 'directors': '姚宇',
 'doubanRate': ['3.8'],
 'duration': [88],
 'genre': '剧情/音乐',
 'movieName': ['毕业那年'],
 'publishedDate': ['2012-09-21'],
 'rateCount': ['1972'],
 'tppMovieID': [836],
 'writers': '仧縯'}
2020-05-02 20:51:25,686 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:25,686 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/10759842/?suggest=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-02 20:51:25,703 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,703 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:25,705 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,705 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:25,705 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,705 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:25,705 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,705 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,706 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,706 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,706 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,706 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:25,707 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :10759842
{'actors': '顾莉雅/朱文超/叶青青/王仲欣/丁汀/飞龙/龙泽',
 'area': ' 中国大陆',
 'dbMovieID': ['10759842'],
 'directors': '姚宇',
 'doubanRate': ['3.8'],
 'duration': [88],
 'genre': '剧情/音乐',
 'movieName': ['毕业那年'],
 'publishedDate': ['2012-09-21'],
 'rateCount': ['1972'],
 'tppMovieID': [836],
 'writers': '仧縯'}
2020-05-02 20:51:25,708 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 20:51:25,708 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-02 and tpp_id = 643506
2020-05-02 20:51:25,708 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 20:51:25,708 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-02 20:51:25,708 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:25,708 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:25,708 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:25,708 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:30,324 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 20:51:30,324 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-02 20:51:30,334 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/)
2020-05-02 20:51:30,336 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-02 20:51:30,338 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-02 20:51:30,338 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-02 20:51:30,340 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#26
{'boxInfo': ['5.80'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1167831],
 'movieName': ['波西米亚狂想曲'],
 'releaseInfo': ['上映42天'],
 'seatRate': ['23.2%'],
 'showInfo': [71],
 'showRate': ['<0.1%'],
 'showView': ['20'],
 'splitBoxInfo': ['5.34'],
 'splitSumBoxInfo': ['8939.8'],
 'sumBoxInfo': ['9864.5'],
 'yearRate': ['2019-05-02#26']}
2020-05-02 20:51:31,014 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:31,014 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27663742/?suggest=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-02 20:51:31,052 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:31,052 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:31,056 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:31,056 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:31,057 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:31,057 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:31,057 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,057 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,058 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,058 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,058 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,058 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,061 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27663742
{'actors': '于谦/汤梦佳/王广源/秦鸣悦/徐子力/孙艺杨/徐紫茵/郝鹏飞/郜玄铭/黑妹',
 'area': ' 中国大陆',
 'dbMovieID': ['27663742'],
 'directors': '张栾',
 'doubanRate': ['6.7'],
 'duration': [111],
 'genre': '剧情',
 'movieName': ['老师·好'],
 'publishedDate': ['2019-03-22'],
 'rateCount': ['216392'],
 'tppMovieID': [1212492],
 'writers': '张栾/徐伟'}
2020-05-02 20:51:31,063 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 20:51:31,063 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30230160/?suggest=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-02 20:51:31,082 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:31,082 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:31,084 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:31,084 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:31,084 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:31,084 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:31,084 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,084 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,084 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,084 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,085 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,085 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:31,086 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30230160
{'actors': '李立宏',
 'area': ' 中国大陆',
 'dbMovieID': ['30230160'],
 'directors': '闫东',
 'doubanRate': ['6.7'],
 'duration': [70],
 'genre': '纪录片',
 'movieName': ['港珠澳大桥'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['3712'],
 'tppMovieID': [1239281],
 'writers': '李凯/张艺宰'}
2020-05-02 20:51:31,087 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 20:51:31,087 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-02 and tpp_id = 245881
2020-05-02 20:51:31,087 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 20:51:31,087 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-02 20:51:31,087 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:31,087 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:31,087 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:31,087 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:36,186 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 20:51:36,186 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-02 20:51:36,201 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/)
2020-05-02 20:51:36,204 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-02 20:51:36,204 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-02 20:51:36,206 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#27
{'boxInfo': ['5.61'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [883196],
 'movieName': ['一个母亲的复仇'],
 'releaseInfo': ['点映'],
 'seatRate': ['98.7%'],
 'showInfo': [8],
 'showRate': ['<0.1%'],
 'showView': ['171'],
 'splitBoxInfo': ['5.18'],
 'splitSumBoxInfo': ['6.5'],
 'sumBoxInfo': ['6.9'],
 'yearRate': ['2019-05-02#27']}
2020-05-02 20:51:36,222 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 20:51:36,222 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-02 and tpp_id = 1213175
2020-05-02 20:51:36,223 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 20:51:36,223 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-02 20:51:36,223 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:36,223 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:36,223 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:36,223 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:40,061 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-02 20:51:40,061 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-02 20:51:40,080 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-02 20:51:40,081 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-02 20:51:40,081 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-02 20:51:40,082 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#28
{'boxInfo': ['4.80'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1217701],
 'movieName': ['九克拉战栗'],
 'releaseInfo': ['重映3天'],
 'seatRate': ['6.1%'],
 'showInfo': [471],
 'showRate': ['0.1%'],
 'showView': ['4'],
 'splitBoxInfo': ['4.36'],
 'splitSumBoxInfo': ['23.5'],
 'sumBoxInfo': ['25.4'],
 'yearRate': ['2019-05-02#28']}
2020-05-02 20:51:40,118 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 20:51:40,118 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-02 and tpp_id = 248906
2020-05-02 20:51:40,119 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 20:51:40,119 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-02 20:51:40,119 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:40,119 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:40,119 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:40,119 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:40,120 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 20:51:40,120 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26731376/?suggest=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-02 20:51:40,141 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:40,141 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-02 20:51:40,143 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:40,143 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-02 20:51:40,144 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:40,144 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-02 20:51:40,144 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:40,144 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:40,144 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:40,144 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:40,144 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:40,144 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-02 20:51:40,145 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26731376
{'actors': '纳威尔·佩雷兹·毕斯卡亚特/阿尔贝·杜邦泰尔/罗兰·拉斐特/尼尔斯·阿贺斯图普/艾米莉·德奎恩/梅兰尼·蒂埃里/埃洛伊兹·巴尔斯特/菲利普·乌禅/安德烈·马尔孔/米歇尔·维耶尔莫',
 'area': ' 法国 / 加拿大',
 'dbMovieID': ['26731376'],
 'directors': '阿尔贝·杜邦泰尔',
 'doubanRate': ['8.1'],
 'duration': [117],
 'genre': '喜剧/战争/犯罪',
 'movieName': ['天上再见 Au revoir là-haut'],
 'publishedDate': ['2017-10-25'],
 'rateCount': ['27401'],
 'tppMovieID': [476263],
 'writers': '阿尔贝·杜邦泰尔/皮耶尔·勒迈特'}
2020-05-02 20:51:40,153 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 20:51:40,153 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-02 20:51:40,163 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87> (referer: https://movie.douban.com/)
2020-05-02 20:51:40,164 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-02 20:51:40,164 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-02 20:51:40,165 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#29
{'boxInfo': ['4.28'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [342568],
 'movieName': ['诡梦凶铃'],
 'releaseInfo': [''],
 'seatRate': ['6.6%'],
 'showInfo': [11],
 'showRate': ['<0.1%'],
 'showView': ['147'],
 'splitBoxInfo': ['4.28'],
 'splitSumBoxInfo': ['1125.3'],
 'sumBoxInfo': ['1125.3'],
 'yearRate': ['2019-05-02#29']}
2020-05-02 20:51:42,993 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 20:51:42,993 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-02 and tpp_id = 1263355
2020-05-02 20:51:42,996 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 20:51:42,996 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-02 20:51:42,997 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:42,997 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:42,997 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:42,997 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:42,999 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 20:51:42,999 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83 has been crawled, drop it
2020-05-02 20:51:43,013 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-02 20:51:43,014 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-02 20:51:43,014 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-02 20:51:43,015 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-02#30
{'boxInfo': ['4.02'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-02'],
 'movieID': [1216383],
 'movieName': ['比悲伤更悲伤的故事'],
 'releaseInfo': ['上映50天'],
 'seatRate': ['12.6%'],
 'showInfo': [193],
 'showRate': ['<0.1%'],
 'showView': ['8'],
 'splitBoxInfo': ['3.68'],
 'splitSumBoxInfo': ['85800.0'],
 'sumBoxInfo': ['95700.0'],
 'yearRate': ['2019-05-02#30']}
2020-05-02 20:51:43,673 -  logstats.py[line:48] - INFO: Crawled 43 pages (at 43 pages/min), scraped 0 items (at 0 items/min)
2020-05-02 20:51:43,676 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 20:51:43,676 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-02 20:51:43,684 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83> (referer: https://movie.douban.com/)
2020-05-02 20:51:43,686 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 20:51:43,686 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-02 and tpp_id = 1167831
2020-05-02 20:51:43,686 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 20:51:43,686 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-02 20:51:43,686 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,686 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,686 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,686 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,688 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 20:51:43,688 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-02 and tpp_id = 883196
2020-05-02 20:51:43,688 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 20:51:43,688 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-02 20:51:43,688 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,688 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,688 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,688 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,690 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 20:51:43,690 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-02 and tpp_id = 1217701
2020-05-02 20:51:43,690 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 20:51:43,690 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-02 20:51:43,690 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,690 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,690 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,690 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,759 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/)
2020-05-02 20:51:43,787 -  movie_spider.py[line:156] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 20:51:43,787 -  movie_spider.py[line:156] - INFO: movie_name = 诡梦凶铃 and movie_year = 2019-05-02 and tpp_id = 342568
2020-05-02 20:51:43,787 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 20:51:43,787 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%AF%A1%E6%A2%A6%E5%87%B6%E9%93%83
2020-05-02 20:51:43,788 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,788 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,788 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,788 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,863 -  movie_spider.py[line:156] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 20:51:43,863 -  movie_spider.py[line:156] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-02 and tpp_id = 1216383
2020-05-02 20:51:43,865 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 20:51:43,865 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-02 20:51:43,865 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,865 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-02 20:51:43,866 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,866 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-02 20:51:43,872 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-05-02 20:51:43,874 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 54561,
 'downloader/request_count': 45,
 'downloader/request_method_count/GET': 45,
 'downloader/response_bytes': 369969,
 'downloader/response_count': 45,
 'downloader/response_status_count/200': 45,
 'elapsed_time_seconds': 61.145742,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 2, 12, 51, 43, 873264),
 'item_dropped_count': 44,
 'item_dropped_reasons_count/DropItem': 44,
 'log_count/ERROR': 65,
 'log_count/WARNING': 44,
 'memusage/max': 110116864,
 'memusage/startup': 73728000,
 'request_depth_max': 2,
 'response_received_count': 45,
 'scheduler/dequeued': 45,
 'scheduler/dequeued/memory': 45,
 'scheduler/enqueued': 45,
 'scheduler/enqueued/memory': 45,
 'start_time': datetime.datetime(2020, 5, 2, 12, 50, 42, 727522)}
2020-05-02 20:51:43,874 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-05-03 00:36:24,734 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-03 00:36:24,759 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-03 00:36:24,783 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-03 00:36:24,892 -  telnet.py[line:60] - INFO: Telnet Password: 9d0941a88d30ad1c
2020-05-03 00:36:25,004 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-03 00:36:30,087 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-03 00:36:30,150 -  utils.py[line:88] - DEBUG: Sleeping for 0.1 seconds
2020-05-03 00:36:35,289 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-03 00:36:35,312 -  _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2020-05-03 00:36:35,412 -  _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 85, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 108, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 53, in __init__
    self.headers = get_random_headers()
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 41, in get_random_headers
    return {'User-Agent': str(UserAgent(use_cache_server=False).random)}
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 69, in __init__
    self.load()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 78, in load
    verify_ssl=self.verify_ssl,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 250, in load_cached
    update(path, use_cache_server=use_cache_server, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 245, in update
    write(path, load(use_cache_server=use_cache_server, verify_ssl=verify_ssl))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 178, in load
    raise exc
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2020-05-03 00:38:24,039 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-03 00:38:24,042 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-03 00:38:24,045 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-03 00:38:24,054 -  telnet.py[line:60] - INFO: Telnet Password: b8447576790d967a
2020-05-03 00:38:24,062 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-03 00:38:29,079 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-03 00:38:29,084 -  utils.py[line:88] - DEBUG: Sleeping for 0.1 seconds
2020-05-03 00:38:34,211 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-03 00:38:34,231 -  _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2020-05-03 00:38:34,232 -  _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 85, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 108, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 53, in __init__
    self.headers = get_random_headers()
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 41, in get_random_headers
    return {'User-Agent': str(UserAgent(use_cache_server=False).random)}
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 69, in __init__
    self.load()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 78, in load
    verify_ssl=self.verify_ssl,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 250, in load_cached
    update(path, use_cache_server=use_cache_server, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 245, in update
    write(path, load(use_cache_server=use_cache_server, verify_ssl=verify_ssl))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 178, in load
    raise exc
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2020-05-03 00:42:03,763 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-03 00:42:03,766 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-03 00:42:03,769 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-03 00:42:03,777 -  telnet.py[line:60] - INFO: Telnet Password: 4a6f3cbfe7d4428d
2020-05-03 00:42:03,785 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-03 00:42:05,729 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-03 00:42:05,729 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-03 00:42:05,735 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.RefererMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-03 00:42:05,738 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-03 00:42:05,786 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-03 00:42:05,786 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-03 00:42:05,927 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.ItemPipeline', 'movie.pipelines.MySQLPipeline']
2020-05-03 00:42:05,928 -  engine.py[line:257] - INFO: Spider opened
2020-05-03 00:42:05,934 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-03 00:42:05,936 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6023
2020-05-03 00:42:05,995 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-03 00:42:05,995 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-03 00:42:06,272 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503> (referer: https://movie.douban.com/)
2020-05-03 00:42:06,861 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503
2020-05-03 00:42:06,861 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503
2020-05-03 00:42:06,889 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-03 00:42:06,889 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-03 00:42:06,891 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:06,891 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:06,891 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:06,891 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:06,893 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:06,893 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:06,895 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'sql_mode'
2020-05-03 00:42:06,895 -  log.py[line:110] - INFO: {}
2020-05-03 00:42:06,928 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'lower_case_table_names'
2020-05-03 00:42:06,928 -  log.py[line:110] - INFO: {}
2020-05-03 00:42:06,934 -  log.py[line:110] - INFO: SELECT DATABASE()
2020-05-03 00:42:06,934 -  log.py[line:110] - INFO: {}
2020-05-03 00:42:06,936 -  log.py[line:110] - INFO: show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'
2020-05-03 00:42:06,937 -  log.py[line:110] - INFO: {}
2020-05-03 00:42:06,948 -  log.py[line:110] - INFO: SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1
2020-05-03 00:42:06,948 -  log.py[line:110] - INFO: {}
2020-05-03 00:42:06,950 -  log.py[line:110] - INFO: SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1
2020-05-03 00:42:06,950 -  log.py[line:110] - INFO: {}
2020-05-03 00:42:06,952 -  log.py[line:110] - INFO: SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1
2020-05-03 00:42:06,953 -  log.py[line:110] - INFO: {}
2020-05-03 00:42:06,956 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:06,961 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:06,961 -  log.py[line:110] - INFO: {'movieID': 248172, 'movieName': '复仇者联盟4：终局之战', 'seatRate': '19.7%', 'boxInfo': '24210.25', 'boxRate': '77.0%', 'releaseInfo': '上映10天', 'showInfo': 189322, 'showRate': '60.1%', 'splitBoxInfo': '22867.99', 'splitSumBoxInfo': '351200.0', 'sumBoxInfo': '369900.0', 'showView': '28', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#1'}
2020-05-03 00:42:06,994 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:07,145 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:07,383 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-03 00:42:07,383 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-03 00:42:07,412 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-03 00:42:07,412 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-03 00:42:07,414 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:07,414 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:07,415 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:07,415 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:07,415 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:07,415 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:07,416 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:07,416 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:07,417 -  log.py[line:110] - INFO: {'movieID': 1218727, 'movieName': '何以为家', 'seatRate': '27.5%', 'boxInfo': '3546.07', 'boxRate': '11.2%', 'releaseInfo': '重映5天', 'showInfo': 42434, 'showRate': '13.4%', 'splitBoxInfo': '3226.44', 'splitSumBoxInfo': '11100.0', 'sumBoxInfo': '12200.0', 'showView': '27', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#2'}
2020-05-03 00:42:07,418 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:07,537 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:08,188 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-03 00:42:08,188 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-03 00:42:08,216 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-03 00:42:08,216 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-03 00:42:08,218 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:08,218 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:08,218 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:08,218 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:08,219 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:08,219 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:08,220 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:08,220 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:08,220 -  log.py[line:110] - INFO: {'movieID': 1228776, 'movieName': '下一任：前任', 'seatRate': '14.8%', 'boxInfo': '1600.71', 'boxRate': '5.0%', 'releaseInfo': '上映3天', 'showInfo': 35633, 'showRate': '11.3%', 'splitBoxInfo': '1478.61', 'splitSumBoxInfo': '8458.2', 'sumBoxInfo': '9206.9', 'showView': '14', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#3'}
2020-05-03 00:42:08,222 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:08,324 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:08,443 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-03 00:42:08,443 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-03 00:42:08,470 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-03 00:42:08,470 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-03 00:42:08,472 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:08,472 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:08,472 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:08,472 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:08,473 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:08,473 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:08,473 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:08,474 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:08,474 -  log.py[line:110] - INFO: {'movieID': 1211412, 'movieName': '神奇乐园历险记', 'seatRate': '20.3%', 'boxInfo': '524.16', 'boxRate': '1.6%', 'releaseInfo': '上映15天', 'showInfo': 8112, 'showRate': '2.5%', 'splitBoxInfo': '482.90', 'splitSumBoxInfo': '3850.3', 'sumBoxInfo': '4146.2', 'showView': '20', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#4'}
2020-05-03 00:42:08,475 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:08,650 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:08,754 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-03 00:42:08,754 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-03 00:42:08,783 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-03 00:42:08,783 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-03 00:42:08,784 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:08,784 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:08,784 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:08,784 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:08,785 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:08,785 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:08,785 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:08,786 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:08,786 -  log.py[line:110] - INFO: {'movieID': 672379, 'movieName': '悟空奇遇记', 'seatRate': '11.2%', 'boxInfo': '393.83', 'boxRate': '1.2%', 'releaseInfo': '上映3天', 'showInfo': 13267, 'showRate': '4.2%', 'splitBoxInfo': '366.42', 'splitSumBoxInfo': '1396.9', 'sumBoxInfo': '1502.6', 'showView': '10', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#5'}
2020-05-03 00:42:08,787 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:08,947 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:09,617 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-03 00:42:09,617 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-03 00:42:09,626 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-03 00:42:09,626 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-03 00:42:09,626 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:09,626 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:09,627 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:09,627 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:09,627 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:09,627 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:09,627 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:09,627 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:09,627 -  log.py[line:110] - INFO: {'movieID': 672279, 'movieName': '雪暴', 'seatRate': '12.4%', 'boxInfo': '307.87', 'boxRate': '0.9%', 'releaseInfo': '上映4天', 'showInfo': 8308, 'showRate': '2.6%', 'splitBoxInfo': '284.28', 'splitSumBoxInfo': '1455.5', 'sumBoxInfo': '1554.1', 'showView': '11', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#6'}
2020-05-03 00:42:09,628 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:09,772 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:09,797 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-03 00:42:10,475 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-03 00:42:10,475 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-03 00:42:10,509 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-03 00:42:10,516 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-03 00:42:10,516 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-03 00:42:10,517 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:10,517 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:10,517 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:10,517 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:10,518 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:10,518 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:10,518 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:10,518 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:10,519 -  log.py[line:110] - INFO: {'movieID': 1239544, 'movieName': '调音师', 'seatRate': '22.9%', 'boxInfo': '174.10', 'boxRate': '0.5%', 'releaseInfo': '上映31天', 'showInfo': 2419, 'showRate': '0.7%', 'splitBoxInfo': '158.52', 'splitSumBoxInfo': '28800.0', 'sumBoxInfo': '31900.0', 'showView': '21', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#7'}
2020-05-03 00:42:10,520 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:10,656 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:10,658 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-03 and tpp_id = 248172
2020-05-03 00:42:10,658 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-03 and tpp_id = 248172
2020-05-03 00:42:10,659 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-03 00:42:10,659 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-03 00:42:10,660 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:42:10,660 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:42:10,660 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-03 00:42:10,660 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-03 00:42:13,254 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-03 00:42:13,260 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-03 00:42:13,262 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:13,262 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:13,280 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-03 00:42:13,280 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-03 00:42:13,290 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-03 and tpp_id = 1218727
2020-05-03 00:42:13,290 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-03 and tpp_id = 1218727
2020-05-03 00:42:13,291 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-03 00:42:13,291 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-03 00:42:13,291 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:42:13,291 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:42:13,291 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-03 00:42:13,291 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-03 00:42:14,340 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-03 00:42:14,340 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-03 00:42:14,343 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:14,343 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:14,344 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:14,344 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:14,345 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:14,345 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:14,345 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:14,346 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:14,346 -  log.py[line:110] - INFO: {'movieID': 1211727, 'movieName': '反贪风暴4', 'seatRate': '15.5%', 'boxInfo': '151.60', 'boxRate': '0.4%', 'releaseInfo': '上映30天', 'showInfo': 3178, 'showRate': '1.0%', 'splitBoxInfo': '139.87', 'splitSumBoxInfo': '72700.0', 'sumBoxInfo': '78800.0', 'showView': '14', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#8'}
2020-05-03 00:42:14,349 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:14,473 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:14,475 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-03 00:42:14,475 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-03 00:42:14,890 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-03 00:42:14,896 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:14,897 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-03 and tpp_id = 1228776
2020-05-03 00:42:14,897 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-03 and tpp_id = 1228776
2020-05-03 00:42:14,897 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-03 00:42:14,897 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-03 00:42:14,898 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:42:14,898 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:42:14,898 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-03 00:42:14,898 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-03 00:42:16,017 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-03 and tpp_id = 672279
2020-05-03 00:42:16,017 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-03 and tpp_id = 672279
2020-05-03 00:42:16,018 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:16,018 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:16,019 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-03 00:42:16,019 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-03 00:42:16,019 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:16,019 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:17,656 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:17,656 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:17,658 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-03 00:42:17,658 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-03 00:42:17,687 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-03 00:42:17,687 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-03 00:42:17,700 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-03 00:42:17,700 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-03 00:42:17,710 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-03 00:42:17,710 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-03 00:42:17,717 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-03 00:42:17,717 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-03 00:42:17,718 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:17,718 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:17,718 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:17,718 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:17,718 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:17,718 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:17,718 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:17,718 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:17,718 -  log.py[line:110] - INFO: {'movieID': 1189325, 'movieName': '捉妖学院', 'seatRate': '4.5%', 'boxInfo': '100.90', 'boxRate': '0.3%', 'releaseInfo': '上映4天', 'showInfo': 131, 'showRate': '<0.1%', 'splitBoxInfo': '100.88', 'splitSumBoxInfo': '312.2', 'sumBoxInfo': '312.3', 'showView': '27', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#9'}
2020-05-03 00:42:17,719 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:17,851 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:17,882 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-03 00:42:17,890 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-03 00:42:20,308 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-03 00:42:20,308 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-03 00:42:20,342 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-03 00:42:20,345 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-03 00:42:20,349 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-03 00:42:20,352 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-03 and tpp_id = 1211412
2020-05-03 00:42:20,352 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-03 and tpp_id = 1211412
2020-05-03 00:42:20,352 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-03 00:42:20,352 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-03 00:42:20,352 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:20,352 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:20,352 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:20,352 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:20,353 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-03 and tpp_id = 1239544
2020-05-03 00:42:20,353 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-03 and tpp_id = 1239544
2020-05-03 00:42:20,354 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:20,354 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:20,354 -  movie_spider.py[line:162] - INFO: len of text is 6
2020-05-03 00:42:20,354 -  movie_spider.py[line:162] - INFO: len of text is 6
2020-05-03 00:42:20,354 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:20,354 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:21,711 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:21,711 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:21,721 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-03 00:42:21,721 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-03 00:42:21,724 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:21,724 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:21,724 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:21,724 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:21,725 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:21,725 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:21,726 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:21,727 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:21,727 -  log.py[line:110] - INFO: {'movieID': 1230152, 'movieName': '撞死了一只羊', 'seatRate': '9.2%', 'boxInfo': '57.30', 'boxRate': '0.1%', 'releaseInfo': '上映8天', 'showInfo': 1560, 'showRate': '0.4%', 'splitBoxInfo': '55.03', 'splitSumBoxInfo': '887.5', 'sumBoxInfo': '921.7', 'showView': '10', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#10'}
2020-05-03 00:42:21,729 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:21,935 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:21,936 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:21,936 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:21,963 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:21,963 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:21,978 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-03 00:42:23,923 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:23,923 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:23,927 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-03 00:42:23,927 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-03 00:42:23,942 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:23,942 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:23,944 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:23,944 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:23,944 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:23,944 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:23,944 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,944 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,944 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,944 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,945 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,945 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,947 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30170448
{'actors': '赞恩·阿尔·拉菲亚/约丹诺斯·希费罗/博鲁瓦蒂夫·特雷杰·班科尔/卡萨尔·艾尔·哈达德/法迪·尤瑟夫/海塔·塞德拉·伊扎姆/阿拉·乔什涅/娜丁·拉巴基/埃利亚斯·库利/努尔·艾尔·侯赛尼',
 'area': ' 黎巴嫩 / 法国 / 美国',
 'dbMovieID': ['30170448'],
 'directors': '娜丁·拉巴基',
 'doubanRate': ['9.1'],
 'duration': [126],
 'genre': '剧情',
 'movieName': ['何以为家 كفرناحوم'],
 'publishedDate': ['2018-05-17'],
 'rateCount': ['637925'],
 'tppMovieID': [1218727],
 'writers': '娜丁·拉巴基/吉哈德·霍加里/米歇尔·凯斯沃尼/乔治斯·哈巴兹/哈立德·穆扎纳'}
2020-05-03 00:42:23,948 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-03 00:42:23,948 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-03 00:42:23,961 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:23,961 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:23,963 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:23,963 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:23,963 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:23,963 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:23,963 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,963 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,963 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,963 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,964 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,964 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:23,979 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['832821'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-05-03 00:42:24,126 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-03 00:42:24,126 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-03 00:42:24,135 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:24,135 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:24,143 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:24,145 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:24,146 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-03 and tpp_id = 672379
2020-05-03 00:42:24,146 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-03 and tpp_id = 672379
2020-05-03 00:42:24,146 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-03 00:42:24,146 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-03 00:42:24,146 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:24,146 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:24,146 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:24,146 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:24,147 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:24,147 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:24,162 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:24,162 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:24,163 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:24,163 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:24,163 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:24,163 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:24,163 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,163 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,163 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,163 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,164 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,164 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,166 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26899146
{'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利',
 'area': ' 中国大陆',
 'dbMovieID': ['26899146'],
 'directors': '崔斯韦',
 'doubanRate': ['6.2'],
 'duration': [111],
 'genre': '动作/犯罪/悬疑',
 'movieName': ['雪暴'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['52310'],
 'tppMovieID': [672279],
 'writers': '崔斯韦'}
2020-05-03 00:42:24,166 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:24,166 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-03 00:42:24,179 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:24,179 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:24,180 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:24,180 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:24,180 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:24,180 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:24,180 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,180 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,181 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,181 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,181 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,181 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:24,183 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26899146
{'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利',
 'area': ' 中国大陆',
 'dbMovieID': ['26899146'],
 'directors': '崔斯韦',
 'doubanRate': ['6.2'],
 'duration': [111],
 'genre': '动作/犯罪/悬疑',
 'movieName': ['雪暴'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['52310'],
 'tppMovieID': [672279],
 'writers': '崔斯韦'}
2020-05-03 00:42:25,427 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:25,427 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:28,927 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-03 00:42:28,927 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-03 00:42:28,930 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:28,930 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:28,930 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:28,930 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:28,931 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:28,931 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:28,931 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:28,931 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:28,932 -  log.py[line:110] - INFO: {'movieID': 330115, 'movieName': '我和神马查干', 'seatRate': '--', 'boxInfo': '52.29', 'boxRate': '0.1%', 'releaseInfo': '', 'showInfo': 220, 'showRate': '<0.1%', 'splitBoxInfo': '52.13', 'splitSumBoxInfo': '2221.7', 'sumBoxInfo': '2229.5', 'showView': '75', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#11'}
2020-05-03 00:42:28,933 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:29,096 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:29,098 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:29,098 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:29,126 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-03 00:42:29,129 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:32,315 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-03 and tpp_id = 1189325
2020-05-03 00:42:32,315 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-03 and tpp_id = 1189325
2020-05-03 00:42:32,317 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-03 00:42:32,317 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-03 00:42:32,317 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:32,317 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:32,318 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:32,318 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:33,623 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:33,623 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:34,036 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-03 00:42:34,036 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-03 00:42:34,063 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:34,063 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:34,079 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:34,082 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:34,082 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:34,097 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:34,097 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:34,098 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:34,098 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:34,098 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:34,098 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:34,098 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,098 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,098 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,098 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,099 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,099 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,102 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30334073
{'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼',
 'area': ' 印度',
 'dbMovieID': ['30334073'],
 'directors': '斯里兰姆·拉格万',
 'doubanRate': ['8.3'],
 'duration': [139],
 'genre': '喜剧/犯罪/悬疑/惊悚',
 'movieName': ['调音师 Andhadhun'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['656350'],
 'tppMovieID': [1239544],
 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内'}
2020-05-03 00:42:34,102 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:34,102 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:34,115 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:34,115 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:34,117 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:34,117 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:34,117 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:34,117 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:34,117 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,117 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,117 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,117 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,118 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,118 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:34,121 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30334073
{'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼',
 'area': ' 印度',
 'dbMovieID': ['30334073'],
 'directors': '斯里兰姆·拉格万',
 'doubanRate': ['8.3'],
 'duration': [139],
 'genre': '喜剧/犯罪/悬疑/惊悚',
 'movieName': ['调音师 Andhadhun'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['656350'],
 'tppMovieID': [1239544],
 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内'}
2020-05-03 00:42:35,222 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:35,222 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:35,226 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-03 00:42:35,226 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-03 00:42:35,229 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:35,229 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:35,229 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:35,229 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:35,230 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:35,230 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:35,231 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:35,232 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:35,232 -  log.py[line:110] - INFO: {'movieID': 1243904, 'movieName': '动物出击', 'seatRate': '11.0%', 'boxInfo': '34.93', 'boxRate': '0.1%', 'releaseInfo': '上映4天', 'showInfo': 1615, 'showRate': '0.5%', 'splitBoxInfo': '32.87', 'splitSumBoxInfo': '295.2', 'sumBoxInfo': '304.7', 'showView': '7', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#12'}
2020-05-03 00:42:35,234 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:35,495 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:35,497 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:35,497 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:35,527 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-03 00:42:35,530 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:35,531 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-03 and tpp_id = 1230152
2020-05-03 00:42:35,531 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-03 and tpp_id = 1230152
2020-05-03 00:42:35,531 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-03 00:42:35,531 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-03 00:42:35,531 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:35,531 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:35,531 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:35,531 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:35,534 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:35,534 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:35,546 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:35,546 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:35,548 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:35,548 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:35,548 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:35,548 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:35,548 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:35,548 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:35,548 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:35,548 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:35,548 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:35,548 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:35,550 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-03 00:42:41,007 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-03 00:42:41,007 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-03 00:42:41,036 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-03 00:42:41,038 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-03 00:42:41,041 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:42,587 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:42,587 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:42,614 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:42,614 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:42,616 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:42,616 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:42,616 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:42,616 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:42,616 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,616 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,616 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,616 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,617 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,617 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,619 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-03 00:42:42,621 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-03 00:42:42,621 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-03 00:42:42,622 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:42,622 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:42,622 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:42,622 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:42,623 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:42,623 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:42,623 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:42,623 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:42,623 -  log.py[line:110] - INFO: {'movieID': 1228750, 'movieName': '照相师', 'seatRate': '78.0%', 'boxInfo': '26.20', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 55, 'showRate': '<0.1%', 'splitBoxInfo': '26.07', 'splitSumBoxInfo': '2121.7', 'sumBoxInfo': '2134.3', 'showView': '108', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#13'}
2020-05-03 00:42:42,624 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:42,780 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:42,783 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-03 00:42:42,793 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-03 and tpp_id = 330115
2020-05-03 00:42:42,793 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-03 and tpp_id = 330115
2020-05-03 00:42:42,794 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-03 00:42:42,794 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-03 00:42:42,794 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:42,794 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:42,795 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:42,795 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:42,798 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:42,798 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:42,822 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:42,822 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:42,823 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:42,823 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:42,824 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:42,824 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:42,824 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,824 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,824 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,824 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,824 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,824 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:42,828 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-03 00:42:45,392 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:45,392 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-03 00:42:45,416 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-03 00:42:45,416 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-03 00:42:45,434 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:45,434 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:45,435 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:45,435 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:45,435 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:45,435 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:45,435 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,435 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,436 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,436 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,436 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,436 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,440 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26311974
{'actors': '郭采洁/郑恺/李东学/谢依霖/刘心悠/邱欣怡/李荣浩/蓝心湄/林辰唏/林美秀',
 'area': ' 中国台湾 / 中国大陆',
 'dbMovieID': ['26311974'],
 'directors': '陈鸿仪',
 'doubanRate': ['2.8'],
 'duration': [99],
 'genre': '爱情',
 'movieName': ['下一任：前任'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['23790'],
 'tppMovieID': [1228776],
 'writers': '陈鸿仪'}
2020-05-03 00:42:45,440 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-03 and tpp_id = 1211727
2020-05-03 00:42:45,440 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-03 and tpp_id = 1211727
2020-05-03 00:42:45,441 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-03 00:42:45,441 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-03 00:42:45,441 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:45,441 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:45,441 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:45,441 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:45,442 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:45,442 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-03 00:42:45,451 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:45,451 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:42:45,452 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:45,452 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:42:45,452 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:45,452 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:42:45,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,453 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,453 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:42:45,455 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-03 00:42:46,716 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-03 00:42:46,716 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-03 00:42:46,719 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:46,719 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:46,719 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:46,719 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:46,720 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:46,720 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:46,721 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:46,722 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:46,722 -  log.py[line:110] - INFO: {'movieID': 1212492, 'movieName': '老师·好', 'seatRate': '18.5%', 'boxInfo': '23.87', 'boxRate': '<0.1%', 'releaseInfo': '重映43天', 'showInfo': 468, 'showRate': '0.1%', 'splitBoxInfo': '22.17', 'splitSumBoxInfo': '32600.0', 'sumBoxInfo': '35300.0', 'showView': '15', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#14'}
2020-05-03 00:42:46,724 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:46,891 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:46,894 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:49,827 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-03 and tpp_id = 1243904
2020-05-03 00:42:49,827 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-03 and tpp_id = 1243904
2020-05-03 00:42:49,829 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-03 00:42:49,829 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-03 00:42:49,830 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:49,830 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:49,830 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:49,830 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:50,073 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-03 00:42:50,073 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-03 00:42:50,103 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-03 00:42:50,103 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-03 00:42:50,104 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:50,104 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:50,104 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:50,104 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:50,105 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:50,105 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:50,105 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:50,106 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:50,106 -  log.py[line:110] - INFO: {'movieID': 1205909, 'movieName': '祈祷落幕时', 'seatRate': '20.1%', 'boxInfo': '22.95', 'boxRate': '<0.1%', 'releaseInfo': '上映22天', 'showInfo': 394, 'showRate': '0.1%', 'splitBoxInfo': '20.96', 'splitSumBoxInfo': '6053.5', 'sumBoxInfo': '6694.5', 'showView': '17', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#15'}
2020-05-03 00:42:50,107 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:50,328 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:50,329 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-03 and tpp_id = 1228750
2020-05-03 00:42:50,329 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-03 and tpp_id = 1228750
2020-05-03 00:42:50,329 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-03 00:42:50,329 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-03 00:42:50,330 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:50,330 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:50,330 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:50,330 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:50,803 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-03 00:42:50,804 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-03 00:42:50,804 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-03 00:42:50,832 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-03 00:42:50,832 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-03 00:42:50,834 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:50,834 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:50,834 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:50,834 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:50,835 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:50,835 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:50,836 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:50,837 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:50,837 -  log.py[line:110] - INFO: {'movieID': 476263, 'movieName': '天上再见', 'seatRate': '12.6%', 'boxInfo': '22.33', 'boxRate': '<0.1%', 'releaseInfo': '上映4天', 'showInfo': 688, 'showRate': '0.2%', 'splitBoxInfo': '20.53', 'splitSumBoxInfo': '80.7', 'sumBoxInfo': '86.5', 'showView': '9', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#16'}
2020-05-03 00:42:50,966 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:51,114 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:51,848 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/)
2020-05-03 00:42:51,849 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-03 and tpp_id = 1212492
2020-05-03 00:42:51,849 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-03 and tpp_id = 1212492
2020-05-03 00:42:51,850 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-03 00:42:51,850 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-03 00:42:51,850 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:51,850 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:51,850 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:51,850 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:51,854 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-03 00:42:51,854 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-03 00:42:51,885 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-03 00:42:51,885 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-03 00:42:51,886 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:51,886 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:51,886 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:51,886 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:51,887 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:51,887 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:51,887 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:51,888 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:51,888 -  log.py[line:110] - INFO: {'movieID': 1234116, 'movieName': '猫公主苏菲', 'seatRate': '4.5%', 'boxInfo': '17.42', 'boxRate': '<0.1%', 'releaseInfo': '上映3天', 'showInfo': 1833, 'showRate': '0.5%', 'splitBoxInfo': '16.31', 'splitSumBoxInfo': '78.2', 'sumBoxInfo': '83.7', 'showView': '4', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#17'}
2020-05-03 00:42:51,946 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:52,120 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:52,201 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-03 00:42:52,202 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-03 and tpp_id = 1205909
2020-05-03 00:42:52,202 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-03 and tpp_id = 1205909
2020-05-03 00:42:52,202 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-03 00:42:52,202 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-03 00:42:52,203 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:52,203 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:52,203 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:52,203 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:52,207 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-03 00:42:52,207 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-03 00:42:52,233 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-03 00:42:52,233 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-03 00:42:52,234 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:52,234 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:52,234 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:52,234 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:52,235 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:52,235 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:52,235 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:52,236 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:52,236 -  log.py[line:110] - INFO: {'movieID': 643506, 'movieName': '古镇画情', 'seatRate': '--', 'boxInfo': '15.88', 'boxRate': '<0.1%', 'releaseInfo': '展映', 'showInfo': 72, 'showRate': '<0.1%', 'splitBoxInfo': '15.87', 'splitSumBoxInfo': '1153.4', 'sumBoxInfo': '1156.3', 'showView': '59', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#18'}
2020-05-03 00:42:52,237 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:52,345 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:53,087 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2> (referer: https://movie.douban.com/)
2020-05-03 00:42:53,088 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-03 and tpp_id = 476263
2020-05-03 00:42:53,088 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-03 and tpp_id = 476263
2020-05-03 00:42:53,088 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-03 00:42:53,088 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-03 00:42:53,089 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:53,089 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:53,089 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:53,089 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:53,094 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-03 00:42:53,094 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-03 00:42:53,118 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-03 00:42:53,118 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-03 00:42:53,119 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:53,119 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:53,120 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:53,120 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:53,120 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:53,120 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:53,121 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:53,121 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:53,121 -  log.py[line:110] - INFO: {'movieID': 836, 'movieName': '毕业那年', 'seatRate': '--', 'boxInfo': '14.42', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 47, 'showRate': '<0.1%', 'splitBoxInfo': '14.39', 'splitSumBoxInfo': '1054.2', 'sumBoxInfo': '1055.9', 'showView': '96', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#19'}
2020-05-03 00:42:53,123 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:53,337 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:53,546 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/)
2020-05-03 00:42:53,547 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-03 and tpp_id = 1234116
2020-05-03 00:42:53,547 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-03 and tpp_id = 1234116
2020-05-03 00:42:53,547 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-03 00:42:53,547 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-03 00:42:53,548 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:53,548 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:53,548 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:53,548 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:53,553 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-03 00:42:53,553 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-03 00:42:53,577 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-03 00:42:53,577 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-03 00:42:53,579 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:53,579 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:53,579 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:53,579 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:53,580 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:53,580 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:53,580 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:53,580 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:53,581 -  log.py[line:110] - INFO: {'movieID': 1239281, 'movieName': '港珠澳大桥', 'seatRate': '4.4%', 'boxInfo': '13.94', 'boxRate': '<0.1%', 'releaseInfo': '上映3天', 'showInfo': 1700, 'showRate': '0.5%', 'splitBoxInfo': '13.13', 'splitSumBoxInfo': '77.5', 'sumBoxInfo': '81.3', 'showView': '3', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#20'}
2020-05-03 00:42:53,582 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:53,739 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:54,702 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-03 00:42:54,703 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-03 and tpp_id = 643506
2020-05-03 00:42:54,703 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-03 and tpp_id = 643506
2020-05-03 00:42:54,704 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-03 00:42:54,704 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-03 00:42:54,704 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:54,704 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:54,704 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:54,704 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:54,709 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-03 00:42:54,709 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-03 00:42:54,735 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-03 00:42:54,735 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-03 00:42:54,736 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:54,736 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:54,736 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:54,736 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:54,737 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:54,737 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:54,737 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:54,738 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:54,738 -  log.py[line:110] - INFO: {'movieID': 245881, 'movieName': '麦兜我和我妈妈', 'seatRate': '10.2%', 'boxInfo': '13.67', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 514, 'showRate': '0.1%', 'splitBoxInfo': '12.09', 'splitSumBoxInfo': '4636.8', 'sumBoxInfo': '4657.4', 'showView': '9', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#21'}
2020-05-03 00:42:54,739 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:54,916 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:55,757 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-03 00:42:55,758 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-03 and tpp_id = 836
2020-05-03 00:42:55,758 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-03 and tpp_id = 836
2020-05-03 00:42:55,758 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-03 00:42:55,758 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-03 00:42:55,759 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:55,759 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:55,759 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:55,759 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:55,760 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-03 00:42:55,760 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-03 00:42:55,767 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-03 00:42:55,767 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-03 00:42:55,768 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:55,768 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:55,768 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:55,768 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:55,769 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:55,769 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:55,769 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:55,769 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:55,769 -  log.py[line:110] - INFO: {'movieID': 1229702, 'movieName': '青蛙王子历险记', 'seatRate': '18.5%', 'boxInfo': '11.80', 'boxRate': '<0.1%', 'releaseInfo': '上映29天', 'showInfo': 93, 'showRate': '<0.1%', 'splitBoxInfo': '11.75', 'splitSumBoxInfo': '1053.1', 'sumBoxInfo': '1109.5', 'showView': '18', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#22'}
2020-05-03 00:42:55,770 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:55,878 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:56,467 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88> (referer: https://movie.douban.com/)
2020-05-03 00:42:56,468 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-03 and tpp_id = 1239281
2020-05-03 00:42:56,468 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-03 and tpp_id = 1239281
2020-05-03 00:42:56,468 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-03 00:42:56,468 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-03 00:42:56,469 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:56,469 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:56,469 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:56,469 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:56,474 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-03 00:42:56,474 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-03 00:42:56,499 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-03 00:42:56,499 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-03 00:42:56,500 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:56,500 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:56,500 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:56,500 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:56,501 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:56,501 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:56,501 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:56,502 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:56,502 -  log.py[line:110] - INFO: {'movieID': 248906, 'movieName': '流浪地球', 'seatRate': '14.1%', 'boxInfo': '9.61', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 231, 'showRate': '<0.1%', 'splitBoxInfo': '8.87', 'splitSumBoxInfo': '435400.0', 'sumBoxInfo': '468000.0', 'showView': '13', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#23'}
2020-05-03 00:42:56,503 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:56,635 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:57,611 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-03 00:42:57,611 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-03 and tpp_id = 245881
2020-05-03 00:42:57,611 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-03 and tpp_id = 245881
2020-05-03 00:42:57,612 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-03 00:42:57,612 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-03 00:42:57,612 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:57,612 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:57,612 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:57,612 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:57,613 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-03 00:42:57,613 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-03 00:42:57,619 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-03 00:42:57,619 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-03 00:42:57,620 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:57,620 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:57,620 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:57,620 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:57,620 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:57,620 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:57,621 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:57,621 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:57,621 -  log.py[line:110] - INFO: {'movieID': 1213175, 'movieName': '在乎你', 'seatRate': '3.2%', 'boxInfo': '9.53', 'boxRate': '<0.1%', 'releaseInfo': '上映22天', 'showInfo': 20, 'showRate': '<0.1%', 'splitBoxInfo': '9.53', 'splitSumBoxInfo': '723.4', 'sumBoxInfo': '755.2', 'showView': '69', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#24'}
2020-05-03 00:42:57,622 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:57,737 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:58,418 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/)
2020-05-03 00:42:58,419 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-03 and tpp_id = 1229702
2020-05-03 00:42:58,419 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-03 and tpp_id = 1229702
2020-05-03 00:42:58,420 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-03 00:42:58,420 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-03 00:42:58,420 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:58,420 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:58,420 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:58,420 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:58,425 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-03 00:42:58,425 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-03 00:42:58,452 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-03 00:42:58,452 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-03 00:42:58,453 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:58,453 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:58,453 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:58,453 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:58,454 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:58,454 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:58,454 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:58,455 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:58,455 -  log.py[line:110] - INFO: {'movieID': 1263355, 'movieName': '狗眼看人心', 'seatRate': '6.3%', 'boxInfo': '6.56', 'boxRate': '<0.1%', 'releaseInfo': '上映14天', 'showInfo': 363, 'showRate': '0.1%', 'splitBoxInfo': '6.09', 'splitSumBoxInfo': '1703.0', 'sumBoxInfo': '1834.3', 'showView': '6', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#25'}
2020-05-03 00:42:58,456 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:58,582 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:59,112 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-03 00:42:59,112 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-03 and tpp_id = 248906
2020-05-03 00:42:59,112 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-03 and tpp_id = 248906
2020-05-03 00:42:59,113 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-03 00:42:59,113 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-03 00:42:59,113 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:59,113 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:59,114 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:59,114 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:59,118 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-03 00:42:59,118 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-03 00:42:59,143 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-03 00:42:59,143 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-03 00:42:59,144 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:59,144 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:59,144 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:59,144 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:59,145 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:59,145 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:59,145 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:59,146 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:59,146 -  log.py[line:110] - INFO: {'movieID': 1167831, 'movieName': '波西米亚狂想曲', 'seatRate': '15.2%', 'boxInfo': '5.19', 'boxRate': '<0.1%', 'releaseInfo': '上映43天', 'showInfo': 91, 'showRate': '<0.1%', 'splitBoxInfo': '4.80', 'splitSumBoxInfo': '8944.6', 'sumBoxInfo': '9869.7', 'showView': '14', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#26'}
2020-05-03 00:42:59,147 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:42:59,284 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:42:59,929 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/)
2020-05-03 00:42:59,929 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-03 and tpp_id = 1213175
2020-05-03 00:42:59,929 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-03 and tpp_id = 1213175
2020-05-03 00:42:59,930 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-03 00:42:59,930 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-03 00:42:59,930 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:59,930 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:42:59,931 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:59,931 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:42:59,932 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-03 00:42:59,932 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-03 00:42:59,938 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-03 00:42:59,938 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-03 00:42:59,939 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:59,939 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:42:59,939 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:59,939 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:42:59,939 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:59,939 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:42:59,940 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:42:59,940 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:42:59,940 -  log.py[line:110] - INFO: {'movieID': 337625, 'movieName': '海蒂和爷爷', 'seatRate': '32.6%', 'boxInfo': '4.46', 'boxRate': '<0.1%', 'releaseInfo': '点映', 'showInfo': 30, 'showRate': '<0.1%', 'splitBoxInfo': '4.06', 'splitSumBoxInfo': '4.0', 'sumBoxInfo': '4.4', 'showView': '39', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#27'}
2020-05-03 00:43:00,016 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:43:00,188 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:43:01,070 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-03 00:43:01,071 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-03 and tpp_id = 1263355
2020-05-03 00:43:01,071 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-03 and tpp_id = 1263355
2020-05-03 00:43:01,071 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-03 00:43:01,071 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-03 00:43:01,071 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:43:01,071 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-03 00:43:01,072 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:43:01,072 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-03 00:43:01,101 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-03 00:43:01,101 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-03 00:43:01,102 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:01,102 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:01,102 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:43:01,102 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:43:01,102 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:01,102 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:01,103 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:43:01,103 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:43:01,103 -  log.py[line:110] - INFO: {'movieID': 1216383, 'movieName': '比悲伤更悲伤的故事', 'seatRate': '10.4%', 'boxInfo': '4.22', 'boxRate': '<0.1%', 'releaseInfo': '上映51天', 'showInfo': 234, 'showRate': '<0.1%', 'splitBoxInfo': '3.86', 'splitSumBoxInfo': '85800.0', 'sumBoxInfo': '95700.0', 'showView': '7', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#28'}
2020-05-03 00:43:01,105 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:43:01,458 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:43:02,003 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7> (referer: https://movie.douban.com/)
2020-05-03 00:43:02,004 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-03 and tpp_id = 1167831
2020-05-03 00:43:02,004 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-03 and tpp_id = 1167831
2020-05-03 00:43:02,005 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-03 00:43:02,005 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-03 00:43:02,005 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:02,005 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:02,006 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-03 00:43:02,006 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-03 00:43:03,504 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-03 00:43:03,504 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-03 00:43:03,532 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-03 00:43:03,532 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-03 00:43:03,549 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-03 00:43:03,549 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-03 00:43:03,550 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:03,550 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:03,550 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:43:03,550 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:43:03,550 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:03,550 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:03,551 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:43:03,551 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:43:03,551 -  log.py[line:110] - INFO: {'movieID': 1217701, 'movieName': '九克拉战栗', 'seatRate': '4.8%', 'boxInfo': '4.00', 'boxRate': '<0.1%', 'releaseInfo': '重映4天', 'showInfo': 437, 'showRate': '0.1%', 'splitBoxInfo': '3.64', 'splitSumBoxInfo': '27.2', 'sumBoxInfo': '29.4', 'showView': '4', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#29'}
2020-05-03 00:43:03,552 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:43:03,707 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:43:04,049 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/)
2020-05-03 00:43:04,050 -  movie_spider.py[line:156] - INFO: movie_name = 海蒂和爷爷 and movie_year = 2019-05-03 and tpp_id = 337625
2020-05-03 00:43:04,050 -  movie_spider.py[line:156] - INFO: movie_name = 海蒂和爷爷 and movie_year = 2019-05-03 and tpp_id = 337625
2020-05-03 00:43:04,050 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7
2020-05-03 00:43:04,050 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7
2020-05-03 00:43:04,050 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:04,050 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:04,051 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/25958717/?suggest=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7
2020-05-03 00:43:04,051 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/25958717/?suggest=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7
2020-05-03 00:43:05,663 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-03 00:43:05,663 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-03 00:43:05,681 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-03 00:43:05,681 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-03 00:43:05,682 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:05,682 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:05,682 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:43:05,682 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-03 00:43:05,682 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:05,682 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:05,682 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:43:05,683 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-03 00:43:05,683 -  log.py[line:110] - INFO: {'movieID': 319904, 'movieName': '盛世秧歌', 'seatRate': '--', 'boxInfo': '4.00', 'boxRate': '<0.1%', 'releaseInfo': '展映', 'showInfo': 4, 'showRate': '<0.1%', 'splitBoxInfo': '4.00', 'splitSumBoxInfo': '1388.1', 'sumBoxInfo': '1389.7', 'showView': '100', 'crawlDate': '2019-05-03', 'yearRate': '2019-05-03#30'}
2020-05-03 00:43:05,684 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:43:05,885 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190503>
None
2020-05-03 00:43:05,892 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-03 00:43:06,704 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C has been crawled, drop it
2020-05-03 00:43:06,704 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C has been crawled, drop it
2020-05-03 00:43:06,740 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25958717/?suggest=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7> (referer: https://movie.douban.com/)
2020-05-03 00:43:06,742 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-03 00:43:06,743 -  movie_spider.py[line:156] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-03 and tpp_id = 1216383
2020-05-03 00:43:06,743 -  movie_spider.py[line:156] - INFO: movie_name = 比悲伤更悲伤的故事 and movie_year = 2019-05-03 and tpp_id = 1216383
2020-05-03 00:43:06,743 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:06,743 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:06,743 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-03 00:43:06,743 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-03 00:43:06,743 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:06,743 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:08,226 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:08,226 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:08,227 -  logstats.py[line:48] - INFO: Crawled 43 pages (at 43 pages/min), scraped 30 items (at 30 items/min)
2020-05-03 00:43:08,234 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-03 00:43:08,234 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-03 00:43:08,258 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-03 00:43:08,258 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B has been crawled, drop it
2020-05-03 00:43:08,271 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C> (referer: https://movie.douban.com/)
2020-05-03 00:43:09,407 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-03 00:43:09,407 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/5300054/?suggest=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-03 00:43:09,450 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:09,450 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:09,452 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:09,452 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:09,452 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:09,452 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:09,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,452 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,453 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,453 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,461 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :5300054
{'actors': '拉米·马雷克/本·哈迪/约瑟夫·梅泽罗/格威利姆·李/艾伦·里奇/露西·宝通/艾丹·吉伦/汤姆·霍兰德/麦克·梅尔斯/阿隆·麦克卡斯克',
 'area': ' 英国 / 美国',
 'dbMovieID': ['5300054'],
 'directors': '布莱恩·辛格',
 'doubanRate': ['8.7'],
 'duration': [135],
 'genre': '剧情/传记/同性/音乐',
 'movieName': ['波西米亚狂想曲 Bohemian Rhapsody'],
 'publishedDate': ['2018-11-02'],
 'rateCount': ['399612'],
 'tppMovieID': [1167831],
 'writers': '安东尼·麦卡滕/皮特·摩根'}
2020-05-03 00:43:09,464 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/)
2020-05-03 00:43:09,465 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://movie.douban.com/)
2020-05-03 00:43:09,466 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/25958717/?suggest=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7
2020-05-03 00:43:09,466 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/25958717/?suggest=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7
2020-05-03 00:43:09,477 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:09,477 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:09,478 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:09,478 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:09,479 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:09,479 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:09,479 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,479 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,479 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,479 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,479 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,479 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:09,483 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:09,483 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:09,483 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-03 00:43:09,483 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-03 00:43:09,483 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:09,483 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:09,484 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:43:09,485 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-03 00:43:09,485 -  log.py[line:110] - INFO: {'dbMovieID': '25958717', 'tppMovieID': 337625, 'movieName': '海蒂和爷爷 Heidi', 'directors': '阿兰·葛斯彭纳', 'writers': '约翰娜·施皮里/佩特拉·比翁迪娜·沃尔普', 'actors': '阿努克·斯特芬/布鲁诺·甘茨/昆林·艾格匹/安娜·申茨/伊莎贝尔·奥特曼/莉莲·奈福/彼得·杰克林/克里斯托夫·高格勒/丽贝卡·因德穆/莫妮卡·古布瑟', 'genre': '剧情/冒险/家庭', 'area': ' 德国 / 瑞士 / 南非', 'duration': 111, 'publishedDate': '2015-12-10', 'rateCount': '257290', 'doubanRate': '9.2'}
2020-05-03 00:43:09,486 -  log.py[line:110] - INFO: COMMIT
2020-05-03 00:43:09,652 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/25958717/?suggest=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7>
None
2020-05-03 00:43:09,653 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-03 and tpp_id = 1217701
2020-05-03 00:43:09,653 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-03 and tpp_id = 1217701
2020-05-03 00:43:09,654 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-03 00:43:09,654 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-03 00:43:09,654 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:09,654 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:09,654 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-03 00:43:09,654 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-03 00:43:13,474 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-03 00:43:13,474 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-03 00:43:14,756 -  movie_spider.py[line:156] - INFO: movie_name = 盛世秧歌 and movie_year = 2019-05-03 and tpp_id = 319904
2020-05-03 00:43:14,756 -  movie_spider.py[line:156] - INFO: movie_name = 盛世秧歌 and movie_year = 2019-05-03 and tpp_id = 319904
2020-05-03 00:43:14,759 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-05-03 00:43:14,759 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-05-03 00:43:14,759 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:14,759 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-03 00:43:14,760 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-05-03 00:43:14,760 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-05-03 00:43:16,213 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-03 00:43:16,214 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:16,214 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3805946/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:16,251 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:16,251 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:16,253 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:16,253 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:16,253 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:16,253 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:16,253 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,253 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,253 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,253 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,254 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,254 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,257 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3805946
{'actors': '权相宇/李凡秀/李宝英/郑爱延/李瀚伟/申贤俊/池大汉/杨知元/金正碧/金景龙',
 'area': ' 韩国',
 'dbMovieID': ['3805946'],
 'directors': '元泰渊',
 'doubanRate': ['7.7'],
 'duration': [105],
 'genre': '爱情',
 'movieName': ['比悲伤更悲伤的故事 슬픔보다 더 슬픈 이야기'],
 'publishedDate': ['2009-03-12'],
 'rateCount': ['83027'],
 'tppMovieID': [1216383],
 'writers': '元泰渊'}
2020-05-03 00:43:16,257 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:16,257 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/27624661/?suggest=%E6%AF%94%E6%82%B2%E4%BC%A4%E6%9B%B4%E6%82%B2%E4%BC%A4%E7%9A%84%E6%95%85%E4%BA%8B
2020-05-03 00:43:16,277 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:16,277 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:16,279 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:16,279 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:16,279 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:16,279 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:16,279 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,279 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,279 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,279 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,280 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,280 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:16,283 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :27624661
{'actors': '陈意涵/刘以豪/张书豪/陈庭妮/吴映洁/禾浩辰/游大庆/石知田/黄丽玲/姚爱宁',
 'area': ' 中国台湾',
 'dbMovieID': ['27624661'],
 'directors': '林孝谦',
 'doubanRate': ['4.8'],
 'duration': [105],
 'genre': '爱情',
 'movieName': ['比悲伤更悲伤的故事 比悲傷更悲傷的故事'],
 'publishedDate': ['2018-11-30'],
 'rateCount': ['142555'],
 'tppMovieID': [1216383],
 'writers': '吕安弦'}
2020-05-03 00:43:16,285 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C has been crawled, drop it
2020-05-03 00:43:16,285 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C has been crawled, drop it
2020-05-03 00:43:18,965 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C> (referer: https://movie.douban.com/)
2020-05-03 00:43:18,974 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-03 00:43:18,974 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26989671/?suggest=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-03 00:43:18,998 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:18,998 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:19,000 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:19,000 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:19,000 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:19,000 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:19,000 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:19,000 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:19,000 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:19,000 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:19,001 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:19,001 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:19,002 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26989671
{'actors': '付然/于非/陆妍淇/鞠帛展',
 'area': ' 中国大陆',
 'dbMovieID': ['26989671'],
 'directors': '林峻兆',
 'doubanRate': [''],
 'duration': [86],
 'genre': '悬疑',
 'movieName': ['九克拉战栗'],
 'publishedDate': ['2019-12-18'],
 'rateCount': ['0'],
 'tppMovieID': [1217701],
 'writers': ''}
2020-05-03 00:43:20,550 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-05-03 00:43:20,550 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3023638/?suggest=%E7%9B%9B%E4%B8%96%E7%A7%A7%E6%AD%8C
2020-05-03 00:43:20,575 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:20,575 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-03 00:43:20,577 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:20,577 -  movie_spider.py[line:229] - INFO: finish parse one movie info, ready to parse person
2020-05-03 00:43:20,577 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:20,577 -  movie_spider.py[line:230] - INFO: test: 13
2020-05-03 00:43:20,577 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:20,577 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:20,577 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:20,577 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:20,577 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:20,577 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-03 00:43:20,579 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:20,579 -  pipelines.py[line:52] - INFO: item is new
2020-05-03 00:43:20,579 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-03 00:43:20,579 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.MovieInfoItem'>
2020-05-03 00:43:20,580 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:20,580 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-03 00:43:20,580 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-03 00:43:20,580 -  log.py[line:110] - INFO: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)
2020-05-03 00:43:20,580 -  log.py[line:110] - INFO: {'dbMovieID': '3023638', 'tppMovieID': 319904, 'movieName': '盛世秧歌', 'directors': '孙小茹', 'writers': '', 'actors': '季晨/朱子岩/嘉骏', 'genre': None, 'area': ' 中国大陆', 'duration': 0, 'publishedDate': '', 'rateCount': '0', 'doubanRate': ''}
2020-05-03 00:43:20,581 -  log.py[line:110] - INFO: ROLLBACK
2020-05-03 00:43:20,582 -  scraper.py[line:236] - ERROR: Error processing {'actors': '季晨/朱子岩/嘉骏',
 'area': ' 中国大陆',
 'dbMovieID': ['3023638'],
 'directors': '孙小茹',
 'doubanRate': [''],
 'duration': [0],
 'movieName': ['盛世秧歌'],
 'publishedDate': [''],
 'rateCount': ['0'],
 'tppMovieID': [319904],
 'writers': ''}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1048, "Column 'genre' cannot be null")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1048, "Column 'genre' cannot be null")
[SQL: INSERT INTO `movieInfo` (`dbMovieID`, `tppMovieID`, `movieName`, directors, writers, actors, genre, area, duration, `publishedDate`, `rateCount`, `doubanRate`) VALUES (%(dbMovieID)s, %(tppMovieID)s, %(movieName)s, %(directors)s, %(writers)s, %(actors)s, %(genre)s, %(area)s, %(duration)s, %(publishedDate)s, %(rateCount)s, %(doubanRate)s)]
[parameters: {'dbMovieID': '3023638', 'tppMovieID': 319904, 'movieName': '盛世秧歌', 'directors': '孙小茹', 'writers': '', 'actors': '季晨/朱子岩/嘉骏', 'genre': None, 'area': ' 中国大陆', 'duration': 0, 'publishedDate': '', 'rateCount': '0', 'doubanRate': ''}]
(Background on this error at: http://sqlalche.me/e/gkpj)
2020-05-03 00:43:21,799 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-05-03 00:43:21,803 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 58249,
 'downloader/request_count': 48,
 'downloader/request_method_count/GET': 48,
 'downloader/response_bytes': 407141,
 'downloader/response_count': 48,
 'downloader/response_status_count/200': 48,
 'elapsed_time_seconds': 75.868203,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 2, 16, 43, 21, 802079),
 'item_dropped_count': 15,
 'item_dropped_reasons_count/DropItem': 15,
 'item_scraped_count': 31,
 'log_count/ERROR': 66,
 'log_count/WARNING': 15,
 'memusage/max': 98959360,
 'memusage/startup': 73641984,
 'request_depth_max': 2,
 'response_received_count': 48,
 'scheduler/dequeued': 48,
 'scheduler/dequeued/memory': 48,
 'scheduler/enqueued': 48,
 'scheduler/enqueued/memory': 48,
 'start_time': datetime.datetime(2020, 5, 2, 16, 42, 5, 933876)}
2020-05-03 00:43:21,803 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-05-04 15:06:03,240 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-04 15:06:03,385 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-04 15:06:03,397 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-04 15:06:03,464 -  telnet.py[line:60] - INFO: Telnet Password: ac1f6842e1139c8a
2020-05-04 15:06:03,549 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-04 15:06:08,641 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-04 15:06:08,692 -  utils.py[line:88] - DEBUG: Sleeping for 0.1 seconds
2020-05-04 15:06:13,825 -  utils.py[line:80] - DEBUG: Error occurred during fetching https://www.w3schools.com/browsers/default.asp
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>
2020-05-04 15:06:13,843 -  _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2020-05-04 15:06:13,907 -  _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1319, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1252, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1298, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1247, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 966, in send
    self.connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 1414, in connect
    super().connect()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/http/client.py", line 938, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 67, in get
    context=context,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 543, in _open
    '_open', req)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 503, in _call_chain
    result = func(*args)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1362, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/urllib/request.py", line 1321, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 101] Network is unreachable>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 85, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/crawler.py", line 108, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/scrapy/spiders/__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 53, in __init__
    self.headers = get_random_headers()
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/spiders/movie_spider.py", line 41, in get_random_headers
    return {'User-Agent': str(UserAgent(use_cache_server=False).random)}
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 69, in __init__
    self.load()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/fake.py", line 78, in load
    verify_ssl=self.verify_ssl,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 250, in load_cached
    update(path, use_cache_server=use_cache_server, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 245, in update
    write(path, load(use_cache_server=use_cache_server, verify_ssl=verify_ssl))
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 178, in load
    raise exc
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/fake_useragent/utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2020-05-04 15:06:37,229 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-04 15:06:37,232 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-04 15:06:37,235 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-04 15:06:37,243 -  telnet.py[line:60] - INFO: Telnet Password: add6e1164961c5fc
2020-05-04 15:06:37,251 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-04 15:06:39,529 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-04 15:06:39,529 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-04 15:06:39,544 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.RefererMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-04 15:06:39,550 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-04 15:06:39,589 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-04 15:06:39,589 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-04 15:06:39,707 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.ItemPipeline', 'movie.pipelines.MySQLPipeline']
2020-05-04 15:06:39,707 -  engine.py[line:257] - INFO: Spider opened
2020-05-04 15:06:39,713 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-04 15:06:39,716 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6023
2020-05-04 15:06:39,754 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-04 15:06:39,754 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-04 15:06:39,948 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504> (referer: https://movie.douban.com/)
2020-05-04 15:06:40,424 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504
2020-05-04 15:06:40,424 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504
2020-05-04 15:06:40,449 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-04 15:06:40,449 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-04 15:06:40,453 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:40,453 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:40,453 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:40,453 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:40,459 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:40,459 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:40,492 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'sql_mode'
2020-05-04 15:06:40,492 -  log.py[line:110] - INFO: {}
2020-05-04 15:06:40,636 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'lower_case_table_names'
2020-05-04 15:06:40,636 -  log.py[line:110] - INFO: {}
2020-05-04 15:06:40,641 -  log.py[line:110] - INFO: SELECT DATABASE()
2020-05-04 15:06:40,642 -  log.py[line:110] - INFO: {}
2020-05-04 15:06:40,644 -  log.py[line:110] - INFO: show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'
2020-05-04 15:06:40,645 -  log.py[line:110] - INFO: {}
2020-05-04 15:06:40,660 -  log.py[line:110] - INFO: SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1
2020-05-04 15:06:40,660 -  log.py[line:110] - INFO: {}
2020-05-04 15:06:40,662 -  log.py[line:110] - INFO: SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1
2020-05-04 15:06:40,663 -  log.py[line:110] - INFO: {}
2020-05-04 15:06:40,665 -  log.py[line:110] - INFO: SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1
2020-05-04 15:06:40,665 -  log.py[line:110] - INFO: {}
2020-05-04 15:06:40,668 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:40,674 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:40,674 -  log.py[line:110] - INFO: {'movieID': 248172, 'movieName': '复仇者联盟4：终局之战', 'seatRate': '11.9%', 'boxInfo': '13697.73', 'boxRate': '70.5%', 'releaseInfo': '上映11天', 'showInfo': 180618, 'showRate': '58.2%', 'splitBoxInfo': '12953.76', 'splitSumBoxInfo': '364100.0', 'sumBoxInfo': '383600.0', 'showView': '16', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#1'}
2020-05-04 15:06:41,097 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:41,290 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:41,593 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:06:41,593 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:06:41,627 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-04 15:06:41,627 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-04 15:06:41,629 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:41,629 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:41,630 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:41,630 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:41,630 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:41,630 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:41,631 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:41,631 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:41,631 -  log.py[line:110] - INFO: {'movieID': 1218727, 'movieName': '何以为家', 'seatRate': '20.3%', 'boxInfo': '3000.61', 'boxRate': '15.4%', 'releaseInfo': '重映6天', 'showInfo': 47919, 'showRate': '15.4%', 'splitBoxInfo': '2736.98', 'splitSumBoxInfo': '13900.0', 'sumBoxInfo': '15200.0', 'showView': '20', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#2'}
2020-05-04 15:06:41,633 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:41,767 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:42,323 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:06:42,323 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:06:42,354 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-04 15:06:42,354 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-04 15:06:42,356 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:42,356 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:42,356 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:42,356 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:42,356 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:42,356 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:42,357 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:42,357 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:42,357 -  log.py[line:110] - INFO: {'movieID': 1228776, 'movieName': '下一任：前任', 'seatRate': '10.5%', 'boxInfo': '1003.62', 'boxRate': '5.1%', 'releaseInfo': '上映4天', 'showInfo': 32754, 'showRate': '10.5%', 'splitBoxInfo': '928.20', 'splitSumBoxInfo': '9386.4', 'sumBoxInfo': '10200.0', 'showView': '10', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#3'}
2020-05-04 15:06:42,359 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:42,460 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:43,226 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:06:43,226 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:06:43,253 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-04 15:06:43,253 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-04 15:06:43,253 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:43,253 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:43,254 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:43,254 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:43,254 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:43,254 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:43,254 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:43,254 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:43,254 -  log.py[line:110] - INFO: {'movieID': 1211412, 'movieName': '神奇乐园历险记', 'seatRate': '15.1%', 'boxInfo': '430.85', 'boxRate': '2.2%', 'releaseInfo': '上映16天', 'showInfo': 9048, 'showRate': '2.9%', 'splitBoxInfo': '398.55', 'splitSumBoxInfo': '4248.8', 'sumBoxInfo': '4577.1', 'showView': '15', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#4'}
2020-05-04 15:06:43,255 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:43,402 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:44,214 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:06:44,214 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:06:44,225 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-04 15:06:44,225 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-04 15:06:44,226 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:44,226 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:44,226 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:44,226 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:44,226 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:44,226 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:44,227 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:44,227 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:44,227 -  log.py[line:110] - INFO: {'movieID': 672379, 'movieName': '悟空奇遇记', 'seatRate': '8.5%', 'boxInfo': '270.71', 'boxRate': '1.3%', 'releaseInfo': '上映4天', 'showInfo': 12565, 'showRate': '4.0%', 'splitBoxInfo': '253.06', 'splitSumBoxInfo': '1649.9', 'sumBoxInfo': '1773.3', 'showView': '8', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#5'}
2020-05-04 15:06:44,228 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:44,612 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:45,483 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:06:45,483 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:06:45,509 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-04 15:06:45,509 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-04 15:06:45,511 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:45,511 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:45,511 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:45,511 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:45,511 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:45,511 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:45,512 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:45,512 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:45,512 -  log.py[line:110] - INFO: {'movieID': 672279, 'movieName': '雪暴', 'seatRate': '9.5%', 'boxInfo': '244.19', 'boxRate': '1.2%', 'releaseInfo': '上映5天', 'showInfo': 8725, 'showRate': '2.8%', 'splitBoxInfo': '225.80', 'splitSumBoxInfo': '1681.3', 'sumBoxInfo': '1798.3', 'showView': '8', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#6'}
2020-05-04 15:06:45,513 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:45,614 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:45,655 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-04 15:06:45,951 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:06:45,951 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:06:45,981 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-04 15:06:45,989 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-04 15:06:45,989 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-04 15:06:45,990 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:45,990 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:45,990 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:45,990 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:45,991 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:45,991 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:45,991 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:45,992 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:45,992 -  log.py[line:110] - INFO: {'movieID': 883196, 'movieName': '一个母亲的复仇', 'seatRate': '51.5%', 'boxInfo': '147.18', 'boxRate': '0.7%', 'releaseInfo': '点映', 'showInfo': 772, 'showRate': '0.2%', 'splitBoxInfo': '139.21', 'splitSumBoxInfo': '145.7', 'sumBoxInfo': '154.1', 'showView': '50', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#7'}
2020-05-04 15:06:46,087 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:46,343 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:46,347 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-04 15:06:46,347 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-04 and tpp_id = 248172
2020-05-04 15:06:46,347 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-04 and tpp_id = 248172
2020-05-04 15:06:46,348 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:06:46,348 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:06:46,348 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:46,348 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:46,349 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:06:46,349 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:06:47,869 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:06:47,869 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:06:47,875 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:06:47,875 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:06:47,883 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-04 15:06:47,885 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-04 and tpp_id = 1218727
2020-05-04 15:06:47,885 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-04 and tpp_id = 1218727
2020-05-04 15:06:47,885 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:06:47,885 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:06:47,885 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:47,885 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:47,886 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:06:47,886 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:06:49,754 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-04 15:06:49,754 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-04 15:06:49,757 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:49,757 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:49,758 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:49,758 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:49,759 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:49,759 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:49,759 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:49,760 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:49,761 -  log.py[line:110] - INFO: {'movieID': 1239544, 'movieName': '调音师', 'seatRate': '14.7%', 'boxInfo': '127.02', 'boxRate': '0.6%', 'releaseInfo': '上映32天', 'showInfo': 2715, 'showRate': '0.8%', 'splitBoxInfo': '116.00', 'splitSumBoxInfo': '29000.0', 'sumBoxInfo': '32100.0', 'showView': '14', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#8'}
2020-05-04 15:06:49,763 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:49,941 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:49,943 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:06:49,943 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:06:49,972 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87> (referer: https://movie.douban.com/)
2020-05-04 15:06:49,992 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-04 15:06:49,992 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-04 and tpp_id = 672279
2020-05-04 15:06:49,992 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-04 and tpp_id = 672279
2020-05-04 15:06:49,993 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:49,993 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:49,993 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-04 15:06:49,993 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-04 15:06:49,993 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:49,993 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:51,473 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:51,473 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:51,867 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 15:06:51,867 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 15:06:51,902 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:06:51,902 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:06:51,917 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:06:51,917 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:06:51,927 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 15:06:51,930 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-04 15:06:53,637 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-04 and tpp_id = 1228776
2020-05-04 15:06:53,637 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-04 and tpp_id = 1228776
2020-05-04 15:06:53,638 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:06:53,638 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:06:53,638 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:53,638 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:53,638 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:06:53,638 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:06:55,479 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-04 15:06:55,479 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-04 15:06:55,482 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:55,482 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:55,482 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:55,482 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:55,483 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:55,483 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:55,484 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:55,484 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:55,485 -  log.py[line:110] - INFO: {'movieID': 1211727, 'movieName': '反贪风暴4', 'seatRate': '11.6%', 'boxInfo': '100.59', 'boxRate': '0.5%', 'releaseInfo': '上映31天', 'showInfo': 2842, 'showRate': '0.9%', 'splitBoxInfo': '93.20', 'splitSumBoxInfo': '72800.0', 'sumBoxInfo': '78900.0', 'showView': '10', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#9'}
2020-05-04 15:06:55,574 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:55,724 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:55,726 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:06:55,726 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:06:55,754 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 15:06:55,758 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-04 15:06:55,759 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-04 and tpp_id = 883196
2020-05-04 15:06:55,759 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-04 and tpp_id = 883196
2020-05-04 15:06:55,759 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:06:55,759 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:06:55,760 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:55,760 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:06:55,760 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:06:55,760 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:06:57,387 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:06:57,387 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:06:57,431 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:06:57,431 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:06:57,433 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:06:57,433 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:06:57,433 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:57,433 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:57,433 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:57,433 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:57,434 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:57,434 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:57,434 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:57,434 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:57,434 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,434 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,435 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,435 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,435 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,435 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,435 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,435 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,436 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,436 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:57,436 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:57,436 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:57,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,437 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,437 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,437 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,437 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,437 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,437 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,439 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,439 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,439 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,439 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,439 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,439 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,440 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,449 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,450 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,452 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,454 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,457 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,457 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,457 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,457 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,457 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,457 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,459 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,460 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:57,462 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['833482'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-05-04 15:06:57,703 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-04 15:06:57,703 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-04 15:06:57,711 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:06:57,711 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:06:57,718 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 15:06:57,720 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-04 15:06:59,230 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-04 and tpp_id = 1211412
2020-05-04 15:06:59,230 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-04 and tpp_id = 1211412
2020-05-04 15:06:59,232 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:06:59,232 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:06:59,232 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:06:59,232 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:06:59,232 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:06:59,232 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:06:59,236 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:06:59,236 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:06:59,249 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:06:59,249 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:06:59,250 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:06:59,250 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:06:59,251 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,251 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,251 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:59,251 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:59,251 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,251 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,251 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,251 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,251 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,251 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,252 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,252 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,252 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,252 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,252 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,252 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,252 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,252 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,253 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,253 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,253 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,253 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,253 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,253 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,254 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,254 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,254 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,254 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,254 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,254 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,255 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,256 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30170448
{'actors': '赞恩·阿尔·拉菲亚/约丹诺斯·希费罗/博鲁瓦蒂夫·特雷杰·班科尔/卡萨尔·艾尔·哈达德/法迪·尤瑟夫/海塔·塞德拉·伊扎姆/阿拉·乔什涅/娜丁·拉巴基/埃利亚斯·库利/努尔·艾尔·侯赛尼',
 'area': ' 黎巴嫩 / 法国 / 美国',
 'dbMovieID': ['30170448'],
 'directors': '娜丁·拉巴基',
 'doubanRate': ['9.1'],
 'duration': [126],
 'genre': '剧情',
 'movieName': ['何以为家 كفرناحوم'],
 'publishedDate': ['2018-05-17'],
 'rateCount': ['638879'],
 'tppMovieID': [1218727],
 'writers': '娜丁·拉巴基/吉哈德·霍加里/米歇尔·凯斯沃尼/乔治斯·哈巴兹/哈立德·穆扎纳'}
2020-05-04 15:06:59,257 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-04 15:06:59,257 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-04 15:06:59,258 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:59,258 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:06:59,258 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:59,258 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:06:59,258 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:59,258 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:06:59,259 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:06:59,259 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:06:59,259 -  log.py[line:110] - INFO: {'movieID': 1230152, 'movieName': '撞死了一只羊', 'seatRate': '8.2%', 'boxInfo': '59.02', 'boxRate': '0.3%', 'releaseInfo': '上映9天', 'showInfo': 1562, 'showRate': '0.5%', 'splitBoxInfo': '57.28', 'splitSumBoxInfo': '944.7', 'sumBoxInfo': '980.7', 'showView': '10', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#10'}
2020-05-04 15:06:59,260 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:06:59,362 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:06:59,364 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-04 15:06:59,369 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87> (referer: https://movie.douban.com/)
2020-05-04 15:06:59,370 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-04 and tpp_id = 1239544
2020-05-04 15:06:59,370 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-04 and tpp_id = 1239544
2020-05-04 15:06:59,370 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 15:06:59,370 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 15:06:59,371 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:06:59,371 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:06:59,371 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:06:59,371 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:06:59,374 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:59,374 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:06:59,406 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:06:59,406 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:06:59,407 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:06:59,407 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:06:59,408 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,408 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,408 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:59,408 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:06:59,408 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,408 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,408 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,408 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:06:59,408 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,408 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:06:59,409 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,409 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,409 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,409 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,409 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,409 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,411 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,411 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,411 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,411 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,411 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,411 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,412 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,412 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,412 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,412 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:06:59,413 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26899146
{'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利',
 'area': ' 中国大陆',
 'dbMovieID': ['26899146'],
 'directors': '崔斯韦',
 'doubanRate': ['6.2'],
 'duration': [111],
 'genre': '动作/犯罪/悬疑',
 'movieName': ['雪暴'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['52323'],
 'tppMovieID': [672279],
 'writers': '崔斯韦'}
2020-05-04 15:07:00,986 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:07:00,986 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:07:02,311 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-04 and tpp_id = 672379
2020-05-04 15:07:02,311 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-04 and tpp_id = 672379
2020-05-04 15:07:02,312 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:07:02,312 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:07:02,313 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:02,313 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:02,313 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:02,313 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:02,317 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:07:02,317 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:07:02,353 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:02,353 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:02,355 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:02,355 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:02,355 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:02,355 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:02,355 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:02,355 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:02,355 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:02,355 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:02,355 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:02,355 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:02,356 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:02,356 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:02,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,358 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,358 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,358 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,358 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,358 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,358 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,359 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,359 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,359 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,359 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:02,360 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26311974
{'actors': '郭采洁/郑恺/李东学/谢依霖/刘心悠/邱欣怡/李荣浩/蓝心湄/林辰唏/林美秀',
 'area': ' 中国台湾 / 中国大陆',
 'dbMovieID': ['26311974'],
 'directors': '陈鸿仪',
 'doubanRate': ['2.8'],
 'duration': [99],
 'genre': '爱情',
 'movieName': ['下一任：前任'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['23802'],
 'tppMovieID': [1228776],
 'writers': '陈鸿仪'}
2020-05-04 15:07:02,363 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-04 15:07:02,363 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-04 15:07:02,364 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:02,364 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:02,364 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:02,364 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:02,364 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:02,364 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:02,365 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:02,365 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:02,365 -  log.py[line:110] - INFO: {'movieID': 1189325, 'movieName': '捉妖学院', 'seatRate': '2.7%', 'boxInfo': '50.23', 'boxRate': '0.2%', 'releaseInfo': '上映5天', 'showInfo': 126, 'showRate': '<0.1%', 'splitBoxInfo': '50.20', 'splitSumBoxInfo': '362.4', 'sumBoxInfo': '362.6', 'showView': '12', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#11'}
2020-05-04 15:07:02,366 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:02,508 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:02,513 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-04 15:07:03,755 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-04 and tpp_id = 1211727
2020-05-04 15:07:03,755 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-04 and tpp_id = 1211727
2020-05-04 15:07:03,757 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-04 15:07:03,757 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-04 15:07:03,758 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:03,758 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:03,758 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:03,758 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:03,761 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:07:03,761 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26996734/?suggest=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:07:03,783 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:03,783 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:03,784 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:03,784 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:03,784 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:03,784 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:03,785 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:03,785 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:03,785 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:03,785 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,785 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,786 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,787 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,787 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:03,788 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26996734
{'actors': '诗丽黛玮/阿克夏耶·坎纳/萨佳·阿里/阿德南·西德奎/纳瓦祖丁·席迪圭/乔伊·波德拉尼',
 'area': ' 印度',
 'dbMovieID': ['26996734'],
 'directors': '拉维·德耶瓦尔',
 'doubanRate': ['6.8'],
 'duration': [146],
 'genre': '剧情/犯罪',
 'movieName': ['一个母亲的复仇 Mom'],
 'publishedDate': ['2017-07-07'],
 'rateCount': ['73263'],
 'tppMovieID': [883196],
 'writers': '吉里什·科赫利/拉维·德耶瓦尔'}
2020-05-04 15:07:04,605 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 15:07:04,605 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 15:07:06,014 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-04 15:07:06,014 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-04 15:07:06,017 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:06,017 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:06,017 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:06,017 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:06,018 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:06,018 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:06,019 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:06,020 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:06,020 -  log.py[line:110] - INFO: {'movieID': 330115, 'movieName': '我和神马查干', 'seatRate': '--', 'boxInfo': '31.47', 'boxRate': '0.1%', 'releaseInfo': '', 'showInfo': 212, 'showRate': '<0.1%', 'splitBoxInfo': '31.42', 'splitSumBoxInfo': '2253.1', 'sumBoxInfo': '2261.0', 'showView': '49', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#12'}
2020-05-04 15:07:06,022 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:06,138 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:06,139 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-04 and tpp_id = 1230152
2020-05-04 15:07:06,139 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-04 and tpp_id = 1230152
2020-05-04 15:07:06,140 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:07:06,140 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:07:06,140 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:06,140 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:06,141 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:07:06,141 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:07:08,009 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-04 15:07:08,013 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-04 15:07:08,014 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 15:07:08,014 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 15:07:08,038 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:07:08,038 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:07:08,051 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-04 15:07:08,051 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-04 15:07:08,052 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:08,052 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:08,052 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:08,052 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:08,053 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:08,053 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:08,053 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:08,053 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:08,053 -  log.py[line:110] - INFO: {'movieID': 1228750, 'movieName': '照相师', 'seatRate': '85.8%', 'boxInfo': '30.61', 'boxRate': '0.1%', 'releaseInfo': '', 'showInfo': 57, 'showRate': '<0.1%', 'splitBoxInfo': '30.37', 'splitSumBoxInfo': '2152.1', 'sumBoxInfo': '2165.0', 'showView': '125', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#13'}
2020-05-04 15:07:08,054 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:08,152 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:08,327 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-04 15:07:08,328 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:07:08,328 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26899146/?suggest=%E9%9B%AA%E6%9A%B4
2020-05-04 15:07:08,365 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:08,365 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:08,367 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:08,367 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:08,367 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:08,367 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:08,367 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:08,367 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:08,367 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:08,367 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:08,368 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:08,368 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:08,368 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:08,368 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:08,368 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,368 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,368 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,368 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,369 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,369 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,369 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,369 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,369 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,369 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,370 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,370 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,370 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,370 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,370 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,370 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,371 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,371 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,371 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,371 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,371 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,371 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:08,372 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26899146
{'actors': '张震/倪妮/廖凡/黄觉/刘桦/张奕聪/李光洁/岳小军/昌隆/王太利',
 'area': ' 中国大陆',
 'dbMovieID': ['26899146'],
 'directors': '崔斯韦',
 'doubanRate': ['6.2'],
 'duration': [111],
 'genre': '动作/犯罪/悬疑',
 'movieName': ['雪暴'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['52323'],
 'tppMovieID': [672279],
 'writers': '崔斯韦'}
2020-05-04 15:07:08,373 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-04 and tpp_id = 1189325
2020-05-04 15:07:08,373 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-04 and tpp_id = 1189325
2020-05-04 15:07:08,373 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:07:08,373 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:07:08,373 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:08,373 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:08,373 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:07:08,373 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:07:09,519 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 15:07:09,519 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 15:07:09,534 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:07:09,534 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:07:09,540 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-04 15:07:09,540 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-04 15:07:09,541 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:09,541 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:09,541 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:09,541 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:09,541 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:09,541 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:09,541 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:09,542 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:09,542 -  log.py[line:110] - INFO: {'movieID': 1243904, 'movieName': '动物出击', 'seatRate': '7.2%', 'boxInfo': '26.03', 'boxRate': '0.1%', 'releaseInfo': '上映5天', 'showInfo': 1638, 'showRate': '0.5%', 'splitBoxInfo': '24.67', 'splitSumBoxInfo': '319.8', 'sumBoxInfo': '330.7', 'showView': '6', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#14'}
2020-05-04 15:07:09,543 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:09,642 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:09,648 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-04 15:07:12,031 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 15:07:12,031 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 15:07:12,061 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-04 15:07:12,063 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 15:07:12,067 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-04 and tpp_id = 330115
2020-05-04 15:07:12,067 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-04 and tpp_id = 330115
2020-05-04 15:07:12,068 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:07:12,068 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:07:12,068 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:12,068 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:12,068 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:07:12,068 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:07:13,426 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-04 15:07:13,426 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-04 15:07:13,429 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:13,429 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:13,429 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:13,429 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:13,430 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:13,430 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:13,431 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:13,432 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:13,432 -  log.py[line:110] - INFO: {'movieID': 476263, 'movieName': '天上再见', 'seatRate': '11.6%', 'boxInfo': '24.19', 'boxRate': '0.1%', 'releaseInfo': '上映5天', 'showInfo': 725, 'showRate': '0.2%', 'splitBoxInfo': '22.24', 'splitSumBoxInfo': '103.0', 'sumBoxInfo': '110.7', 'showView': '9', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#15'}
2020-05-04 15:07:13,434 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:13,534 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:13,536 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 15:07:13,536 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 15:07:13,564 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-04 15:07:13,565 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:07:13,565 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:07:13,585 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:13,585 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:13,586 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:13,586 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:13,586 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:13,586 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:13,586 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:13,586 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:13,587 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:13,587 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:13,587 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:13,587 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:13,587 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:13,587 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:13,587 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:13,587 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,588 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:13,589 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30283179
{'actors': '金巴/更登彭措/索朗旺姆/加华草',
 'area': ' 中国大陆',
 'dbMovieID': ['30283179'],
 'directors': '万玛才旦',
 'doubanRate': ['7.2'],
 'duration': [87],
 'genre': '剧情',
 'movieName': ['撞死了一只羊'],
 'publishedDate': ['2018-09-04'],
 'rateCount': ['40935'],
 'tppMovieID': [1230152],
 'writers': '万玛才旦/次仁罗布'}
2020-05-04 15:07:14,242 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-04 15:07:14,242 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-04 15:07:16,151 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:07:16,151 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:07:16,182 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:16,182 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:16,185 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:16,185 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:16,185 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:16,185 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:16,185 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:16,185 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:16,185 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:16,185 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:16,186 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:16,186 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:16,186 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:16,186 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:16,187 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:16,187 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:16,187 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,187 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,188 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,188 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,188 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,188 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,188 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,188 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:16,190 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26879542
{'actors': '王泽宗/慈婉彤/周海媚/胡昌霖',
 'area': ' 中国大陆',
 'dbMovieID': ['26879542'],
 'directors': '田梓橙',
 'doubanRate': [''],
 'duration': [96],
 'genre': '奇幻/冒险',
 'movieName': ['捉妖学院'],
 'publishedDate': ['2019-04-30'],
 'rateCount': ['0'],
 'tppMovieID': [1189325],
 'writers': '方岚/田梓橙'}
2020-05-04 15:07:16,191 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-04 and tpp_id = 1228750
2020-05-04 15:07:16,191 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-04 and tpp_id = 1228750
2020-05-04 15:07:16,191 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:16,191 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:16,191 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-04 15:07:16,191 -  movie_spider.py[line:162] - INFO: len of text is 2
2020-05-04 15:07:16,191 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:16,191 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:17,270 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:17,270 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:17,275 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-04 15:07:17,275 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-04 15:07:17,278 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:17,278 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:17,278 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:17,278 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:17,279 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:17,279 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:17,280 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:17,281 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:17,281 -  log.py[line:110] - INFO: {'movieID': 1212492, 'movieName': '老师·好', 'seatRate': '13.6%', 'boxInfo': '21.52', 'boxRate': '0.1%', 'releaseInfo': '重映44天', 'showInfo': 562, 'showRate': '0.1%', 'splitBoxInfo': '20.19', 'splitSumBoxInfo': '32700.0', 'sumBoxInfo': '35300.0', 'showView': '12', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#16'}
2020-05-04 15:07:17,283 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:17,392 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:17,395 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-04 15:07:17,401 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-04 15:07:18,703 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:07:18,703 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:07:18,730 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:07:18,730 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:07:20,404 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-04 and tpp_id = 1243904
2020-05-04 15:07:20,404 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-04 and tpp_id = 1243904
2020-05-04 15:07:20,404 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:07:20,404 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:07:20,405 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:20,405 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:07:20,405 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:07:20,405 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:07:23,142 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-04 15:07:23,142 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-04 15:07:23,148 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 15:07:23,148 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 15:07:23,156 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-04 15:07:23,156 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-04 15:07:23,157 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:23,157 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:23,157 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:23,157 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:23,157 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:23,157 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:23,157 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:23,158 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:23,158 -  log.py[line:110] - INFO: {'movieID': 1205909, 'movieName': '祈祷落幕时', 'seatRate': '14.5%', 'boxInfo': '18.26', 'boxRate': '<0.1%', 'releaseInfo': '上映23天', 'showInfo': 455, 'showRate': '0.1%', 'splitBoxInfo': '16.73', 'splitSumBoxInfo': '6070.2', 'sumBoxInfo': '6712.7', 'showView': '11', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#17'}
2020-05-04 15:07:23,158 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:23,267 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:23,268 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-04 and tpp_id = 476263
2020-05-04 15:07:23,268 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-04 and tpp_id = 476263
2020-05-04 15:07:23,269 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-04 15:07:23,269 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-04 15:07:23,269 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:23,269 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:23,269 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:23,269 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:23,272 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:07:23,272 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/20438453/?suggest=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:07:23,294 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:23,294 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:23,297 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:23,297 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:23,297 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:23,297 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:23,297 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:23,297 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:23,298 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:23,298 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:23,299 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:23,299 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:23,299 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:23,299 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:23,299 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:23,299 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:23,301 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :20438453
{'actors': '',
 'area': ' 中国大陆',
 'dbMovieID': ['20438453'],
 'directors': '侯克明/刘珅',
 'doubanRate': ['5.3'],
 'duration': [90],
 'genre': '剧情/儿童',
 'movieName': ['我和神马查干'],
 'publishedDate': ['2012-12-05'],
 'rateCount': ['54'],
 'tppMovieID': [330115],
 'writers': '刘珅'}
2020-05-04 15:07:24,162 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-04 15:07:24,169 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-04 15:07:24,174 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 15:07:24,180 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 15:07:25,609 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-04 15:07:25,609 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-04 15:07:25,639 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-04 15:07:25,639 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-04 15:07:25,641 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:25,641 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:25,641 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:25,641 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:25,642 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:25,642 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:25,642 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:25,643 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:25,643 -  log.py[line:110] - INFO: {'movieID': 1239281, 'movieName': '港珠澳大桥', 'seatRate': '5.8%', 'boxInfo': '15.79', 'boxRate': '<0.1%', 'releaseInfo': '上映4天', 'showInfo': 1613, 'showRate': '0.5%', 'splitBoxInfo': '15.05', 'splitSumBoxInfo': '92.5', 'sumBoxInfo': '97.1', 'showView': '4', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#18'}
2020-05-04 15:07:25,644 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:25,759 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:26,644 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/)
2020-05-04 15:07:26,645 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-04 and tpp_id = 1212492
2020-05-04 15:07:26,645 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-04 and tpp_id = 1212492
2020-05-04 15:07:26,646 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-04 15:07:26,646 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-04 15:07:26,646 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:26,646 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:26,646 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:26,646 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:26,650 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:07:26,650 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30345341/?suggest=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:07:26,679 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:26,679 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:26,681 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:26,681 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:26,681 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,681 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,681 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:26,681 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:26,681 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,681 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,681 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:26,681 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:26,682 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,682 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,682 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,682 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,682 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,682 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,682 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,682 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,683 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,683 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,683 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,683 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,684 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,684 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:26,684 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30345341
{'actors': '景熙童/宝德/冯冯/冯薇朵/陈长海/李浩轩',
 'area': ' 中国大陆',
 'dbMovieID': ['30345341'],
 'directors': '冯小宁',
 'doubanRate': ['3.4'],
 'duration': [105],
 'genre': '科幻/冒险',
 'movieName': ['动物出击'],
 'publishedDate': ['2019-04-30'],
 'rateCount': ['1954'],
 'tppMovieID': [1243904],
 'writers': '冯小宁'}
2020-05-04 15:07:26,685 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:26,685 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/34970135/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:26,690 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:26,690 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:26,691 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:26,691 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:26,691 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,691 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,691 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,691 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,691 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,691 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:26,692 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :34970135
{'actors': '',
 'area': ' 中国大陆',
 'dbMovieID': ['34970135'],
 'directors': '',
 'doubanRate': [''],
 'duration': [4],
 'genre': '短片',
 'movieName': ['照相师'],
 'publishedDate': [''],
 'rateCount': ['0'],
 'tppMovieID': [1228750],
 'writers': ''}
2020-05-04 15:07:28,125 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:28,125 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30258232/?suggest=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:07:28,139 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:28,139 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:07:28,140 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:28,140 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:07:28,141 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:28,141 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:28,141 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:28,141 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:07:28,141 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:28,141 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:28,141 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:28,141 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:07:28,141 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:28,141 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:07:28,141 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,141 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,142 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,143 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,144 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,144 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,144 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,144 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,144 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,144 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:07:28,145 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30258232
{'actors': '谢钢/刘牧/康磊/涓子/秦楚明/马东延/于卉怡/上泽/张优/方子怡',
 'area': ' 中国大陆',
 'dbMovieID': ['30258232'],
 'directors': '张唯',
 'doubanRate': ['5.2'],
 'duration': [112],
 'genre': '剧情/历史',
 'movieName': ['照相师'],
 'publishedDate': ['2018-12-12'],
 'rateCount': ['928'],
 'tppMovieID': [1228750],
 'writers': '张敏'}
2020-05-04 15:07:28,146 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-04 15:07:28,146 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-04 15:07:28,153 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-04 15:07:28,153 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-04 15:07:28,153 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:28,153 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:28,154 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:28,154 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:28,154 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:28,154 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:28,154 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:28,154 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:28,154 -  log.py[line:110] - INFO: {'movieID': 1234116, 'movieName': '猫公主苏菲', 'seatRate': '3.9%', 'boxInfo': '11.67', 'boxRate': '<0.1%', 'releaseInfo': '上映4天', 'showInfo': 1601, 'showRate': '0.5%', 'splitBoxInfo': '10.97', 'splitSumBoxInfo': '89.1', 'sumBoxInfo': '95.4', 'showView': '3', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#19'}
2020-05-04 15:07:28,155 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:28,307 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:32,577 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-04 15:07:32,580 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-04 15:07:32,580 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-04 15:07:32,597 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-04 and tpp_id = 1205909
2020-05-04 15:07:32,597 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-04 and tpp_id = 1205909
2020-05-04 15:07:32,597 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-04 15:07:32,597 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-04 15:07:32,597 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:32,597 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:32,597 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:32,597 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:32,602 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-04 15:07:32,602 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-04 15:07:32,603 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:32,603 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:32,603 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:32,603 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:32,604 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:32,604 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:32,604 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:32,605 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:32,605 -  log.py[line:110] - INFO: {'movieID': 245881, 'movieName': '麦兜我和我妈妈', 'seatRate': '8.2%', 'boxInfo': '10.74', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 515, 'showRate': '0.1%', 'splitBoxInfo': '9.57', 'splitSumBoxInfo': '4646.4', 'sumBoxInfo': '4668.1', 'showView': '7', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#20'}
2020-05-04 15:07:32,606 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:32,712 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:32,801 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2> (referer: https://movie.douban.com/)
2020-05-04 15:07:32,802 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-04 and tpp_id = 1239281
2020-05-04 15:07:32,802 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-04 and tpp_id = 1239281
2020-05-04 15:07:32,802 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-04 15:07:32,802 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-04 15:07:32,803 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:32,803 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:32,803 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:32,803 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:32,808 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-04 15:07:32,808 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-04 15:07:32,838 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-04 15:07:32,838 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-04 15:07:32,839 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:32,839 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:32,839 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:32,839 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:32,840 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:32,840 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:32,840 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:32,841 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:32,841 -  log.py[line:110] - INFO: {'movieID': 1213175, 'movieName': '在乎你', 'seatRate': '0.8%', 'boxInfo': '9.48', 'boxRate': '<0.1%', 'releaseInfo': '上映23天', 'showInfo': 27, 'showRate': '<0.1%', 'splitBoxInfo': '9.48', 'splitSumBoxInfo': '732.9', 'sumBoxInfo': '764.7', 'showView': '51', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#21'}
2020-05-04 15:07:32,842 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:32,954 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:33,079 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88> (referer: https://movie.douban.com/)
2020-05-04 15:07:33,080 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-04 and tpp_id = 1234116
2020-05-04 15:07:33,080 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-04 and tpp_id = 1234116
2020-05-04 15:07:33,081 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-04 15:07:33,081 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-04 15:07:33,081 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:33,081 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:33,081 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:33,081 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:33,086 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-04 15:07:33,086 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-04 15:07:33,112 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-04 15:07:33,112 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-04 15:07:33,113 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:33,113 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:33,113 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:33,113 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:33,114 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:33,114 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:33,114 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:33,114 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:33,115 -  log.py[line:110] - INFO: {'movieID': 1229702, 'movieName': '青蛙王子历险记', 'seatRate': '13.2%', 'boxInfo': '9.03', 'boxRate': '<0.1%', 'releaseInfo': '上映30天', 'showInfo': 83, 'showRate': '<0.1%', 'splitBoxInfo': '9.00', 'splitSumBoxInfo': '1062.1', 'sumBoxInfo': '1118.6', 'showView': '15', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#22'}
2020-05-04 15:07:33,151 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:33,324 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:33,439 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-04 15:07:33,440 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-04 and tpp_id = 245881
2020-05-04 15:07:33,440 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-04 and tpp_id = 245881
2020-05-04 15:07:33,441 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-04 15:07:33,441 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-04 15:07:33,441 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:33,441 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:33,441 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:33,441 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:33,446 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:07:33,446 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:07:33,472 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-04 15:07:33,472 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-04 15:07:33,473 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:33,473 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:33,473 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:33,473 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:33,474 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:33,474 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:33,474 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:33,475 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:33,475 -  log.py[line:110] - INFO: {'movieID': 643506, 'movieName': '古镇画情', 'seatRate': '--', 'boxInfo': '8.45', 'boxRate': '<0.1%', 'releaseInfo': '展映', 'showInfo': 74, 'showRate': '<0.1%', 'splitBoxInfo': '8.45', 'splitSumBoxInfo': '1161.9', 'sumBoxInfo': '1164.8', 'showView': '30', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#23'}
2020-05-04 15:07:33,476 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:33,632 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:33,983 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 15:07:33,984 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-04 and tpp_id = 1213175
2020-05-04 15:07:33,984 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-04 and tpp_id = 1213175
2020-05-04 15:07:33,984 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-04 15:07:33,984 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-04 15:07:33,984 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:33,984 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:33,984 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:33,984 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:33,985 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-04 15:07:33,985 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-04 15:07:33,992 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-04 15:07:33,992 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-04 15:07:33,993 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:33,993 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:33,993 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:33,993 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:33,993 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:33,993 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:33,993 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:33,993 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:33,993 -  log.py[line:110] - INFO: {'movieID': 836, 'movieName': '毕业那年', 'seatRate': '--', 'boxInfo': '8.11', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 46, 'showRate': '<0.1%', 'splitBoxInfo': '8.10', 'splitSumBoxInfo': '1062.3', 'sumBoxInfo': '1064.0', 'showView': '55', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#24'}
2020-05-04 15:07:33,994 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:34,103 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:34,774 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/)
2020-05-04 15:07:34,774 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-04 and tpp_id = 1229702
2020-05-04 15:07:34,774 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-04 and tpp_id = 1229702
2020-05-04 15:07:34,775 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:07:34,775 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:07:34,775 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:34,775 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:34,775 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:34,775 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:34,780 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-04 15:07:34,780 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-04 15:07:34,796 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-04 15:07:34,796 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-04 15:07:34,796 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:34,796 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:34,797 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:34,797 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:34,797 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:34,797 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:34,797 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:34,797 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:34,797 -  log.py[line:110] - INFO: {'movieID': 1216025, 'movieName': '欢迎来北方II', 'seatRate': '64.9%', 'boxInfo': '8.10', 'boxRate': '<0.1%', 'releaseInfo': '点映', 'showInfo': 30, 'showRate': '<0.1%', 'splitBoxInfo': '8.01', 'splitSumBoxInfo': '9.0', 'sumBoxInfo': '9.1', 'showView': '75', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#25'}
2020-05-04 15:07:34,798 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:34,900 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:35,526 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-04 15:07:35,527 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-04 and tpp_id = 643506
2020-05-04 15:07:35,527 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-04 and tpp_id = 643506
2020-05-04 15:07:35,527 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-04 15:07:35,527 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-04 15:07:35,528 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:35,528 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:35,528 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:35,528 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:35,561 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-04 15:07:35,561 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-04 15:07:35,563 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:35,563 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:35,563 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:35,563 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:35,564 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:35,564 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:35,564 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:35,565 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:35,565 -  log.py[line:110] - INFO: {'movieID': 248906, 'movieName': '流浪地球', 'seatRate': '8.6%', 'boxInfo': '6.34', 'boxRate': '<0.1%', 'releaseInfo': '', 'showInfo': 265, 'showRate': '<0.1%', 'splitBoxInfo': '5.86', 'splitSumBoxInfo': '435400.0', 'sumBoxInfo': '468000.0', 'showView': '8', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#26'}
2020-05-04 15:07:35,566 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:35,668 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:36,626 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II> (referer: https://movie.douban.com/)
2020-05-04 15:07:36,627 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-04 and tpp_id = 836
2020-05-04 15:07:36,627 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-04 and tpp_id = 836
2020-05-04 15:07:36,627 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-04 15:07:36,627 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-04 15:07:36,627 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:36,627 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:36,627 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:36,627 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:36,629 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-04 15:07:36,629 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-04 15:07:36,636 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-04 15:07:36,636 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-04 15:07:36,637 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:36,637 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:36,637 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:36,637 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:36,637 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:36,637 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:36,637 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:36,638 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:36,638 -  log.py[line:110] - INFO: {'movieID': 1263355, 'movieName': '狗眼看人心', 'seatRate': '4.9%', 'boxInfo': '4.94', 'boxRate': '<0.1%', 'releaseInfo': '上映15天', 'showInfo': 377, 'showRate': '0.1%', 'splitBoxInfo': '4.62', 'splitSumBoxInfo': '1707.6', 'sumBoxInfo': '1839.3', 'showView': '4', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#27'}
2020-05-04 15:07:36,638 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:36,744 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:36,991 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/)
2020-05-04 15:07:36,992 -  movie_spider.py[line:156] - INFO: movie_name = 欢迎来北方II and movie_year = 2019-05-04 and tpp_id = 1216025
2020-05-04 15:07:36,992 -  movie_spider.py[line:156] - INFO: movie_name = 欢迎来北方II and movie_year = 2019-05-04 and tpp_id = 1216025
2020-05-04 15:07:36,992 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II
2020-05-04 15:07:36,992 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II
2020-05-04 15:07:36,993 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:36,993 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:36,993 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:36,993 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:36,997 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-04 15:07:36,997 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-04 15:07:37,022 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-04 15:07:37,022 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-04 15:07:37,023 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:37,023 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:37,024 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:37,024 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:37,024 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:37,024 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:37,024 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:37,025 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:37,025 -  log.py[line:110] - INFO: {'movieID': 1167831, 'movieName': '波西米亚狂想曲', 'seatRate': '12.2%', 'boxInfo': '4.26', 'boxRate': '<0.1%', 'releaseInfo': '上映44天', 'showInfo': 103, 'showRate': '<0.1%', 'splitBoxInfo': '3.94', 'splitSumBoxInfo': '8948.6', 'sumBoxInfo': '9874.0', 'showView': '10', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#28'}
2020-05-04 15:07:37,026 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:37,133 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:37,182 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-04 and tpp_id = 248906
2020-05-04 15:07:37,182 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-04 and tpp_id = 248906
2020-05-04 15:07:37,183 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-04 15:07:37,183 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-04 15:07:37,183 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:37,183 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:37,184 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:37,184 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:37,188 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-04 15:07:37,188 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-04 15:07:37,218 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-04 15:07:37,218 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-04 15:07:37,219 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:37,219 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:37,219 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:37,219 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:37,220 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:37,220 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:37,220 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:37,221 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:37,221 -  log.py[line:110] - INFO: {'movieID': 1217701, 'movieName': '九克拉战栗', 'seatRate': '4.1%', 'boxInfo': '3.35', 'boxRate': '<0.1%', 'releaseInfo': '重映5天', 'showInfo': 443, 'showRate': '0.1%', 'splitBoxInfo': '3.05', 'splitSumBoxInfo': '30.2', 'sumBoxInfo': '32.8', 'showView': '3', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#29'}
2020-05-04 15:07:37,222 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:37,330 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:37,334 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/)
2020-05-04 15:07:37,727 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-04 15:07:37,727 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-04 15:07:37,760 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-04 15:07:37,763 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-04 15:07:37,763 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-04 15:07:37,764 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:37,764 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:07:37,764 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:37,764 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.BoxOfficeItem'>
2020-05-04 15:07:37,765 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:37,765 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:07:37,765 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:07:37,766 -  log.py[line:110] - INFO: INSERT INTO `boxOffice` (`movieID`, `movieName`, `seatRate`, `boxInfo`, `boxRate`, `releaseInfo`, `showInfo`, `showRate`, `splitBoxInfo`, `splitSumBoxInfo`, `sumBoxInfo`, `showView`, `crawlDate`, `yearRate`) VALUES (%(movieID)s, %(movieName)s, %(seatRate)s, %(boxInfo)s, %(boxRate)s, %(releaseInfo)s, %(showInfo)s, %(showRate)s, %(splitBoxInfo)s, %(splitSumBoxInfo)s, %(sumBoxInfo)s, %(showView)s, %(crawlDate)s, %(yearRate)s)
2020-05-04 15:07:37,766 -  log.py[line:110] - INFO: {'movieID': 1262087, 'movieName': '醒来之爱的呼唤', 'seatRate': '69.3%', 'boxInfo': '3.26', 'boxRate': '<0.1%', 'releaseInfo': '上映58天', 'showInfo': 18, 'showRate': '<0.1%', 'splitBoxInfo': '3.25', 'splitSumBoxInfo': '322.1', 'sumBoxInfo': '324.2', 'showView': '61', 'crawlDate': '2019-05-04', 'yearRate': '2019-05-04#30'}
2020-05-04 15:07:37,767 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:07:37,915 -  scraper.py[line:243] - DEBUG: Scraped from <200 http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504>
None
2020-05-04 15:07:37,918 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-04 15:07:37,919 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-04 and tpp_id = 1263355
2020-05-04 15:07:37,919 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-04 and tpp_id = 1263355
2020-05-04 15:07:37,919 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-04 15:07:37,919 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-04 15:07:37,919 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:37,919 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:37,920 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:37,920 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:37,968 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-04 and tpp_id = 1167831
2020-05-04 15:07:37,968 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-04 and tpp_id = 1167831
2020-05-04 15:07:37,968 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-04 15:07:37,968 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-04 15:07:37,968 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:37,968 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:37,968 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:37,968 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:38,020 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-04 and tpp_id = 1217701
2020-05-04 15:07:38,020 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-04 and tpp_id = 1217701
2020-05-04 15:07:38,020 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-04 15:07:38,020 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-04 15:07:38,020 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:38,020 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:38,021 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:38,021 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:38,069 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4> (referer: https://movie.douban.com/)
2020-05-04 15:07:38,172 -  movie_spider.py[line:156] - INFO: movie_name = 醒来之爱的呼唤 and movie_year = 2019-05-04 and tpp_id = 1262087
2020-05-04 15:07:38,172 -  movie_spider.py[line:156] - INFO: movie_name = 醒来之爱的呼唤 and movie_year = 2019-05-04 and tpp_id = 1262087
2020-05-04 15:07:38,172 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4
2020-05-04 15:07:38,172 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4
2020-05-04 15:07:38,173 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:38,173 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:07:38,173 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:38,173 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:07:38,177 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-05-04 15:07:38,179 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 52091,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 43,
 'downloader/response_bytes': 293256,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 43,
 'elapsed_time_seconds': 58.464522,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 4, 7, 7, 38, 177915),
 'item_dropped_count': 12,
 'item_dropped_reasons_count/DropItem': 12,
 'item_scraped_count': 30,
 'log_count/ERROR': 60,
 'log_count/WARNING': 12,
 'memusage/max': 73428992,
 'memusage/startup': 73428992,
 'request_depth_max': 2,
 'response_received_count': 43,
 'scheduler/dequeued': 43,
 'scheduler/dequeued/memory': 43,
 'scheduler/enqueued': 43,
 'scheduler/enqueued/memory': 43,
 'start_time': datetime.datetime(2020, 5, 4, 7, 6, 39, 713393)}
2020-05-04 15:07:38,179 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-05-04 15:34:27,808 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-04 15:34:27,812 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-04 15:34:27,815 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-04 15:34:27,822 -  telnet.py[line:60] - INFO: Telnet Password: a58c089fb138dd96
2020-05-04 15:34:27,830 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-04 15:34:27,976 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-04 15:34:27,976 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-04 15:34:27,980 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.RefererMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-04 15:34:27,981 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-04 15:34:27,988 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-04 15:34:27,988 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-04 15:34:28,001 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.ItemPipeline', 'movie.pipelines.MySQLPipeline']
2020-05-04 15:34:28,001 -  engine.py[line:257] - INFO: Spider opened
2020-05-04 15:34:28,003 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-04 15:34:28,003 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6023
2020-05-04 15:34:28,006 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-04 15:34:28,006 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-04 15:34:28,008 -  middlewares.py[line:144] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504 has been crawled, drop it
2020-05-04 15:34:28,008 -  middlewares.py[line:144] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504 has been crawled, drop it
2020-05-04 15:34:28,200 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504> (referer: https://movie.douban.com/)
2020-05-04 15:34:28,437 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504
2020-05-04 15:34:28,437 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504
2020-05-04 15:34:28,442 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-04 15:34:28,442 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-04 15:34:28,445 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#1
{'boxInfo': ['13697.73'],
 'boxRate': ['70.5%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [248172],
 'movieName': ['复仇者联盟4：终局之战'],
 'releaseInfo': ['上映11天'],
 'seatRate': ['11.9%'],
 'showInfo': [180618],
 'showRate': ['58.2%'],
 'showView': ['16'],
 'splitBoxInfo': ['12953.76'],
 'splitSumBoxInfo': ['364100.0'],
 'sumBoxInfo': ['383600.0'],
 'yearRate': ['2019-05-04#1']}
2020-05-04 15:34:29,236 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:34:29,236 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:34:29,265 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-04 15:34:29,265 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-04 15:34:29,267 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#2
{'boxInfo': ['3000.61'],
 'boxRate': ['15.4%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1218727],
 'movieName': ['何以为家'],
 'releaseInfo': ['重映6天'],
 'seatRate': ['20.3%'],
 'showInfo': [47919],
 'showRate': ['15.4%'],
 'showView': ['20'],
 'splitBoxInfo': ['2736.98'],
 'splitSumBoxInfo': ['13900.0'],
 'sumBoxInfo': ['15200.0'],
 'yearRate': ['2019-05-04#2']}
2020-05-04 15:34:29,411 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-04 15:34:29,411 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-04 15:34:29,414 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#3
{'boxInfo': ['1003.62'],
 'boxRate': ['5.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1228776],
 'movieName': ['下一任：前任'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['10.5%'],
 'showInfo': [32754],
 'showRate': ['10.5%'],
 'showView': ['10'],
 'splitBoxInfo': ['928.20'],
 'splitSumBoxInfo': ['9386.4'],
 'sumBoxInfo': ['10200.0'],
 'yearRate': ['2019-05-04#3']}
2020-05-04 15:34:29,422 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:34:29,422 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:34:29,447 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:34:29,447 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:34:29,459 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-04 15:34:29,459 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-04 15:34:29,460 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#4
{'boxInfo': ['430.85'],
 'boxRate': ['2.2%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1211412],
 'movieName': ['神奇乐园历险记'],
 'releaseInfo': ['上映16天'],
 'seatRate': ['15.1%'],
 'showInfo': [9048],
 'showRate': ['2.9%'],
 'showView': ['15'],
 'splitBoxInfo': ['398.55'],
 'splitSumBoxInfo': ['4248.8'],
 'sumBoxInfo': ['4577.1'],
 'yearRate': ['2019-05-04#4']}
2020-05-04 15:34:29,670 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-04 15:34:29,670 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-04 15:34:29,673 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#5
{'boxInfo': ['270.71'],
 'boxRate': ['1.3%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [672379],
 'movieName': ['悟空奇遇记'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['8.5%'],
 'showInfo': [12565],
 'showRate': ['4.0%'],
 'showView': ['8'],
 'splitBoxInfo': ['253.06'],
 'splitSumBoxInfo': ['1649.9'],
 'sumBoxInfo': ['1773.3'],
 'yearRate': ['2019-05-04#5']}
2020-05-04 15:34:30,558 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:30,558 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:30,589 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:30,589 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:30,605 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-04 15:34:30,605 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-04 15:34:30,606 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#6
{'boxInfo': ['244.19'],
 'boxRate': ['1.2%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [672279],
 'movieName': ['雪暴'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['9.5%'],
 'showInfo': [8725],
 'showRate': ['2.8%'],
 'showView': ['8'],
 'splitBoxInfo': ['225.80'],
 'splitSumBoxInfo': ['1681.3'],
 'sumBoxInfo': ['1798.3'],
 'yearRate': ['2019-05-04#6']}
2020-05-04 15:34:31,157 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-04 15:34:31,157 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-04 15:34:31,160 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#7
{'boxInfo': ['147.18'],
 'boxRate': ['0.7%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [883196],
 'movieName': ['一个母亲的复仇'],
 'releaseInfo': ['点映'],
 'seatRate': ['51.5%'],
 'showInfo': [772],
 'showRate': ['0.2%'],
 'showView': ['50'],
 'splitBoxInfo': ['139.21'],
 'splitSumBoxInfo': ['145.7'],
 'sumBoxInfo': ['154.1'],
 'yearRate': ['2019-05-04#7']}
2020-05-04 15:34:31,420 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:34:31,420 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:34:31,448 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:34:31,448 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:34:31,467 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-04 15:34:31,467 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-04 15:34:31,468 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#8
{'boxInfo': ['127.02'],
 'boxRate': ['0.6%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1239544],
 'movieName': ['调音师'],
 'releaseInfo': ['上映32天'],
 'seatRate': ['14.7%'],
 'showInfo': [2715],
 'showRate': ['0.8%'],
 'showView': ['14'],
 'splitBoxInfo': ['116.00'],
 'splitSumBoxInfo': ['29000.0'],
 'sumBoxInfo': ['32100.0'],
 'yearRate': ['2019-05-04#8']}
2020-05-04 15:34:32,320 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-04 15:34:32,320 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-04 15:34:32,323 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#9
{'boxInfo': ['100.59'],
 'boxRate': ['0.5%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1211727],
 'movieName': ['反贪风暴4'],
 'releaseInfo': ['上映31天'],
 'seatRate': ['11.6%'],
 'showInfo': [2842],
 'showRate': ['0.9%'],
 'showView': ['10'],
 'splitBoxInfo': ['93.20'],
 'splitSumBoxInfo': ['72800.0'],
 'sumBoxInfo': ['78900.0'],
 'yearRate': ['2019-05-04#9']}
2020-05-04 15:34:32,515 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-04 15:34:32,515 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-04 15:34:32,543 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 15:34:32,543 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 15:34:32,554 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-04 15:34:32,554 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-04 15:34:32,555 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#10
{'boxInfo': ['59.02'],
 'boxRate': ['0.3%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1230152],
 'movieName': ['撞死了一只羊'],
 'releaseInfo': ['上映9天'],
 'seatRate': ['8.2%'],
 'showInfo': [1562],
 'showRate': ['0.5%'],
 'showView': ['10'],
 'splitBoxInfo': ['57.28'],
 'splitSumBoxInfo': ['944.7'],
 'sumBoxInfo': ['980.7'],
 'yearRate': ['2019-05-04#10']}
2020-05-04 15:34:32,602 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-04 15:34:32,602 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-04 15:34:32,602 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#11
{'boxInfo': ['50.23'],
 'boxRate': ['0.2%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1189325],
 'movieName': ['捉妖学院'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['2.7%'],
 'showInfo': [126],
 'showRate': ['<0.1%'],
 'showView': ['12'],
 'splitBoxInfo': ['50.20'],
 'splitSumBoxInfo': ['362.4'],
 'sumBoxInfo': ['362.6'],
 'yearRate': ['2019-05-04#11']}
2020-05-04 15:34:33,538 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 15:34:33,538 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 15:34:33,543 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:34:33,543 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:34:33,570 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-04 15:34:33,581 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-04 15:34:33,590 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-04 15:34:33,592 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-04 15:34:33,592 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-04 15:34:33,592 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#12
{'boxInfo': ['31.47'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [330115],
 'movieName': ['我和神马查干'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [212],
 'showRate': ['<0.1%'],
 'showView': ['49'],
 'splitBoxInfo': ['31.42'],
 'splitSumBoxInfo': ['2253.1'],
 'sumBoxInfo': ['2261.0'],
 'yearRate': ['2019-05-04#12']}
2020-05-04 15:34:34,157 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 15:34:34,157 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 15:34:34,164 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-04 15:34:34,164 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-04 15:34:34,167 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#13
{'boxInfo': ['30.61'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1228750],
 'movieName': ['照相师'],
 'releaseInfo': [''],
 'seatRate': ['85.8%'],
 'showInfo': [57],
 'showRate': ['<0.1%'],
 'showView': ['125'],
 'splitBoxInfo': ['30.37'],
 'splitSumBoxInfo': ['2152.1'],
 'sumBoxInfo': ['2165.0'],
 'yearRate': ['2019-05-04#13']}
2020-05-04 15:34:34,645 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 15:34:34,647 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 15:34:34,653 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 15:34:34,655 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-04 15:34:34,658 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-04 15:34:34,662 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-04 15:34:34,662 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-04 15:34:34,664 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#14
{'boxInfo': ['26.03'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1243904],
 'movieName': ['动物出击'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['7.2%'],
 'showInfo': [1638],
 'showRate': ['0.5%'],
 'showView': ['6'],
 'splitBoxInfo': ['24.67'],
 'splitSumBoxInfo': ['319.8'],
 'sumBoxInfo': ['330.7'],
 'yearRate': ['2019-05-04#14']}
2020-05-04 15:34:35,470 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 15:34:35,470 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 15:34:35,480 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:34:35,480 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 15:34:35,486 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-04 and tpp_id = 1218727
2020-05-04 15:34:35,486 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-04 and tpp_id = 1218727
2020-05-04 15:34:35,486 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:34:35,486 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:34:35,486 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:35,486 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:35,486 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:34:35,486 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:34:37,353 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-04 and tpp_id = 1228776
2020-05-04 15:34:37,353 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-04 and tpp_id = 1228776
2020-05-04 15:34:37,354 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:34:37,354 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:34:37,354 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:37,354 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:37,354 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:34:37,354 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:34:38,389 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-04 and tpp_id = 248172
2020-05-04 15:34:38,389 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-04 and tpp_id = 248172
2020-05-04 15:34:38,390 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:34:38,390 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:34:38,390 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:38,390 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:38,391 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:34:38,391 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:34:39,399 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-04 15:34:39,399 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-04 15:34:39,402 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#15
{'boxInfo': ['24.19'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [476263],
 'movieName': ['天上再见'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['11.6%'],
 'showInfo': [725],
 'showRate': ['0.2%'],
 'showView': ['9'],
 'splitBoxInfo': ['22.24'],
 'splitSumBoxInfo': ['103.0'],
 'sumBoxInfo': ['110.7'],
 'yearRate': ['2019-05-04#15']}
2020-05-04 15:34:39,986 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-04 15:34:39,986 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-04 15:34:40,009 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:34:40,009 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:34:40,017 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:34:40,017 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:34:40,019 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:34:40,019 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:34:40,027 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87> (referer: https://movie.douban.com/)
2020-05-04 15:34:40,033 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-04 15:34:40,035 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-04 15:34:40,036 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-04 15:34:40,036 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 15:34:40,037 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-04 15:34:40,037 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-04 15:34:40,038 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#16
{'boxInfo': ['21.52'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1212492],
 'movieName': ['老师·好'],
 'releaseInfo': ['重映44天'],
 'seatRate': ['13.6%'],
 'showInfo': [562],
 'showRate': ['0.1%'],
 'showView': ['12'],
 'splitBoxInfo': ['20.19'],
 'splitSumBoxInfo': ['32700.0'],
 'sumBoxInfo': ['35300.0'],
 'yearRate': ['2019-05-04#16']}
2020-05-04 15:34:40,293 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-04 and tpp_id = 672379
2020-05-04 15:34:40,293 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-04 and tpp_id = 672379
2020-05-04 15:34:40,294 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:34:40,294 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:34:40,294 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:40,294 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:40,294 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:34:40,294 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:34:42,032 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-04 and tpp_id = 1211412
2020-05-04 15:34:42,032 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-04 and tpp_id = 1211412
2020-05-04 15:34:42,033 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:34:42,033 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:34:42,033 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:42,033 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:42,034 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:42,034 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:42,037 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-04 and tpp_id = 1239544
2020-05-04 15:34:42,037 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-04 and tpp_id = 1239544
2020-05-04 15:34:42,037 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 15:34:42,037 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 15:34:42,038 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:42,038 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:42,038 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:42,038 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:42,041 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-04 and tpp_id = 1189325
2020-05-04 15:34:42,041 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-04 and tpp_id = 1189325
2020-05-04 15:34:42,042 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:34:42,042 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 15:34:42,042 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:42,042 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:42,042 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:42,042 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:42,046 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-04 and tpp_id = 1230152
2020-05-04 15:34:42,046 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-04 and tpp_id = 1230152
2020-05-04 15:34:42,046 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:34:42,046 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:34:42,047 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:42,047 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 15:34:42,047 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:34:42,047 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:34:43,602 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:34:43,602 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 15:34:43,629 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:43,629 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:43,643 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-04 15:34:43,643 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-04 15:34:43,653 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-04 15:34:43,655 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-04 15:34:43,656 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-04 15:34:43,656 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-04 15:34:43,657 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#17
{'boxInfo': ['18.26'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1205909],
 'movieName': ['祈祷落幕时'],
 'releaseInfo': ['上映23天'],
 'seatRate': ['14.5%'],
 'showInfo': [455],
 'showRate': ['0.1%'],
 'showView': ['11'],
 'splitBoxInfo': ['16.73'],
 'splitSumBoxInfo': ['6070.2'],
 'sumBoxInfo': ['6712.7'],
 'yearRate': ['2019-05-04#17']}
2020-05-04 15:34:44,317 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-04 15:34:44,317 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-04 15:34:44,338 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,341 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,344 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,346 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,347 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,348 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-04 15:34:44,348 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-04 15:34:44,349 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#18
{'boxInfo': ['15.79'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1239281],
 'movieName': ['港珠澳大桥'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['5.8%'],
 'showInfo': [1613],
 'showRate': ['0.5%'],
 'showView': ['4'],
 'splitBoxInfo': ['15.05'],
 'splitSumBoxInfo': ['92.5'],
 'sumBoxInfo': ['97.1'],
 'yearRate': ['2019-05-04#18']}
2020-05-04 15:34:44,565 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-04 and tpp_id = 883196
2020-05-04 15:34:44,565 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-04 and tpp_id = 883196
2020-05-04 15:34:44,566 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:34:44,566 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 15:34:44,566 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,566 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,566 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,566 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,571 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-04 and tpp_id = 672279
2020-05-04 15:34:44,571 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-04 and tpp_id = 672279
2020-05-04 15:34:44,571 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-04 15:34:44,571 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-04 15:34:44,572 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,572 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,572 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,572 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,573 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-04 and tpp_id = 330115
2020-05-04 15:34:44,573 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-04 and tpp_id = 330115
2020-05-04 15:34:44,573 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:34:44,573 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 15:34:44,573 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,573 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,573 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,573 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,574 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-04 and tpp_id = 1243904
2020-05-04 15:34:44,574 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-04 and tpp_id = 1243904
2020-05-04 15:34:44,574 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:34:44,574 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 15:34:44,574 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,574 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,574 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,574 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,575 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-04 and tpp_id = 1228750
2020-05-04 15:34:44,575 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-04 and tpp_id = 1228750
2020-05-04 15:34:44,575 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:34:44,575 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 15:34:44,575 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,575 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,575 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,575 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,577 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-04 15:34:44,577 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-04 15:34:44,585 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,585 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,586 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-04 15:34:44,586 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-04 15:34:44,587 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#19
{'boxInfo': ['11.67'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1234116],
 'movieName': ['猫公主苏菲'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['3.9%'],
 'showInfo': [1601],
 'showRate': ['0.5%'],
 'showView': ['3'],
 'splitBoxInfo': ['10.97'],
 'splitSumBoxInfo': ['89.1'],
 'sumBoxInfo': ['95.4'],
 'yearRate': ['2019-05-04#19']}
2020-05-04 15:34:44,727 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-04 and tpp_id = 476263
2020-05-04 15:34:44,727 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-04 and tpp_id = 476263
2020-05-04 15:34:44,727 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-04 15:34:44,727 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-04 15:34:44,727 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,727 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:44,727 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,727 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:44,728 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:34:44,728 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 15:34:44,742 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:44,742 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:44,743 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:44,743 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:44,743 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:44,743 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:44,744 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:44,744 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:44,744 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:44,744 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:44,744 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:44,744 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:44,746 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:44,746 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:44,747 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'sql_mode'
2020-05-04 15:34:44,748 -  log.py[line:110] - INFO: {}
2020-05-04 15:34:44,750 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'lower_case_table_names'
2020-05-04 15:34:44,750 -  log.py[line:110] - INFO: {}
2020-05-04 15:34:44,752 -  log.py[line:110] - INFO: SELECT DATABASE()
2020-05-04 15:34:44,752 -  log.py[line:110] - INFO: {}
2020-05-04 15:34:44,753 -  log.py[line:110] - INFO: show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'
2020-05-04 15:34:44,753 -  log.py[line:110] - INFO: {}
2020-05-04 15:34:44,755 -  log.py[line:110] - INFO: SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1
2020-05-04 15:34:44,755 -  log.py[line:110] - INFO: {}
2020-05-04 15:34:44,756 -  log.py[line:110] - INFO: SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1
2020-05-04 15:34:44,756 -  log.py[line:110] - INFO: {}
2020-05-04 15:34:44,757 -  log.py[line:110] - INFO: SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1
2020-05-04 15:34:44,757 -  log.py[line:110] - INFO: {}
2020-05-04 15:34:44,758 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:44,760 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:44,760 -  log.py[line:110] - INFO: {'name': '安东尼·罗素 Anthony Russo', 'url': '/celebrity/1321812/', 'identity': 'director'}
2020-05-04 15:34:44,760 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:44,761 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['director'],
 'name': ['安东尼·罗素 Anthony Russo'],
 'url': ['/celebrity/1321812/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '安东尼·罗素 Anthony Russo', 'url': '/celebrity/1321812/', 'identity': 'director'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:44,953 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-04 15:34:44,953 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-04 15:34:44,960 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-04 15:34:44,960 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-04 15:34:44,960 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-04 15:34:44,961 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#20
{'boxInfo': ['10.74'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [245881],
 'movieName': ['麦兜我和我妈妈'],
 'releaseInfo': [''],
 'seatRate': ['8.2%'],
 'showInfo': [515],
 'showRate': ['0.1%'],
 'showView': ['7'],
 'splitBoxInfo': ['9.57'],
 'splitSumBoxInfo': ['4646.4'],
 'sumBoxInfo': ['4668.1'],
 'yearRate': ['2019-05-04#20']}
2020-05-04 15:34:45,393 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-04 and tpp_id = 1211727
2020-05-04 15:34:45,393 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-04 and tpp_id = 1211727
2020-05-04 15:34:45,393 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-04 15:34:45,393 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-04 15:34:45,394 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:45,394 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:45,394 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:45,394 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:45,395 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:34:45,395 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 15:34:45,407 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:45,407 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:45,409 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:45,409 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:45,409 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:45,409 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:45,409 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,409 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,410 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,410 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,410 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,410 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,410 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,410 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,410 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:45,410 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:45,410 -  warnings.py[line:110] - WARNING: /home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py:561: SAWarning: Session's state has been changed on a non-active transaction - this state will be discarded.
  "Session's state has been changed on "

2020-05-04 15:34:45,411 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:45,411 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:34:45,411 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 15:34:45,422 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:45,422 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:45,423 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:45,423 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:45,423 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:45,423 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:45,424 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,424 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,424 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,424 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,424 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,424 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,424 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,424 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,425 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:45,425 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:45,425 -  log.py[line:110] - INFO: {'name': '万玛才旦 Pema Tseden', 'url': '/celebrity/1316181/', 'identity': 'director'}
2020-05-04 15:34:45,426 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:45,541 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A>
None
2020-05-04 15:34:45,542 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:34:45,542 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 15:34:45,584 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:45,584 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:45,586 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:45,586 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:45,586 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:45,586 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:45,586 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,586 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,587 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,587 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,587 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,587 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,587 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,587 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,587 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:45,587 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:45,588 -  log.py[line:110] - INFO: {'name': '殷玉麒 Yuqi Yin', 'url': '/celebrity/1330909/', 'identity': 'director'}
2020-05-04 15:34:45,588 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:45,700 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-04 15:34:45,701 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-04 and tpp_id = 1212492
2020-05-04 15:34:45,701 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-04 and tpp_id = 1212492
2020-05-04 15:34:45,701 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-04 15:34:45,701 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-04 15:34:45,701 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:45,701 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:45,702 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:45,702 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:45,705 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,705 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:45,707 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,707 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:45,707 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,707 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:45,708 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,708 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:45,708 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:45,709 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:45,709 -  log.py[line:110] - INFO: {'name': '乔·罗素 Joe Russo', 'url': '/celebrity/1320870/', 'identity': 'director'}
2020-05-04 15:34:45,711 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:45,823 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:45,825 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-04 15:34:45,825 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-04 15:34:45,857 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2> (referer: https://movie.douban.com/)
2020-05-04 15:34:45,858 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-04 15:34:45,858 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-04 15:34:45,860 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#21
{'boxInfo': ['9.48'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1213175],
 'movieName': ['在乎你'],
 'releaseInfo': ['上映23天'],
 'seatRate': ['0.8%'],
 'showInfo': [27],
 'showRate': ['<0.1%'],
 'showView': ['51'],
 'splitBoxInfo': ['9.48'],
 'splitSumBoxInfo': ['732.9'],
 'sumBoxInfo': ['764.7'],
 'yearRate': ['2019-05-04#21']}
2020-05-04 15:34:46,795 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:34:46,795 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 15:34:46,807 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:46,807 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 15:34:46,808 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:46,808 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 15:34:46,809 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,809 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,809 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:46,809 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 15:34:46,809 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,809 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,809 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,809 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,810 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,810 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,810 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:46,810 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:46,810 -  log.py[line:110] - INFO: {'name': '娜丁·拉巴基 Nadine Labaki', 'url': '/celebrity/1275745/', 'identity': 'director'}
2020-05-04 15:34:46,811 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:46,811 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['director'],
 'name': ['娜丁·拉巴基 Nadine Labaki'],
 'url': ['/celebrity/1275745/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '娜丁·拉巴基 Nadine Labaki', 'url': '/celebrity/1275745/', 'identity': 'director'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:46,812 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-04 and tpp_id = 1205909
2020-05-04 15:34:46,812 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-04 and tpp_id = 1205909
2020-05-04 15:34:46,812 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-04 15:34:46,812 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-04 15:34:46,812 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:46,812 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:46,812 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:46,812 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:46,813 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,813 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,814 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,814 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,814 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :陈鸿仪 Hung-I Chen
{'identity': ['author'],
 'name': ['陈鸿仪 Hung-I Chen'],
 'url': ['/celebrity/1348355/']}
2020-05-04 15:34:46,814 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,814 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,815 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,815 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,815 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,815 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,815 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,815 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,815 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,815 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,815 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:46,815 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:46,816 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:46,816 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,816 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,816 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,816 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,816 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,816 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,817 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,817 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,817 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:46,817 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:46,817 -  log.py[line:110] - INFO: {'name': '郑恺 Kai Zheng', 'url': '/celebrity/1275564/', 'identity': 'actor'}
2020-05-04 15:34:46,818 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:46,951 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:46,952 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,952 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,953 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,953 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,955 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :万玛才旦 Pema Tseden
{'identity': ['author'],
 'name': ['万玛才旦 Pema Tseden'],
 'url': ['/celebrity/1316181/']}
2020-05-04 15:34:46,956 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,956 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,958 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,958 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,958 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,958 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,959 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,959 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,959 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:46,960 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:46,960 -  log.py[line:110] - INFO: {'name': '次仁罗布 Tsering Norbu', 'url': '/celebrity/1415681/', 'identity': 'author'}
2020-05-04 15:34:46,962 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:46,963 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['author'],
 'name': ['次仁罗布 Tsering Norbu'],
 'url': ['/celebrity/1415681/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '次仁罗布 Tsering Norbu', 'url': '/celebrity/1415681/', 'identity': 'author'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:46,966 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,966 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,967 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,967 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:46,969 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :殷玉麒 Yuqi Yin
{'identity': ['author'],
 'name': ['殷玉麒 Yuqi Yin'],
 'url': ['/celebrity/1330909/']}
2020-05-04 15:34:46,970 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,970 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:46,971 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,971 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,972 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,972 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,973 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,973 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,973 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,973 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,974 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:46,974 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:46,975 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-04 15:34:46,976 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,976 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:46,978 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,978 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:46,978 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,978 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:46,979 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,979 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:46,979 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:46,980 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:46,980 -  log.py[line:110] - INFO: {'name': '李姗姗 Shanshan Li', 'url': '/celebrity/1360420/', 'identity': 'actor'}
2020-05-04 15:34:46,982 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:47,144 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-04 15:34:47,145 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:47,145 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:47,168 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:47,168 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:47,170 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:47,170 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:47,170 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:47,170 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:47,171 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:47,171 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:47,172 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:47,172 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:47,173 -  log.py[line:110] - INFO: {'name': '克里斯托弗·马库斯 Christopher Markus', 'url': '/celebrity/1276125/', 'identity': 'author'}
2020-05-04 15:34:47,174 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:47,176 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['author'],
 'name': ['克里斯托弗·马库斯 Christopher Markus'],
 'url': ['/celebrity/1276125/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '克里斯托弗·马库斯 Christopher Markus', 'url': '/celebrity/1276125/', 'identity': 'author'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:47,180 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-04 15:34:47,180 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-04 15:34:47,209 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88> (referer: https://movie.douban.com/)
2020-05-04 15:34:47,210 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-04 15:34:47,210 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-04 15:34:47,211 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#22
{'boxInfo': ['9.03'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1229702],
 'movieName': ['青蛙王子历险记'],
 'releaseInfo': ['上映30天'],
 'seatRate': ['13.2%'],
 'showInfo': [83],
 'showRate': ['<0.1%'],
 'showView': ['15'],
 'splitBoxInfo': ['9.00'],
 'splitSumBoxInfo': ['1062.1'],
 'sumBoxInfo': ['1118.6'],
 'yearRate': ['2019-05-04#22']}
2020-05-04 15:34:48,031 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-04 and tpp_id = 1239281
2020-05-04 15:34:48,031 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-04 and tpp_id = 1239281
2020-05-04 15:34:48,031 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-04 15:34:48,031 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-04 15:34:48,031 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:48,031 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:48,032 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:48,032 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:48,033 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:48,033 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:48,033 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,033 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,034 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :娜丁·拉巴基 Nadine Labaki
{'identity': ['author'],
 'name': ['娜丁·拉巴基 Nadine Labaki'],
 'url': ['/celebrity/1275745/']}
2020-05-04 15:34:48,034 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,034 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,035 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,035 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,035 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,035 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,035 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,035 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,035 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,035 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,036 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6>
None
2020-05-04 15:34:48,036 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,036 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,036 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,036 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,036 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,036 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,037 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,037 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,037 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,037 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,037 -  log.py[line:110] - INFO: {'name': '米歇尔·凯斯沃尼 Michelle Keserwany', 'url': '/celebrity/1395543/', 'identity': 'author'}
2020-05-04 15:34:48,038 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:48,038 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['author'],
 'name': ['米歇尔·凯斯沃尼 Michelle Keserwany'],
 'url': ['/celebrity/1395543/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '米歇尔·凯斯沃尼 Michelle Keserwany', 'url': '/celebrity/1395543/', 'identity': 'author'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:48,039 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,039 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,040 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,040 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,040 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,040 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,040 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,040 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,040 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,040 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,040 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6>
None
2020-05-04 15:34:48,041 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,041 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,041 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,041 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,041 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,041 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,041 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,041 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,042 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,042 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,042 -  log.py[line:110] - INFO: {'name': '哈立德·穆扎纳 Khaled Mouzanar', 'url': '/celebrity/1393709/', 'identity': 'author'}
2020-05-04 15:34:48,042 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:48,043 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['author'],
 'name': ['哈立德·穆扎纳 Khaled Mouzanar'],
 'url': ['/celebrity/1393709/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '哈立德·穆扎纳 Khaled Mouzanar', 'url': '/celebrity/1393709/', 'identity': 'author'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:48,044 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,044 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,044 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,044 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,044 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,044 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,044 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,044 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,044 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,044 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,045 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:48,045 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,045 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,045 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,045 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,045 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,045 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,045 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,045 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,045 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,046 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,046 -  log.py[line:110] - INFO: {'name': '谢依霖 Yilin Sie', 'url': '/celebrity/1319858/', 'identity': 'actor'}
2020-05-04 15:34:48,046 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:48,212 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:48,213 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:48,213 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:48,214 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,214 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,215 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,215 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,215 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,215 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,216 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,216 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,217 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,218 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,218 -  log.py[line:110] - INFO: {'name': '金巴 Jinpa', 'url': '/celebrity/1362878/', 'identity': 'actor'}
2020-05-04 15:34:48,220 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:48,385 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A>
None
2020-05-04 15:34:48,386 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,386 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,387 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,387 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,388 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,388 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,388 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,388 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,389 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,390 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,390 -  log.py[line:110] - INFO: {'name': '元气纣  ', 'url': '/celebrity/1411430/', 'identity': 'actor'}
2020-05-04 15:34:48,392 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:48,516 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-04 15:34:48,518 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,518 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,519 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,519 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,520 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,520 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,520 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,520 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,521 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,522 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,522 -  log.py[line:110] - INFO: {'name': '斯蒂芬·麦克菲利 Stephen McFeely', 'url': '/celebrity/1276126/', 'identity': 'author'}
2020-05-04 15:34:48,523 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:48,526 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['author'],
 'name': ['斯蒂芬·麦克菲利 Stephen McFeely'],
 'url': ['/celebrity/1276126/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '斯蒂芬·麦克菲利 Stephen McFeely', 'url': '/celebrity/1276126/', 'identity': 'author'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:48,530 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:48,530 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:34:48,560 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-04 15:34:48,562 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-04 15:34:48,562 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-04 15:34:48,564 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#23
{'boxInfo': ['8.45'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [643506],
 'movieName': ['古镇画情'],
 'releaseInfo': ['展映'],
 'seatRate': ['--'],
 'showInfo': [74],
 'showRate': ['<0.1%'],
 'showView': ['30'],
 'splitBoxInfo': ['8.45'],
 'splitSumBoxInfo': ['1161.9'],
 'sumBoxInfo': ['1164.8'],
 'yearRate': ['2019-05-04#23']}
2020-05-04 15:34:48,699 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-04 and tpp_id = 1234116
2020-05-04 15:34:48,699 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-04 and tpp_id = 1234116
2020-05-04 15:34:48,700 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-04 15:34:48,700 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-04 15:34:48,700 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:48,700 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:48,700 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:48,700 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:48,704 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:48,704 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:48,705 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,705 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,707 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,707 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,707 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,707 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,708 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,708 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,708 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,708 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,710 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6>
None
2020-05-04 15:34:48,711 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,711 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,712 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,712 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,713 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,713 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,713 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,713 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,714 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,715 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,716 -  log.py[line:110] - INFO: {'name': '约丹诺斯·希费罗 Yordanos Shiferaw', 'url': '/celebrity/1411924/', 'identity': 'actor'}
2020-05-04 15:34:48,717 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:48,719 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['约丹诺斯·希费罗 Yordanos Shiferaw'],
 'url': ['/celebrity/1411924/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '约丹诺斯·希费罗 Yordanos Shiferaw', 'url': '/celebrity/1411924/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:48,722 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,722 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,724 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,724 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,724 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,724 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,725 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,725 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,725 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,725 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,726 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:48,728 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,728 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,729 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,729 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,729 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,729 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,730 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,730 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,731 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,731 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,732 -  log.py[line:110] - INFO: {'name': '邱欣怡 Xinyi Qiu', 'url': '/celebrity/1349465/', 'identity': 'actor'}
2020-05-04 15:34:48,733 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:48,836 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:48,837 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,837 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,838 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,838 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,839 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,839 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,839 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,839 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,840 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,841 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,841 -  log.py[line:110] - INFO: {'name': '更登彭措 Genden Phuntsok', 'url': '/celebrity/1363820/', 'identity': 'actor'}
2020-05-04 15:34:48,842 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:48,844 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['更登彭措 Genden Phuntsok'],
 'url': ['/celebrity/1363820/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '更登彭措 Genden Phuntsok', 'url': '/celebrity/1363820/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:48,847 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,847 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,849 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,849 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,849 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,849 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,850 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,850 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,850 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,850 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:48,851 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-04 15:34:48,853 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,853 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:48,854 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,854 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,854 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,854 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,855 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,855 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,856 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,856 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:48,857 -  log.py[line:110] - INFO: {'name': '叮当 Sheng Zhang', 'url': '/celebrity/1361373/', 'identity': 'actor'}
2020-05-04 15:34:48,858 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:48,994 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-04 15:34:48,996 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,996 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:48,997 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,997 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:48,998 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,998 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:48,998 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,998 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:48,999 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:48,999 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:49,000 -  log.py[line:110] - INFO: {'name': '斯坦·李 Stan Lee', 'url': '/celebrity/1013888/', 'identity': 'author'}
2020-05-04 15:34:49,002 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:49,104 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:49,106 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-04 15:34:49,106 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-04 15:34:49,137 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 15:34:49,140 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-04 15:34:49,140 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-04 15:34:49,142 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#24
{'boxInfo': ['8.11'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [836],
 'movieName': ['毕业那年'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [46],
 'showRate': ['<0.1%'],
 'showView': ['55'],
 'splitBoxInfo': ['8.10'],
 'splitSumBoxInfo': ['1062.3'],
 'sumBoxInfo': ['1064.0'],
 'yearRate': ['2019-05-04#24']}
2020-05-04 15:34:49,611 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-04 and tpp_id = 245881
2020-05-04 15:34:49,611 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-04 and tpp_id = 245881
2020-05-04 15:34:49,612 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-04 15:34:49,612 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-04 15:34:49,612 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:49,612 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:49,612 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:49,612 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:49,617 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,617 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,618 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,618 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,618 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,618 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,619 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,619 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,620 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:49,620 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:49,621 -  log.py[line:110] - INFO: {'name': '博鲁瓦蒂夫·特雷杰·班科尔 Boluwatife Treasure Bankole', 'url': '/celebrity/1395545/', 'identity': 'actor'}
2020-05-04 15:34:49,622 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:49,624 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['博鲁瓦蒂夫·特雷杰·班科尔 Boluwatife Treasure Bankole'],
 'url': ['/celebrity/1395545/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '博鲁瓦蒂夫·特雷杰·班科尔 Boluwatife Treasure Bankole', 'url': '/celebrity/1395545/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:49,627 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,627 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,628 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,628 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,629 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,629 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,629 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,629 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,630 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:49,630 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:49,631 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:49,632 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,632 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,634 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,634 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,634 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,634 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,635 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,635 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,635 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:49,636 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:49,636 -  log.py[line:110] - INFO: {'name': '蓝心湄 Pauline Lan', 'url': '/celebrity/1275579/', 'identity': 'actor'}
2020-05-04 15:34:49,639 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:49,819 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:49,821 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,821 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,822 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,822 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,823 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,823 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,823 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,823 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,824 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:49,824 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:49,825 -  log.py[line:110] - INFO: {'name': '索朗旺姆 Sonam Wangmo', 'url': '/celebrity/1400147/', 'identity': 'actor'}
2020-05-04 15:34:49,826 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:49,828 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['索朗旺姆 Sonam Wangmo'],
 'url': ['/celebrity/1400147/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '索朗旺姆 Sonam Wangmo', 'url': '/celebrity/1400147/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:49,831 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,831 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:49,833 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,833 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,833 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,833 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,834 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,834 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,834 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:49,834 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:49,837 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0>
None
2020-05-04 15:34:49,840 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26878827
{'actors': '张震/李姗姗/元气纣/宝木中阳/叮当/李璐',
 'area': ' 中国大陆',
 'dbMovieID': ['26878827'],
 'directors': '殷玉麒',
 'doubanRate': ['2.7'],
 'duration': [88],
 'genre': '喜剧/动画',
 'movieName': ['悟空奇遇记'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['712'],
 'tppMovieID': [672379],
 'writers': '殷玉麒'}
2020-05-04 15:34:49,842 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:49,842 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:49,844 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,844 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:49,844 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,844 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:49,845 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,845 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:49,846 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:49,846 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:49,847 -  log.py[line:110] - INFO: {'name': '杰克·科比 Jack Kirby', 'url': '/celebrity/1050183/', 'identity': 'author'}
2020-05-04 15:34:49,849 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:49,967 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:49,969 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-04 15:34:49,969 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-04 15:34:49,997 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/)
2020-05-04 15:34:50,000 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-04 15:34:50,000 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-04 15:34:50,002 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#25
{'boxInfo': ['8.10'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1216025],
 'movieName': ['欢迎来北方II'],
 'releaseInfo': ['点映'],
 'seatRate': ['64.9%'],
 'showInfo': [30],
 'showRate': ['<0.1%'],
 'showView': ['75'],
 'splitBoxInfo': ['8.01'],
 'splitSumBoxInfo': ['9.0'],
 'sumBoxInfo': ['9.1'],
 'yearRate': ['2019-05-04#25']}
2020-05-04 15:34:50,495 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-04 and tpp_id = 1213175
2020-05-04 15:34:50,495 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-04 and tpp_id = 1213175
2020-05-04 15:34:50,496 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-04 15:34:50,496 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-04 15:34:50,496 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:50,496 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:50,497 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:50,497 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:50,501 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,501 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,503 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,503 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,503 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,503 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,504 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,504 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,505 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:50,506 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:50,506 -  log.py[line:110] - INFO: {'name': '卡萨尔·艾尔·哈达德 Kawsar Al Haddad', 'url': '/celebrity/1411925/', 'identity': 'actor'}
2020-05-04 15:34:50,508 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:50,510 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['卡萨尔·艾尔·哈达德 Kawsar Al Haddad'],
 'url': ['/celebrity/1411925/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '卡萨尔·艾尔·哈达德 Kawsar Al Haddad', 'url': '/celebrity/1411925/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:50,514 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,514 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,515 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,515 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,515 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,515 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,516 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,516 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,516 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:50,516 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:50,518 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:50,519 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,519 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,520 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,520 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,521 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,521 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,521 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,521 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,522 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:50,523 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:50,523 -  log.py[line:110] - INFO: {'name': '林美秀 Mei-shiu Lin', 'url': '/celebrity/1316086/', 'identity': 'actor'}
2020-05-04 15:34:50,525 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:50,682 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:50,684 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,684 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:50,685 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,685 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:50,686 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,686 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:50,686 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,686 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:50,687 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:50,688 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:50,688 -  log.py[line:110] - INFO: {'name': '加华草 ', 'url': '/celebrity/1431565/', 'identity': 'actor'}
2020-05-04 15:34:50,690 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:50,817 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A>
None
2020-05-04 15:34:52,487 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:52,487 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 15:34:52,490 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:52,490 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:52,490 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:52,490 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:52,491 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:52,491 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:52,492 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:52,492 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:52,493 -  log.py[line:110] - INFO: {'name': '吉姆·斯特林 Jim Starlin', 'url': '/celebrity/1360715/', 'identity': 'author'}
2020-05-04 15:34:52,494 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:52,495 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['author'],
 'name': ['吉姆·斯特林 Jim Starlin'],
 'url': ['/celebrity/1360715/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '吉姆·斯特林 Jim Starlin', 'url': '/celebrity/1360715/', 'identity': 'author'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:52,499 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II has been crawled, drop it
2020-05-04 15:34:52,499 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II has been crawled, drop it
2020-05-04 15:34:52,525 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-04 15:34:52,526 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-04 15:34:52,526 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-04 15:34:52,528 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#26
{'boxInfo': ['6.34'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [248906],
 'movieName': ['流浪地球'],
 'releaseInfo': [''],
 'seatRate': ['8.6%'],
 'showInfo': [265],
 'showRate': ['<0.1%'],
 'showView': ['8'],
 'splitBoxInfo': ['5.86'],
 'splitSumBoxInfo': ['435400.0'],
 'sumBoxInfo': ['468000.0'],
 'yearRate': ['2019-05-04#26']}
2020-05-04 15:34:52,996 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-04 and tpp_id = 1229702
2020-05-04 15:34:52,996 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-04 and tpp_id = 1229702
2020-05-04 15:34:52,997 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:34:52,997 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 15:34:52,997 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:52,997 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:52,997 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:52,997 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:53,002 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:53,002 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:53,004 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:53,004 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:53,004 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:53,004 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:53,005 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:53,005 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:53,005 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:53,005 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:53,007 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6>
None
2020-05-04 15:34:53,008 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:53,008 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:53,009 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:53,009 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:53,010 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:53,010 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:53,010 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:53,010 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:53,012 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:53,013 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:53,013 -  log.py[line:110] - INFO: {'name': '海塔·塞德拉·伊扎姆 Haita &#39;Cedra&#39; Izzam', 'url': '/celebrity/1411927/', 'identity': 'actor'}
2020-05-04 15:34:53,015 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:53,016 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['海塔·塞德拉·伊扎姆 Haita &#39;Cedra&#39; Izzam'],
 'url': ['/celebrity/1411927/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '海塔·塞德拉·伊扎姆 Haita &#39;Cedra&#39; Izzam', 'url': '/celebrity/1411927/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:53,019 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:53,019 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:53,020 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:53,020 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:53,020 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:53,020 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:53,020 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:53,020 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:53,020 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:53,020 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:53,021 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB>
None
2020-05-04 15:34:53,022 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26311974
{'actors': '郭采洁/郑恺/李东学/谢依霖/刘心悠/邱欣怡/李荣浩/蓝心湄/林辰唏/林美秀',
 'area': ' 中国台湾 / 中国大陆',
 'dbMovieID': ['26311974'],
 'directors': '陈鸿仪',
 'doubanRate': ['2.8'],
 'duration': [99],
 'genre': '爱情',
 'movieName': ['下一任：前任'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['23802'],
 'tppMovieID': [1228776],
 'writers': '陈鸿仪'}
2020-05-04 15:34:54,463 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30283179
{'actors': '金巴/更登彭措/索朗旺姆/加华草',
 'area': ' 中国大陆',
 'dbMovieID': ['30283179'],
 'directors': '万玛才旦',
 'doubanRate': ['7.2'],
 'duration': [87],
 'genre': '剧情',
 'movieName': ['撞死了一只羊'],
 'publishedDate': ['2018-09-04'],
 'rateCount': ['40935'],
 'tppMovieID': [1230152],
 'writers': '万玛才旦/次仁罗布'}
2020-05-04 15:34:55,892 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:55,892 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 15:34:55,894 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:55,894 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:55,896 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:55,896 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:55,896 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:55,896 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:55,897 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:55,897 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:55,897 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:55,898 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:55,898 -  log.py[line:110] - INFO: {'name': '小罗伯特·唐尼 Robert Downey Jr.', 'url': '/celebrity/1016681/', 'identity': 'actor'}
2020-05-04 15:34:55,900 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:55,901 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['小罗伯特·唐尼 Robert Downey Jr.'],
 'url': ['/celebrity/1016681/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '小罗伯特·唐尼 Robert Downey Jr.', 'url': '/celebrity/1016681/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:55,905 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-04 15:34:55,905 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-04 15:34:55,928 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II> (referer: https://movie.douban.com/)
2020-05-04 15:34:55,930 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-04 15:34:55,930 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-04 15:34:55,931 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#27
{'boxInfo': ['4.94'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1263355],
 'movieName': ['狗眼看人心'],
 'releaseInfo': ['上映15天'],
 'seatRate': ['4.9%'],
 'showInfo': [377],
 'showRate': ['0.1%'],
 'showView': ['4'],
 'splitBoxInfo': ['4.62'],
 'splitSumBoxInfo': ['1707.6'],
 'sumBoxInfo': ['1839.3'],
 'yearRate': ['2019-05-04#27']}
2020-05-04 15:34:56,833 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-04 and tpp_id = 643506
2020-05-04 15:34:56,833 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-04 and tpp_id = 643506
2020-05-04 15:34:56,834 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-04 15:34:56,834 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-04 15:34:56,834 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:56,834 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:56,834 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:56,834 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:56,836 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,836 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,836 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:56,836 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:56,836 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:56,836 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:56,837 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:56,837 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:56,837 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:56,837 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:56,837 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6>
None
2020-05-04 15:34:56,838 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,838 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,838 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :娜丁·拉巴基 Nadine Labaki
{'identity': ['actor'],
 'name': ['娜丁·拉巴基 Nadine Labaki'],
 'url': ['/celebrity/1275745/']}
2020-05-04 15:34:56,839 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,839 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,839 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:56,839 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:56,839 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:56,839 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:56,839 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:56,839 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:56,840 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:56,840 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:56,840 -  log.py[line:110] - INFO: {'name': '埃利亚斯·库利 Elias Khoury', 'url': '/celebrity/1411929/', 'identity': 'actor'}
2020-05-04 15:34:56,840 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:56,841 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['埃利亚斯·库利 Elias Khoury'],
 'url': ['/celebrity/1411929/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '埃利亚斯·库利 Elias Khoury', 'url': '/celebrity/1411929/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:56,842 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,842 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:56,842 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:56,842 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:56,842 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:56,842 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:56,843 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:56,843 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:56,843 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:56,843 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:56,843 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6>
None
2020-05-04 15:34:56,844 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30170448
{'actors': '赞恩·阿尔·拉菲亚/约丹诺斯·希费罗/博鲁瓦蒂夫·特雷杰·班科尔/卡萨尔·艾尔·哈达德/法迪·尤瑟夫/海塔·塞德拉·伊扎姆/阿拉·乔什涅/娜丁·拉巴基/埃利亚斯·库利/努尔·艾尔·侯赛尼',
 'area': ' 黎巴嫩 / 法国 / 美国',
 'dbMovieID': ['30170448'],
 'directors': '娜丁·拉巴基',
 'doubanRate': ['9.1'],
 'duration': [126],
 'genre': '剧情',
 'movieName': ['何以为家 كفرناحوم'],
 'publishedDate': ['2018-05-17'],
 'rateCount': ['638879'],
 'tppMovieID': [1218727],
 'writers': '娜丁·拉巴基/吉哈德·霍加里/米歇尔·凯斯沃尼/乔治斯·哈巴兹/哈立德·穆扎纳'}
2020-05-04 15:34:58,477 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,477 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,481 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,481 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,481 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,481 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,481 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,481 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,482 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:58,483 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:58,483 -  log.py[line:110] - INFO: {'name': '克里斯·埃文斯 Chris Evans', 'url': '/celebrity/1017885/', 'identity': 'actor'}
2020-05-04 15:34:58,484 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:58,486 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['克里斯·埃文斯 Chris Evans'],
 'url': ['/celebrity/1017885/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '克里斯·埃文斯 Chris Evans', 'url': '/celebrity/1017885/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:58,490 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-04 15:34:58,490 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-04 15:34:58,511 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/)
2020-05-04 15:34:58,512 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-04 15:34:58,512 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-04 15:34:58,514 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#28
{'boxInfo': ['4.26'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1167831],
 'movieName': ['波西米亚狂想曲'],
 'releaseInfo': ['上映44天'],
 'seatRate': ['12.2%'],
 'showInfo': [103],
 'showRate': ['<0.1%'],
 'showView': ['10'],
 'splitBoxInfo': ['3.94'],
 'splitSumBoxInfo': ['8948.6'],
 'sumBoxInfo': ['9874.0'],
 'yearRate': ['2019-05-04#28']}
2020-05-04 15:34:58,683 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-04 and tpp_id = 836
2020-05-04 15:34:58,683 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-04 and tpp_id = 836
2020-05-04 15:34:58,683 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-04 15:34:58,683 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-04 15:34:58,684 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:58,684 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:58,684 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:58,684 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:58,691 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,691 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,693 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,693 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,693 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,693 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,694 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,694 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,694 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:58,694 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:58,695 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:58,696 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,696 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,698 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,698 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,698 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,698 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,699 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,699 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,700 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:58,700 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:58,701 -  log.py[line:110] - INFO: {'name': '克里斯·海姆斯沃斯 Chris Hemsworth', 'url': '/celebrity/1021959/', 'identity': 'actor'}
2020-05-04 15:34:58,702 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:58,704 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['克里斯·海姆斯沃斯 Chris Hemsworth'],
 'url': ['/celebrity/1021959/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '克里斯·海姆斯沃斯 Chris Hemsworth', 'url': '/celebrity/1021959/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:58,710 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-04 15:34:58,710 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-04 15:34:58,731 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/)
2020-05-04 15:34:58,731 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-04 15:34:58,731 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-04 15:34:58,732 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#29
{'boxInfo': ['3.35'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1217701],
 'movieName': ['九克拉战栗'],
 'releaseInfo': ['重映5天'],
 'seatRate': ['4.1%'],
 'showInfo': [443],
 'showRate': ['0.1%'],
 'showView': ['3'],
 'splitBoxInfo': ['3.05'],
 'splitSumBoxInfo': ['30.2'],
 'sumBoxInfo': ['32.8'],
 'yearRate': ['2019-05-04#29']}
2020-05-04 15:34:58,781 -  movie_spider.py[line:156] - INFO: movie_name = 欢迎来北方II and movie_year = 2019-05-04 and tpp_id = 1216025
2020-05-04 15:34:58,781 -  movie_spider.py[line:156] - INFO: movie_name = 欢迎来北方II and movie_year = 2019-05-04 and tpp_id = 1216025
2020-05-04 15:34:58,781 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II
2020-05-04 15:34:58,781 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II
2020-05-04 15:34:58,782 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:58,782 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:58,782 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:58,782 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:58,785 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,785 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,785 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,785 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,786 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,786 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,786 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,786 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,786 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:58,786 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:58,787 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:58,787 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,787 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,788 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,788 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,788 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,788 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,788 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,788 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,788 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:58,789 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:58,789 -  log.py[line:110] - INFO: {'name': '杰瑞米·雷纳 Jeremy Renner', 'url': '/celebrity/1013770/', 'identity': 'actor'}
2020-05-04 15:34:58,789 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:58,790 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['杰瑞米·雷纳 Jeremy Renner'],
 'url': ['/celebrity/1013770/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '杰瑞米·雷纳 Jeremy Renner', 'url': '/celebrity/1013770/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:58,792 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,792 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,792 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,792 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,792 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,792 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,793 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,793 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,793 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:58,793 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:58,793 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:58,794 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,794 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:58,794 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,794 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:58,794 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,794 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:58,795 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,795 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:58,795 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:58,795 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:58,795 -  log.py[line:110] - INFO: {'name': '凯伦·吉兰 Karen Gillan', 'url': '/celebrity/1036344/', 'identity': 'actor'}
2020-05-04 15:34:58,796 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:58,796 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['凯伦·吉兰 Karen Gillan'],
 'url': ['/celebrity/1036344/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '凯伦·吉兰 Karen Gillan', 'url': '/celebrity/1036344/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:58,798 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-04 15:34:58,798 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-04 15:34:58,811 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-04 15:34:58,812 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-04 15:34:58,812 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-04 15:34:58,813 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#30
{'boxInfo': ['3.26'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1262087],
 'movieName': ['醒来之爱的呼唤'],
 'releaseInfo': ['上映58天'],
 'seatRate': ['69.3%'],
 'showInfo': [18],
 'showRate': ['<0.1%'],
 'showView': ['61'],
 'splitBoxInfo': ['3.25'],
 'splitSumBoxInfo': ['322.1'],
 'sumBoxInfo': ['324.2'],
 'yearRate': ['2019-05-04#30']}
2020-05-04 15:34:59,165 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-04 and tpp_id = 248906
2020-05-04 15:34:59,165 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-04 and tpp_id = 248906
2020-05-04 15:34:59,166 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-04 15:34:59,166 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-04 15:34:59,166 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,166 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,167 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,167 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,173 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,173 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,174 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,174 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,175 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,175 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,175 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,175 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,176 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,176 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,177 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,178 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,178 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,179 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,179 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,180 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,180 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,180 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,180 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,181 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,182 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,182 -  log.py[line:110] - INFO: {'name': '布丽·拉尔森 Brie Larson', 'url': '/celebrity/1027194/', 'identity': 'actor'}
2020-05-04 15:34:59,183 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,185 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['布丽·拉尔森 Brie Larson'],
 'url': ['/celebrity/1027194/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '布丽·拉尔森 Brie Larson', 'url': '/celebrity/1027194/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,189 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4 has been crawled, drop it
2020-05-04 15:34:59,189 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4 has been crawled, drop it
2020-05-04 15:34:59,208 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-04 15:34:59,212 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,212 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,213 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,213 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,213 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,213 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,213 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,213 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,213 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,213 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,214 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,214 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,214 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,215 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,215 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,215 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,215 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,215 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,215 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,215 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,216 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,216 -  log.py[line:110] - INFO: {'name': '泰莎·汤普森 Tessa Thompson', 'url': '/celebrity/1027395/', 'identity': 'actor'}
2020-05-04 15:34:59,216 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,217 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['泰莎·汤普森 Tessa Thompson'],
 'url': ['/celebrity/1027395/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '泰莎·汤普森 Tessa Thompson', 'url': '/celebrity/1027395/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,218 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,218 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,219 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,219 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,219 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,219 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,219 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,219 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,219 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,219 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,220 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,220 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,220 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,220 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,220 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,221 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,221 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,221 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,221 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,221 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,221 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,221 -  log.py[line:110] - INFO: {'name': '伊丽莎白·奥尔森 Elizabeth Olsen', 'url': '/celebrity/1129847/', 'identity': 'actor'}
2020-05-04 15:34:59,222 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,222 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['伊丽莎白·奥尔森 Elizabeth Olsen'],
 'url': ['/celebrity/1129847/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '伊丽莎白·奥尔森 Elizabeth Olsen', 'url': '/celebrity/1129847/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,223 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-04 and tpp_id = 1263355
2020-05-04 15:34:59,223 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-04 and tpp_id = 1263355
2020-05-04 15:34:59,223 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-04 15:34:59,223 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-04 15:34:59,223 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,223 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,224 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,224 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,225 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-04 and tpp_id = 1167831
2020-05-04 15:34:59,225 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-04 and tpp_id = 1167831
2020-05-04 15:34:59,225 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-04 15:34:59,225 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-04 15:34:59,225 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,225 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,225 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,225 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,226 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,226 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,227 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,227 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,227 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,227 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,227 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,227 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,227 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,227 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,228 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,228 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,228 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,228 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,228 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,228 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,228 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,229 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,229 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,229 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,229 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,229 -  log.py[line:110] - INFO: {'name': '蒂尔达·斯文顿 Tilda Swinton', 'url': '/celebrity/1025152/', 'identity': 'actor'}
2020-05-04 15:34:59,229 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,230 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['蒂尔达·斯文顿 Tilda Swinton'],
 'url': ['/celebrity/1025152/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '蒂尔达·斯文顿 Tilda Swinton', 'url': '/celebrity/1025152/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,231 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,231 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,231 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,231 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,232 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,232 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,232 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,232 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,232 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,232 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,232 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,233 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,233 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,233 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,233 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,233 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,233 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,233 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,233 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,234 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,234 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,234 -  log.py[line:110] - INFO: {'name': '蕾妮·罗素 Rene Russo', 'url': '/celebrity/1004610/', 'identity': 'actor'}
2020-05-04 15:34:59,235 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:59,353 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,356 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4> (referer: https://movie.douban.com/)
2020-05-04 15:34:59,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,357 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,359 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,359 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,359 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,359 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,360 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,360 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,360 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,361 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,361 -  log.py[line:110] - INFO: {'name': '约翰·斯拉特里 John Slattery', 'url': '/celebrity/1022661/', 'identity': 'actor'}
2020-05-04 15:34:59,363 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,364 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['约翰·斯拉特里 John Slattery'],
 'url': ['/celebrity/1022661/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '约翰·斯拉特里 John Slattery', 'url': '/celebrity/1022661/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,372 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,372 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,373 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,373 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,373 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,373 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,374 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,374 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,374 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,374 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,376 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,377 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,377 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,378 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,378 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,379 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,379 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,379 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,379 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,380 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,381 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,381 -  log.py[line:110] - INFO: {'name': '安东尼·麦凯 Anthony Mackie', 'url': '/celebrity/1027217/', 'identity': 'actor'}
2020-05-04 15:34:59,382 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,384 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['安东尼·麦凯 Anthony Mackie'],
 'url': ['/celebrity/1027217/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '安东尼·麦凯 Anthony Mackie', 'url': '/celebrity/1027217/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,387 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-04 and tpp_id = 1217701
2020-05-04 15:34:59,387 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-04 and tpp_id = 1217701
2020-05-04 15:34:59,388 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-04 15:34:59,388 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-04 15:34:59,388 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,388 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,389 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,389 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,393 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,393 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,395 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,395 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,395 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,395 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,396 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,396 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,396 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,396 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,397 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,398 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,398 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,399 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,399 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,399 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,399 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,399 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,399 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,400 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,400 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,401 -  log.py[line:110] - INFO: {'name': '克里斯·帕拉特 Chris Pratt', 'url': '/celebrity/1017967/', 'identity': 'actor'}
2020-05-04 15:34:59,402 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,403 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['克里斯·帕拉特 Chris Pratt'],
 'url': ['/celebrity/1017967/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '克里斯·帕拉特 Chris Pratt', 'url': '/celebrity/1017967/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,406 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,406 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,407 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,407 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,407 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,407 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,408 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,408 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,408 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,408 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,409 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,410 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,410 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,410 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,411 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,411 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,411 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,411 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,411 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,411 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,412 -  log.py[line:110] - INFO: {'name': '佐伊·索尔达娜 Zoe Saldana', 'url': '/celebrity/1047985/', 'identity': 'actor'}
2020-05-04 15:34:59,412 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,413 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['佐伊·索尔达娜 Zoe Saldana'],
 'url': ['/celebrity/1047985/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '佐伊·索尔达娜 Zoe Saldana', 'url': '/celebrity/1047985/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,414 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,414 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,415 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,415 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,415 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,415 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,415 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,415 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,415 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,415 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,416 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,416 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,416 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,417 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,417 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,417 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,417 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,417 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,417 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,417 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,418 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,418 -  log.py[line:110] - INFO: {'name': '本尼迪克特·王 Benedict Wong', 'url': '/celebrity/1301179/', 'identity': 'actor'}
2020-05-04 15:34:59,419 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,419 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['本尼迪克特·王 Benedict Wong'],
 'url': ['/celebrity/1301179/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '本尼迪克特·王 Benedict Wong', 'url': '/celebrity/1301179/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,421 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,421 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,422 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,422 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,422 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,422 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,423 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,423 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,423 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,423 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,424 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,424 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,424 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,425 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,425 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,425 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,425 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,425 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,425 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,425 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,425 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,426 -  log.py[line:110] - INFO: {'name': '戴夫·巴蒂斯塔 Dave Bautista', 'url': '/celebrity/1014003/', 'identity': 'actor'}
2020-05-04 15:34:59,426 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,426 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['戴夫·巴蒂斯塔 Dave Bautista'],
 'url': ['/celebrity/1014003/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '戴夫·巴蒂斯塔 Dave Bautista', 'url': '/celebrity/1014003/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,428 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,428 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,428 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,428 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,429 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,429 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,429 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,429 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,429 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,429 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,429 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,430 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,430 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,430 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,430 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,430 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,430 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,430 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,430 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,431 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,431 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,431 -  log.py[line:110] - INFO: {'name': '伊万杰琳·莉莉 Evangeline Lilly', 'url': '/celebrity/1021963/', 'identity': 'actor'}
2020-05-04 15:34:59,431 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,432 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['伊万杰琳·莉莉 Evangeline Lilly'],
 'url': ['/celebrity/1021963/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '伊万杰琳·莉莉 Evangeline Lilly', 'url': '/celebrity/1021963/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,433 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,433 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,434 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,434 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,434 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,434 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,434 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,434 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,434 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,434 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,435 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,436 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,436 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,437 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,437 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,437 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,437 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,437 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,437 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,438 -  log.py[line:110] - INFO: {'name': '海莉·阿特维尔 Hayley Atwell', 'url': '/celebrity/1000051/', 'identity': 'actor'}
2020-05-04 15:34:59,438 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,440 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['海莉·阿特维尔 Hayley Atwell'],
 'url': ['/celebrity/1000051/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '海莉·阿特维尔 Hayley Atwell', 'url': '/celebrity/1000051/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,441 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,441 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,441 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,441 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,442 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,442 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,442 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,442 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,442 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,442 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,443 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,443 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,443 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,443 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,443 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,443 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,443 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,444 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,444 -  log.py[line:110] - INFO: {'name': '玛丽莎·托梅 Marisa Tomei', 'url': '/celebrity/1047974/', 'identity': 'actor'}
2020-05-04 15:34:59,444 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,445 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['玛丽莎·托梅 Marisa Tomei'],
 'url': ['/celebrity/1047974/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '玛丽莎·托梅 Marisa Tomei', 'url': '/celebrity/1047974/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,447 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,447 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,447 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,447 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,447 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,447 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,447 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,447 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,448 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,449 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,449 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,449 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,449 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,449 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,449 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,449 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,450 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,450 -  log.py[line:110] - INFO: {'name': '安吉拉·贝塞特 Angela Bassett', 'url': '/celebrity/1025214/', 'identity': 'actor'}
2020-05-04 15:34:59,450 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,450 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['安吉拉·贝塞特 Angela Bassett'],
 'url': ['/celebrity/1025214/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '安吉拉·贝塞特 Angela Bassett', 'url': '/celebrity/1025214/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,452 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,452 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,452 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,452 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,452 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,452 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,452 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,452 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,452 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,453 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,453 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,453 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,453 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,453 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,453 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,453 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,454 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,454 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,454 -  log.py[line:110] - INFO: {'name': '米歇尔·菲佛 Michelle Pfeiffer', 'url': '/celebrity/1035642/', 'identity': 'actor'}
2020-05-04 15:34:59,454 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,455 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['米歇尔·菲佛 Michelle Pfeiffer'],
 'url': ['/celebrity/1035642/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '米歇尔·菲佛 Michelle Pfeiffer', 'url': '/celebrity/1035642/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,456 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,457 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,457 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,457 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,457 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,457 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,457 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,457 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,457 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,458 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,459 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,459 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,459 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,459 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,459 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,459 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,459 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,460 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,460 -  log.py[line:110] - INFO: {'name': '寇碧·史莫德斯 Cobie Smulders', 'url': '/celebrity/1000018/', 'identity': 'actor'}
2020-05-04 15:34:59,460 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,460 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['寇碧·史莫德斯 Cobie Smulders'],
 'url': ['/celebrity/1000018/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '寇碧·史莫德斯 Cobie Smulders', 'url': '/celebrity/1000018/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,461 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,462 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,462 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,462 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,462 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,462 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,462 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,462 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,462 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,463 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,463 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,463 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,464 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,464 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,464 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,464 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,464 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,464 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,465 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,465 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,465 -  log.py[line:110] - INFO: {'name': '温斯顿·杜克 Winston Duke', 'url': '/celebrity/1362864/', 'identity': 'actor'}
2020-05-04 15:34:59,465 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,466 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['温斯顿·杜克 Winston Duke'],
 'url': ['/celebrity/1362864/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '温斯顿·杜克 Winston Duke', 'url': '/celebrity/1362864/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,468 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,468 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,468 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,468 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,468 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,468 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,468 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,468 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,468 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,468 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,469 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,469 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,469 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,470 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,470 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,470 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,470 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,470 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,470 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,471 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,471 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,471 -  log.py[line:110] - INFO: {'name': '马克斯米利亚诺·赫尔南德斯 Maximiliano Hernández', 'url': '/celebrity/1339359/', 'identity': 'actor'}
2020-05-04 15:34:59,472 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,473 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['马克斯米利亚诺·赫尔南德斯 Maximiliano Hernández'],
 'url': ['/celebrity/1339359/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '马克斯米利亚诺·赫尔南德斯 Maximiliano Hernández', 'url': '/celebrity/1339359/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,475 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,475 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,475 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,475 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,475 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,475 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,476 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,476 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,476 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,476 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,476 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,477 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,477 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,477 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,477 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,477 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,477 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,477 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,477 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,478 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,478 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,478 -  log.py[line:110] - INFO: {'name': '真田广之 Hiroyuki Sanada', 'url': '/celebrity/1027879/', 'identity': 'actor'}
2020-05-04 15:34:59,478 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,479 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['真田广之 Hiroyuki Sanada'],
 'url': ['/celebrity/1027879/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '真田广之 Hiroyuki Sanada', 'url': '/celebrity/1027879/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,480 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,480 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,480 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,480 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,480 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,480 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,480 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,480 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,480 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,480 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,481 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,481 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,481 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,481 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,481 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,481 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,481 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,482 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,482 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,482 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,482 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,482 -  log.py[line:110] - INFO: {'name': '詹姆斯·达西 James D&#39;Arcy', 'url': '/celebrity/1049713/', 'identity': 'actor'}
2020-05-04 15:34:59,489 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,490 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['詹姆斯·达西 James D&#39;Arcy'],
 'url': ['/celebrity/1049713/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '詹姆斯·达西 James D&#39;Arcy', 'url': '/celebrity/1049713/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,491 -  movie_spider.py[line:156] - INFO: movie_name = 醒来之爱的呼唤 and movie_year = 2019-05-04 and tpp_id = 1262087
2020-05-04 15:34:59,491 -  movie_spider.py[line:156] - INFO: movie_name = 醒来之爱的呼唤 and movie_year = 2019-05-04 and tpp_id = 1262087
2020-05-04 15:34:59,492 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4
2020-05-04 15:34:59,492 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4
2020-05-04 15:34:59,492 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,492 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 15:34:59,492 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,492 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 15:34:59,493 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,493 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,494 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,494 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,494 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,494 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,494 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,494 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,495 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,495 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,495 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,496 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,496 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,496 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,496 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,496 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,496 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,496 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,496 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,497 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,497 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,497 -  log.py[line:110] - INFO: {'name': '范·迪塞尔 Vin Diesel', 'url': '/celebrity/1041020/', 'identity': 'actor'}
2020-05-04 15:34:59,497 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:59,746 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,746 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,746 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,747 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,747 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,747 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,747 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,747 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,747 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,747 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,748 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,748 -  log.py[line:110] - INFO: {'name': '罗伯特·雷德福 Robert Redford', 'url': '/celebrity/1053617/', 'identity': 'actor'}
2020-05-04 15:34:59,748 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,749 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['罗伯特·雷德福 Robert Redford'],
 'url': ['/celebrity/1053617/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '罗伯特·雷德福 Robert Redford', 'url': '/celebrity/1053617/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,749 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,749 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,750 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,750 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,750 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,750 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,751 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,751 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,751 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,751 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,751 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,752 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,752 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,752 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,752 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,752 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,752 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,753 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,753 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,753 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,753 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,753 -  log.py[line:110] - INFO: {'name': '塞缪尔·杰克逊 Samuel L. Jackson', 'url': '/celebrity/1054408/', 'identity': 'actor'}
2020-05-04 15:34:59,754 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,754 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['塞缪尔·杰克逊 Samuel L. Jackson'],
 'url': ['/celebrity/1054408/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '塞缪尔·杰克逊 Samuel L. Jackson', 'url': '/celebrity/1054408/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,756 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,756 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,756 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,756 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,757 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,757 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,757 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,757 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,757 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,757 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,758 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,758 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,758 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,759 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,759 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,759 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,759 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,759 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,759 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,759 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,759 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,760 -  log.py[line:110] - INFO: {'name': '卡梅伦·布鲁姆布罗 Cameron Brumbelow', 'url': '/celebrity/1392731/', 'identity': 'actor'}
2020-05-04 15:34:59,760 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,761 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['卡梅伦·布鲁姆布罗 Cameron Brumbelow'],
 'url': ['/celebrity/1392731/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '卡梅伦·布鲁姆布罗 Cameron Brumbelow', 'url': '/celebrity/1392731/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,762 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,762 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,763 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,763 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,763 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,763 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,763 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,763 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,763 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,763 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,763 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,764 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,764 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,764 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,764 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,764 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,764 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,764 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,764 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,765 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,765 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,765 -  log.py[line:110] - INFO: {'name': '凯瑞·康顿 Kerry Condon', 'url': '/celebrity/1013874/', 'identity': 'actor'}
2020-05-04 15:34:59,765 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,766 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['凯瑞·康顿 Kerry Condon'],
 'url': ['/celebrity/1013874/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '凯瑞·康顿 Kerry Condon', 'url': '/celebrity/1013874/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,767 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,767 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,767 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,767 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,767 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,767 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,767 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,767 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,768 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,768 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,768 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,768 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,768 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,769 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,769 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,769 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,769 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,769 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,769 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,769 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,769 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,769 -  log.py[line:110] - INFO: {'name': '凯莉·库恩 Carrie Coon', 'url': '/celebrity/1342808/', 'identity': 'actor'}
2020-05-04 15:34:59,770 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,770 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['凯莉·库恩 Carrie Coon'],
 'url': ['/celebrity/1342808/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '凯莉·库恩 Carrie Coon', 'url': '/celebrity/1342808/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,772 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,772 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,772 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,772 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,772 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,772 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,773 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,773 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,773 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,773 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,773 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,773 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,773 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,774 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,774 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,774 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,774 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,774 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,774 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,774 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,775 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,775 -  log.py[line:110] - INFO: {'name': '雷纳·加拉赫 Renah Gallagher', 'url': '/celebrity/1392734/', 'identity': 'actor'}
2020-05-04 15:34:59,775 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,776 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['雷纳·加拉赫 Renah Gallagher'],
 'url': ['/celebrity/1392734/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '雷纳·加拉赫 Renah Gallagher', 'url': '/celebrity/1392734/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,777 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,777 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,778 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,778 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,778 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,778 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,778 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,778 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,778 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,778 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,779 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,779 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,779 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,779 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,779 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,779 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,779 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,780 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,780 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,780 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,780 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,780 -  log.py[line:110] - INFO: {'name': '郑肯 Ken Jeong', 'url': '/celebrity/1275017/', 'identity': 'actor'}
2020-05-04 15:34:59,781 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:34:59,894 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,894 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,894 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,895 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,895 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,895 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,895 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,895 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,895 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,895 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,896 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,896 -  log.py[line:110] - INFO: {'name': '小弗洛伊德·安东尼·约翰 Floyd Anthony Johns Jr.', 'url': '/celebrity/1392722/', 'identity': 'actor'}
2020-05-04 15:34:59,896 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,897 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['小弗洛伊德·安东尼·约翰 Floyd Anthony Johns Jr.'],
 'url': ['/celebrity/1392722/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '小弗洛伊德·安东尼·约翰 Floyd Anthony Johns Jr.', 'url': '/celebrity/1392722/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,898 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,898 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,898 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯坦·李 Stan Lee
{'identity': ['actor'],
 'name': ['斯坦·李 Stan Lee'],
 'url': ['/celebrity/1013888/']}
2020-05-04 15:34:59,899 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,899 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,900 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,900 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,900 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,900 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,900 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,900 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,900 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,900 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,901 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,901 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,901 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,902 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,902 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,902 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,902 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,902 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,902 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,902 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,902 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,902 -  log.py[line:110] - INFO: {'name': '布伦特·麦吉 Brent McGee', 'url': '/celebrity/1392739/', 'identity': 'actor'}
2020-05-04 15:34:59,903 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,903 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['布伦特·麦吉 Brent McGee'],
 'url': ['/celebrity/1392739/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '布伦特·麦吉 Brent McGee', 'url': '/celebrity/1392739/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,904 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,904 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,905 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,905 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,905 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,905 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,905 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,905 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,905 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,905 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,906 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,906 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,906 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,907 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,907 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,907 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,907 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,907 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,907 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,907 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,908 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,908 -  log.py[line:110] - INFO: {'name': '卡兰·马尔韦 Callan Mulvey', 'url': '/celebrity/1126747/', 'identity': 'actor'}
2020-05-04 15:34:59,908 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,909 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['卡兰·马尔韦 Callan Mulvey'],
 'url': ['/celebrity/1126747/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '卡兰·马尔韦 Callan Mulvey', 'url': '/celebrity/1126747/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,910 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,910 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,910 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,910 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,910 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,910 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,910 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,910 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,911 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,911 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,911 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,911 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,911 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,912 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,912 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,912 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,912 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,912 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,912 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,912 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,912 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,913 -  log.py[line:110] - INFO: {'name': '吉米·雷·皮肯斯 Jimmy Ray Pickens', 'url': '/celebrity/1133195/', 'identity': 'actor'}
2020-05-04 15:34:59,913 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,913 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['吉米·雷·皮肯斯 Jimmy Ray Pickens'],
 'url': ['/celebrity/1133195/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '吉米·雷·皮肯斯 Jimmy Ray Pickens', 'url': '/celebrity/1133195/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,915 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,915 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,915 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,915 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,915 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,915 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,916 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,916 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,916 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,916 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,916 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,916 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,916 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,917 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,917 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,917 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,917 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,917 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,917 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,918 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,918 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,918 -  log.py[line:110] - INFO: {'name': '泰·辛普金斯 Ty Simpkins', 'url': '/celebrity/1322702/', 'identity': 'actor'}
2020-05-04 15:34:59,918 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:34:59,919 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['泰·辛普金斯 Ty Simpkins'],
 'url': ['/celebrity/1322702/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '泰·辛普金斯 Ty Simpkins', 'url': '/celebrity/1322702/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:34:59,920 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,920 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,920 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,920 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,920 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,920 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,921 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,921 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,921 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,921 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:34:59,921 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:34:59,922 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,922 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:34:59,922 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,922 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:34:59,922 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,922 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:34:59,922 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,922 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:34:59,922 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:34:59,923 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:34:59,923 -  log.py[line:110] - INFO: {'name': '艾娃·罗素 Ava Russo', 'url': '/celebrity/1415181/', 'identity': 'actor'}
2020-05-04 15:34:59,923 -  log.py[line:110] - INFO: COMMIT
2020-05-04 15:35:00,042 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,042 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,042 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,043 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :乔·罗素 Joe Russo
{'identity': ['actor'],
 'name': ['乔·罗素 Joe Russo'],
 'url': ['/celebrity/1320870/']}
2020-05-04 15:35:00,043 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,043 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,044 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,044 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,044 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,044 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,044 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,044 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,044 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,045 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,045 -  log.py[line:110] - INFO: {'name': '玛丽亚·Z·威尔逊 Maria Z. Wilson', 'url': '/celebrity/1392738/', 'identity': 'actor'}
2020-05-04 15:35:00,045 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,046 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['玛丽亚·Z·威尔逊 Maria Z. Wilson'],
 'url': ['/celebrity/1392738/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '玛丽亚·Z·威尔逊 Maria Z. Wilson', 'url': '/celebrity/1392738/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,047 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,047 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,047 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,047 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,047 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,047 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,048 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,048 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,048 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,048 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,048 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,049 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,049 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,049 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,049 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,050 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,050 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,050 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,050 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,050 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,050 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,050 -  log.py[line:110] - INFO: {'name': '劳尔·阿尔坎塔 Raul Alcantar', 'url': '/celebrity/1392728/', 'identity': 'actor'}
2020-05-04 15:35:00,051 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,051 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['劳尔·阿尔坎塔 Raul Alcantar'],
 'url': ['/celebrity/1392728/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '劳尔·阿尔坎塔 Raul Alcantar', 'url': '/celebrity/1392728/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,052 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,052 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,052 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,052 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,053 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,053 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,053 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,053 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,053 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,053 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,053 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,054 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,054 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,054 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,054 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,054 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,054 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,054 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,054 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,055 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,055 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,055 -  log.py[line:110] - INFO: {'name': '何塞·阿尔弗雷多·费尔南德斯 José Alfredo Fernandez', 'url': '/celebrity/1411163/', 'identity': 'actor'}
2020-05-04 15:35:00,055 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,056 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['何塞·阿尔弗雷多·费尔南德斯 José Alfredo Fernandez'],
 'url': ['/celebrity/1411163/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '何塞·阿尔弗雷多·费尔南德斯 José Alfredo Fernandez', 'url': '/celebrity/1411163/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,056 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,056 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,057 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,057 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,057 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,057 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,057 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,057 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,057 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,057 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,058 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,058 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,058 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,058 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,058 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,058 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,058 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,058 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,058 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,059 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,059 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,059 -  log.py[line:110] - INFO: {'name': '安东尼·B·哈里斯 Anthony B. Harris', 'url': '/celebrity/1266890/', 'identity': 'actor'}
2020-05-04 15:35:00,059 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,060 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['安东尼·B·哈里斯 Anthony B. Harris'],
 'url': ['/celebrity/1266890/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '安东尼·B·哈里斯 Anthony B. Harris', 'url': '/celebrity/1266890/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,061 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,061 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,062 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,062 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,062 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,062 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,062 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,062 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,062 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,062 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,063 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,063 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,063 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,064 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,064 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,064 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,064 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,064 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,064 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,064 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,065 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,065 -  log.py[line:110] - INFO: {'name': '罗伯特·佩恩 Robert Payen', 'url': '/celebrity/1392724/', 'identity': 'actor'}
2020-05-04 15:35:00,065 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,066 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['罗伯特·佩恩 Robert Payen'],
 'url': ['/celebrity/1392724/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '罗伯特·佩恩 Robert Payen', 'url': '/celebrity/1392724/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,067 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,067 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,067 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,067 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,067 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,067 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,067 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,067 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,068 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,068 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,068 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,068 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,068 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,069 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,069 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,069 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,069 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,069 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,069 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,069 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,070 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,070 -  log.py[line:110] - INFO: {'name': '罗伯特·廷斯利 Robert Tinsley', 'url': '/celebrity/1402482/', 'identity': 'actor'}
2020-05-04 15:35:00,070 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,070 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['罗伯特·廷斯利 Robert Tinsley'],
 'url': ['/celebrity/1402482/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '罗伯特·廷斯利 Robert Tinsley', 'url': '/celebrity/1402482/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,071 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,071 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,072 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,072 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,072 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,072 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,072 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,072 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,072 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,072 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,073 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,073 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,073 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,074 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,074 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,074 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,074 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,074 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,074 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,074 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,074 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,074 -  log.py[line:110] - INFO: {'name': '保罗·皮尔斯伯里 Paul Pillsbury', 'url': '/celebrity/1392723/', 'identity': 'actor'}
2020-05-04 15:35:00,075 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,075 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['保罗·皮尔斯伯里 Paul Pillsbury'],
 'url': ['/celebrity/1392723/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '保罗·皮尔斯伯里 Paul Pillsbury', 'url': '/celebrity/1392723/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,076 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,076 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,077 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,077 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,077 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,077 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,077 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,077 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,077 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,077 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,078 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,079 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,079 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,079 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,079 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,079 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,079 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,079 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,079 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,080 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,080 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,080 -  log.py[line:110] - INFO: {'name': '亚历珊德拉‧瑞秋·拉贝 Alexandra Rachael Rabe', 'url': '/celebrity/1415276/', 'identity': 'actor'}
2020-05-04 15:35:00,081 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,082 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['亚历珊德拉‧瑞秋·拉贝 Alexandra Rachael Rabe'],
 'url': ['/celebrity/1415276/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '亚历珊德拉‧瑞秋·拉贝 Alexandra Rachael Rabe', 'url': '/celebrity/1415276/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,083 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,083 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,084 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,084 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,084 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,084 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,084 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,084 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,084 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,084 -  pipelines.py[line:87] - ERROR: something wrong occur, session rollback
2020-05-04 15:35:00,085 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98>
None
2020-05-04 15:35:00,085 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,085 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 15:35:00,086 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,086 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 15:35:00,086 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,086 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 15:35:00,086 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,086 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 15:35:00,086 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 15:35:00,087 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 15:35:00,087 -  log.py[line:110] - INFO: {'name': '杰克逊·艾顿 Jackson A. Dunn', 'url': '/celebrity/1412334/', 'identity': 'actor'}
2020-05-04 15:35:00,087 -  log.py[line:110] - INFO: ROLLBACK
2020-05-04 15:35:00,088 -  scraper.py[line:236] - ERROR: Error processing {'identity': ['actor'],
 'name': ['杰克逊·艾顿 Jackson A. Dunn'],
 'url': ['/celebrity/1412334/']}
Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/dawinia/CodeBook/ScrapyProject/movie/movie/pipelines.py", line 85, in process_item
    self.session.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1036, in commit
    self.transaction.commit()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 503, in commit
    self._prepare_impl()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 482, in _prepare_impl
    self.session.flush()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2479, in flush
    self._flush(objects)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2617, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2577, in _flush
    flush_context.execute()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1137, in _emit_insert_statements
    statement, params
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 293, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1101, in _execute_clauseelement
    distilled_params,
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1250, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1246, in _execute_context
    cursor, statement, parameters, context
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 588, in do_execute
    cursor.execute(statement, parameters)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/dawinia/anaconda3/envs/Scrapy/lib/python3.7/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
sqlalchemy.exc.DataError: (pymysql.err.DataError) (1406, "Data too long for column 'name' at row 1")
[SQL: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)]
[parameters: {'name': '杰克逊·艾顿 Jackson A. Dunn', 'url': '/celebrity/1412334/', 'identity': 'actor'}]
(Background on this error at: http://sqlalche.me/e/9h9h)
2020-05-04 15:35:00,090 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['833482'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-05-04 15:35:01,207 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-05-04 15:35:01,209 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 43513,
 'downloader/request_count': 36,
 'downloader/request_method_count/GET': 36,
 'downloader/response_bytes': 140043,
 'downloader/response_count': 36,
 'downloader/response_status_count/200': 36,
 'elapsed_time_seconds': 33.205934,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 4, 7, 35, 1, 208983),
 'item_dropped_count': 42,
 'item_dropped_reasons_count/DropItem': 42,
 'item_scraped_count': 78,
 'log_count/ERROR': 180,
 'log_count/WARNING': 43,
 'memusage/max': 73895936,
 'memusage/startup': 73895936,
 'request_depth_max': 2,
 'response_received_count': 36,
 'scheduler/dequeued': 36,
 'scheduler/dequeued/memory': 36,
 'scheduler/enqueued': 36,
 'scheduler/enqueued/memory': 36,
 'start_time': datetime.datetime(2020, 5, 4, 7, 34, 28, 3049)}
2020-05-04 15:35:01,209 -  engine.py[line:327] - INFO: Spider closed (finished)
2020-05-04 15:59:51,802 -  log.py[line:146] - INFO: Scrapy 1.8.0 started (bot: movie)
2020-05-04 15:59:51,819 -  log.py[line:149] - INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
2020-05-04 15:59:51,822 -  crawler.py[line:49] - INFO: Overridden settings: {'BOT_NAME': 'movie', 'COMMANDS_MODULE': 'movie.commands', 'LOG_LEVEL': 'WARNING', 'NEWSPIDER_MODULE': 'movie.spiders', 'SPIDER_MODULES': ['movie.spiders']}
2020-05-04 15:59:51,830 -  telnet.py[line:60] - INFO: Telnet Password: 92185458acc2ac98
2020-05-04 15:59:51,840 -  middleware.py[line:48] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-05-04 15:59:52,181 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-04 15:59:52,181 -  middlewares.py[line:134] - INFO: start to use judge duplicate url
2020-05-04 15:59:52,184 -  middleware.py[line:48] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'movie.middlewares.DuplicateMiddleware',
 'movie.middlewares.UserAgentMiddleware',
 'movie.middlewares.RefererMiddleware',
 'movie.middlewares.MovieDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-05-04 15:59:52,185 -  middleware.py[line:48] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'movie.middlewares.MovieSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-05-04 15:59:52,193 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-04 15:59:52,193 -  pipelines.py[line:18] - INFO: start to use judge duplicate item
2020-05-04 15:59:52,283 -  middleware.py[line:48] - INFO: Enabled item pipelines:
['movie.pipelines.ItemPipeline', 'movie.pipelines.MySQLPipeline']
2020-05-04 15:59:52,284 -  engine.py[line:257] - INFO: Spider opened
2020-05-04 15:59:52,285 -  logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-05-04 15:59:52,286 -  telnet.py[line:74] - INFO: Telnet console listening on 127.0.0.1:6023
2020-05-04 15:59:52,290 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-04 15:59:52,290 -  movie_spider.py[line:87] - INFO: boxOffice start request for url = http://piaofang.maoyan.com/dashboard-ajax/movie?
2020-05-04 15:59:52,293 -  middlewares.py[line:144] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504 has been crawled, drop it
2020-05-04 15:59:52,293 -  middlewares.py[line:144] - ERROR: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504 has been crawled, drop it
2020-05-04 15:59:52,478 -  engine.py[line:239] - DEBUG: Crawled (200) <GET http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504> (referer: https://movie.douban.com/)
2020-05-04 15:59:53,493 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504
2020-05-04 15:59:53,493 -  movie_spider.py[line:106] - INFO: now crawl url for boxOffice: http://piaofang.maoyan.com/dashboard-ajax/movie?showDate=20190504
2020-05-04 15:59:53,498 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-04 15:59:53,498 -  movie_spider.py[line:134] - INFO: get 1 boxOffice, named .
2020-05-04 15:59:53,502 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#1
{'boxInfo': ['13697.73'],
 'boxRate': ['70.5%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [248172],
 'movieName': ['复仇者联盟4：终局之战'],
 'releaseInfo': ['上映11天'],
 'seatRate': ['11.9%'],
 'showInfo': [180618],
 'showRate': ['58.2%'],
 'showView': ['16'],
 'splitBoxInfo': ['12953.76'],
 'splitSumBoxInfo': ['364100.0'],
 'sumBoxInfo': ['383600.0'],
 'yearRate': ['2019-05-04#1']}
2020-05-04 15:59:54,220 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:59:54,220 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 15:59:54,251 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-04 15:59:54,251 -  movie_spider.py[line:134] - INFO: get 2 boxOffice, named .
2020-05-04 15:59:54,253 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#2
{'boxInfo': ['3000.61'],
 'boxRate': ['15.4%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1218727],
 'movieName': ['何以为家'],
 'releaseInfo': ['重映6天'],
 'seatRate': ['20.3%'],
 'showInfo': [47919],
 'showRate': ['15.4%'],
 'showView': ['20'],
 'splitBoxInfo': ['2736.98'],
 'splitSumBoxInfo': ['13900.0'],
 'sumBoxInfo': ['15200.0'],
 'yearRate': ['2019-05-04#2']}
2020-05-04 15:59:54,268 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-04 15:59:54,268 -  movie_spider.py[line:134] - INFO: get 3 boxOffice, named .
2020-05-04 15:59:54,270 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#3
{'boxInfo': ['1003.62'],
 'boxRate': ['5.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1228776],
 'movieName': ['下一任：前任'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['10.5%'],
 'showInfo': [32754],
 'showRate': ['10.5%'],
 'showView': ['10'],
 'splitBoxInfo': ['928.20'],
 'splitSumBoxInfo': ['9386.4'],
 'sumBoxInfo': ['10200.0'],
 'yearRate': ['2019-05-04#3']}
2020-05-04 15:59:55,026 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:59:55,026 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 15:59:55,055 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:59:55,055 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 15:59:55,068 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-04 15:59:55,068 -  movie_spider.py[line:134] - INFO: get 4 boxOffice, named .
2020-05-04 15:59:55,069 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#4
{'boxInfo': ['430.85'],
 'boxRate': ['2.2%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1211412],
 'movieName': ['神奇乐园历险记'],
 'releaseInfo': ['上映16天'],
 'seatRate': ['15.1%'],
 'showInfo': [9048],
 'showRate': ['2.9%'],
 'showView': ['15'],
 'splitBoxInfo': ['398.55'],
 'splitSumBoxInfo': ['4248.8'],
 'sumBoxInfo': ['4577.1'],
 'yearRate': ['2019-05-04#4']}
2020-05-04 15:59:55,867 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-04 15:59:55,867 -  movie_spider.py[line:134] - INFO: get 5 boxOffice, named .
2020-05-04 15:59:55,870 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#5
{'boxInfo': ['270.71'],
 'boxRate': ['1.3%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [672379],
 'movieName': ['悟空奇遇记'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['8.5%'],
 'showInfo': [12565],
 'showRate': ['4.0%'],
 'showView': ['8'],
 'splitBoxInfo': ['253.06'],
 'splitSumBoxInfo': ['1649.9'],
 'sumBoxInfo': ['1773.3'],
 'yearRate': ['2019-05-04#5']}
2020-05-04 15:59:56,489 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:59:56,489 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 15:59:56,515 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:59:56,515 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 15:59:56,531 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-04 15:59:56,531 -  movie_spider.py[line:134] - INFO: get 6 boxOffice, named .
2020-05-04 15:59:56,532 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#6
{'boxInfo': ['244.19'],
 'boxRate': ['1.2%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [672279],
 'movieName': ['雪暴'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['9.5%'],
 'showInfo': [8725],
 'showRate': ['2.8%'],
 'showView': ['8'],
 'splitBoxInfo': ['225.80'],
 'splitSumBoxInfo': ['1681.3'],
 'sumBoxInfo': ['1798.3'],
 'yearRate': ['2019-05-04#6']}
2020-05-04 15:59:56,625 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-04 15:59:56,625 -  movie_spider.py[line:134] - INFO: get 7 boxOffice, named .
2020-05-04 15:59:56,628 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#7
{'boxInfo': ['147.18'],
 'boxRate': ['0.7%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [883196],
 'movieName': ['一个母亲的复仇'],
 'releaseInfo': ['点映'],
 'seatRate': ['51.5%'],
 'showInfo': [772],
 'showRate': ['0.2%'],
 'showView': ['50'],
 'splitBoxInfo': ['139.21'],
 'splitSumBoxInfo': ['145.7'],
 'sumBoxInfo': ['154.1'],
 'yearRate': ['2019-05-04#7']}
2020-05-04 15:59:57,498 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:59:57,498 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87 has been crawled, drop it
2020-05-04 15:59:57,507 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:59:57,507 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4 has been crawled, drop it
2020-05-04 15:59:57,516 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-04 15:59:57,516 -  movie_spider.py[line:134] - INFO: get 8 boxOffice, named .
2020-05-04 15:59:57,518 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#8
{'boxInfo': ['127.02'],
 'boxRate': ['0.6%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1239544],
 'movieName': ['调音师'],
 'releaseInfo': ['上映32天'],
 'seatRate': ['14.7%'],
 'showInfo': [2715],
 'showRate': ['0.8%'],
 'showView': ['14'],
 'splitBoxInfo': ['116.00'],
 'splitSumBoxInfo': ['29000.0'],
 'sumBoxInfo': ['32100.0'],
 'yearRate': ['2019-05-04#8']}
2020-05-04 15:59:58,402 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-04 15:59:58,402 -  movie_spider.py[line:134] - INFO: get 9 boxOffice, named .
2020-05-04 15:59:58,402 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#9
{'boxInfo': ['100.59'],
 'boxRate': ['0.5%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1211727],
 'movieName': ['反贪风暴4'],
 'releaseInfo': ['上映31天'],
 'seatRate': ['11.6%'],
 'showInfo': [2842],
 'showRate': ['0.9%'],
 'showView': ['10'],
 'splitBoxInfo': ['93.20'],
 'splitSumBoxInfo': ['72800.0'],
 'sumBoxInfo': ['78900.0'],
 'yearRate': ['2019-05-04#9']}
2020-05-04 15:59:58,990 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-04 15:59:58,990 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44 has been crawled, drop it
2020-05-04 15:59:59,017 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 15:59:59,017 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 15:59:59,030 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-04 15:59:59,030 -  movie_spider.py[line:134] - INFO: get 10 boxOffice, named .
2020-05-04 15:59:59,031 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#10
{'boxInfo': ['59.02'],
 'boxRate': ['0.3%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1230152],
 'movieName': ['撞死了一只羊'],
 'releaseInfo': ['上映9天'],
 'seatRate': ['8.2%'],
 'showInfo': [1562],
 'showRate': ['0.5%'],
 'showView': ['10'],
 'splitBoxInfo': ['57.28'],
 'splitSumBoxInfo': ['944.7'],
 'sumBoxInfo': ['980.7'],
 'yearRate': ['2019-05-04#10']}
2020-05-04 15:59:59,566 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-04 15:59:59,567 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-04 15:59:59,567 -  movie_spider.py[line:134] - INFO: get 11 boxOffice, named .
2020-05-04 15:59:59,568 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#11
{'boxInfo': ['50.23'],
 'boxRate': ['0.2%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1189325],
 'movieName': ['捉妖学院'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['2.7%'],
 'showInfo': [126],
 'showRate': ['<0.1%'],
 'showView': ['12'],
 'splitBoxInfo': ['50.20'],
 'splitSumBoxInfo': ['362.4'],
 'sumBoxInfo': ['362.6'],
 'yearRate': ['2019-05-04#11']}
2020-05-04 16:00:00,372 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 16:00:00,372 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 16:00:00,377 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 16:00:00,377 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 16:00:00,384 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-04 16:00:00,390 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-04 16:00:00,393 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-04 16:00:00,393 -  movie_spider.py[line:134] - INFO: get 12 boxOffice, named .
2020-05-04 16:00:00,393 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#12
{'boxInfo': ['31.47'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [330115],
 'movieName': ['我和神马查干'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [212],
 'showRate': ['<0.1%'],
 'showView': ['49'],
 'splitBoxInfo': ['31.42'],
 'splitSumBoxInfo': ['2253.1'],
 'sumBoxInfo': ['2261.0'],
 'yearRate': ['2019-05-04#12']}
2020-05-04 16:00:00,832 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 16:00:00,832 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2 has been crawled, drop it
2020-05-04 16:00:00,861 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:00,862 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-04 16:00:00,862 -  movie_spider.py[line:134] - INFO: get 13 boxOffice, named .
2020-05-04 16:00:00,864 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#13
{'boxInfo': ['30.61'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1228750],
 'movieName': ['照相师'],
 'releaseInfo': [''],
 'seatRate': ['85.8%'],
 'showInfo': [57],
 'showRate': ['<0.1%'],
 'showView': ['125'],
 'splitBoxInfo': ['30.37'],
 'splitSumBoxInfo': ['2152.1'],
 'sumBoxInfo': ['2165.0'],
 'yearRate': ['2019-05-04#13']}
2020-05-04 16:00:01,307 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-04 and tpp_id = 248172
2020-05-04 16:00:01,307 -  movie_spider.py[line:156] - INFO: movie_name = 复仇者联盟4：终局之战 and movie_year = 2019-05-04 and tpp_id = 248172
2020-05-04 16:00:01,308 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 16:00:01,308 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 16:00:01,308 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:01,308 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:01,309 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 16:00:01,309 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 16:00:02,921 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 16:00:02,921 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98 has been crawled, drop it
2020-05-04 16:00:02,926 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:02,926 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:02,942 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 16:00:02,948 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 16:00:02,949 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-04 16:00:02,950 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-04 16:00:02,951 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-04 16:00:02,951 -  movie_spider.py[line:134] - INFO: get 14 boxOffice, named .
2020-05-04 16:00:02,952 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#14
{'boxInfo': ['26.03'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1243904],
 'movieName': ['动物出击'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['7.2%'],
 'showInfo': [1638],
 'showRate': ['0.5%'],
 'showView': ['6'],
 'splitBoxInfo': ['24.67'],
 'splitSumBoxInfo': ['319.8'],
 'sumBoxInfo': ['330.7'],
 'yearRate': ['2019-05-04#14']}
2020-05-04 16:00:03,664 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-04 and tpp_id = 1218727
2020-05-04 16:00:03,664 -  movie_spider.py[line:156] - INFO: movie_name = 何以为家 and movie_year = 2019-05-04 and tpp_id = 1218727
2020-05-04 16:00:03,665 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 16:00:03,665 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 16:00:03,665 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:03,665 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:03,665 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 16:00:03,665 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 16:00:05,245 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-04 and tpp_id = 1228776
2020-05-04 16:00:05,245 -  movie_spider.py[line:156] - INFO: movie_name = 下一任：前任 and movie_year = 2019-05-04 and tpp_id = 1228776
2020-05-04 16:00:05,246 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 16:00:05,246 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 16:00:05,246 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:05,246 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:05,246 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 16:00:05,246 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 16:00:06,924 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 16:00:06,924 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB has been crawled, drop it
2020-05-04 16:00:06,930 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 16:00:06,930 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6 has been crawled, drop it
2020-05-04 16:00:06,936 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 16:00:06,936 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB has been crawled, drop it
2020-05-04 16:00:06,943 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2> (referer: https://movie.douban.com/)
2020-05-04 16:00:06,944 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-04 16:00:06,944 -  movie_spider.py[line:134] - INFO: get 15 boxOffice, named .
2020-05-04 16:00:06,944 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#15
{'boxInfo': ['24.19'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [476263],
 'movieName': ['天上再见'],
 'releaseInfo': ['上映5天'],
 'seatRate': ['11.6%'],
 'showInfo': [725],
 'showRate': ['0.2%'],
 'showView': ['9'],
 'splitBoxInfo': ['22.24'],
 'splitSumBoxInfo': ['103.0'],
 'sumBoxInfo': ['110.7'],
 'yearRate': ['2019-05-04#15']}
2020-05-04 16:00:07,355 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-04 and tpp_id = 1239544
2020-05-04 16:00:07,355 -  movie_spider.py[line:156] - INFO: movie_name = 调音师 and movie_year = 2019-05-04 and tpp_id = 1239544
2020-05-04 16:00:07,356 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:07,356 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:07,356 -  movie_spider.py[line:162] - INFO: len of text is 6
2020-05-04 16:00:07,356 -  movie_spider.py[line:162] - INFO: len of text is 6
2020-05-04 16:00:07,356 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:07,356 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:09,049 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:09,049 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:09,054 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:09,054 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:09,056 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:09,056 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:09,057 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-04 16:00:09,057 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81 has been crawled, drop it
2020-05-04 16:00:09,063 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4> (referer: https://movie.douban.com/)
2020-05-04 16:00:09,069 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87> (referer: https://movie.douban.com/)
2020-05-04 16:00:09,076 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98> (referer: https://movie.douban.com/)
2020-05-04 16:00:09,077 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:09,079 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB> (referer: https://movie.douban.com/)
2020-05-04 16:00:09,080 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6> (referer: https://movie.douban.com/)
2020-05-04 16:00:09,081 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-04 16:00:09,081 -  movie_spider.py[line:134] - INFO: get 16 boxOffice, named .
2020-05-04 16:00:09,082 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#16
{'boxInfo': ['21.52'],
 'boxRate': ['0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1212492],
 'movieName': ['老师·好'],
 'releaseInfo': ['重映44天'],
 'seatRate': ['13.6%'],
 'showInfo': [562],
 'showRate': ['0.1%'],
 'showView': ['12'],
 'splitBoxInfo': ['20.19'],
 'splitSumBoxInfo': ['32700.0'],
 'sumBoxInfo': ['35300.0'],
 'yearRate': ['2019-05-04#16']}
2020-05-04 16:00:09,548 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-04 and tpp_id = 1211412
2020-05-04 16:00:09,548 -  movie_spider.py[line:156] - INFO: movie_name = 神奇乐园历险记 and movie_year = 2019-05-04 and tpp_id = 1211412
2020-05-04 16:00:09,549 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:09,549 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:09,549 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:09,549 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:09,549 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:09,549 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:11,263 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-04 and tpp_id = 672379
2020-05-04 16:00:11,263 -  movie_spider.py[line:156] - INFO: movie_name = 悟空奇遇记 and movie_year = 2019-05-04 and tpp_id = 672379
2020-05-04 16:00:11,264 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 16:00:11,264 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 16:00:11,264 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:11,264 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:11,265 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 16:00:11,265 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 16:00:12,600 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-04 and tpp_id = 1189325
2020-05-04 16:00:12,600 -  movie_spider.py[line:156] - INFO: movie_name = 捉妖学院 and movie_year = 2019-05-04 and tpp_id = 1189325
2020-05-04 16:00:12,601 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 16:00:12,601 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 16:00:12,601 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:12,601 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:12,602 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 16:00:12,602 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 16:00:14,131 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-04 and tpp_id = 1230152
2020-05-04 16:00:14,131 -  movie_spider.py[line:156] - INFO: movie_name = 撞死了一只羊 and movie_year = 2019-05-04 and tpp_id = 1230152
2020-05-04 16:00:14,132 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 16:00:14,132 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 16:00:14,132 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:14,132 -  movie_spider.py[line:162] - INFO: len of text is 1
2020-05-04 16:00:14,132 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 16:00:14,132 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 16:00:17,580 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:17,580 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:17,582 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:17,582 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:17,609 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 16:00:17,609 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A has been crawled, drop it
2020-05-04 16:00:17,626 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 16:00:17,626 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2 has been crawled, drop it
2020-05-04 16:00:17,635 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 16:00:17,635 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0 has been crawled, drop it
2020-05-04 16:00:17,636 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 16:00:17,636 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 16:00:17,638 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-04 16:00:17,638 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD has been crawled, drop it
2020-05-04 16:00:17,645 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB> (referer: https://movie.douban.com/)
2020-05-04 16:00:17,646 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-04 16:00:17,646 -  movie_spider.py[line:134] - INFO: get 17 boxOffice, named .
2020-05-04 16:00:17,647 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#17
{'boxInfo': ['18.26'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1205909],
 'movieName': ['祈祷落幕时'],
 'releaseInfo': ['上映23天'],
 'seatRate': ['14.5%'],
 'showInfo': [455],
 'showRate': ['0.1%'],
 'showView': ['11'],
 'splitBoxInfo': ['16.73'],
 'splitSumBoxInfo': ['6070.2'],
 'sumBoxInfo': ['6712.7'],
 'yearRate': ['2019-05-04#17']}
2020-05-04 16:00:18,498 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-04 and tpp_id = 330115
2020-05-04 16:00:18,498 -  movie_spider.py[line:156] - INFO: movie_name = 我和神马查干 and movie_year = 2019-05-04 and tpp_id = 330115
2020-05-04 16:00:18,498 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 16:00:18,498 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%88%91%E5%92%8C%E7%A5%9E%E9%A9%AC%E6%9F%A5%E5%B9%B2
2020-05-04 16:00:18,498 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:18,498 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:18,499 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:18,499 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:19,708 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:19,708 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:19,711 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:19,711 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:19,716 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-04 16:00:19,716 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6 has been crawled, drop it
2020-05-04 16:00:19,740 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44> (referer: https://movie.douban.com/)
2020-05-04 16:00:19,751 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:19,760 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:19,765 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81> (referer: https://movie.douban.com/)
2020-05-04 16:00:19,767 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:19,769 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A> (referer: https://movie.douban.com/)
2020-05-04 16:00:19,770 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2> (referer: https://movie.douban.com/)
2020-05-04 16:00:19,771 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-04 16:00:19,771 -  movie_spider.py[line:134] - INFO: get 18 boxOffice, named .
2020-05-04 16:00:19,772 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#18
{'boxInfo': ['15.79'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1239281],
 'movieName': ['港珠澳大桥'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['5.8%'],
 'showInfo': [1613],
 'showRate': ['0.5%'],
 'showView': ['4'],
 'splitBoxInfo': ['15.05'],
 'splitSumBoxInfo': ['92.5'],
 'sumBoxInfo': ['97.1'],
 'yearRate': ['2019-05-04#18']}
2020-05-04 16:00:20,200 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-04 and tpp_id = 672279
2020-05-04 16:00:20,200 -  movie_spider.py[line:156] - INFO: movie_name = 雪暴 and movie_year = 2019-05-04 and tpp_id = 672279
2020-05-04 16:00:20,201 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-04 16:00:20,201 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9B%AA%E6%9A%B4
2020-05-04 16:00:20,201 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:20,201 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:20,202 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:20,202 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:20,205 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-04 and tpp_id = 883196
2020-05-04 16:00:20,205 -  movie_spider.py[line:156] - INFO: movie_name = 一个母亲的复仇 and movie_year = 2019-05-04 and tpp_id = 883196
2020-05-04 16:00:20,206 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 16:00:20,206 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B8%80%E4%B8%AA%E6%AF%8D%E4%BA%B2%E7%9A%84%E5%A4%8D%E4%BB%87
2020-05-04 16:00:20,206 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:20,206 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:20,206 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:20,206 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:20,210 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 16:00:20,210 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26100958/?suggest=%E5%A4%8D%E4%BB%87%E8%80%85%E8%81%94%E7%9B%9F4%EF%BC%9A%E7%BB%88%E5%B1%80%E4%B9%8B%E6%88%98
2020-05-04 16:00:20,246 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:20,246 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:20,248 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:20,248 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:20,248 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:20,248 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:20,248 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:20,248 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:20,249 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :安东尼·罗素 Anthony Russo
{'identity': ['director'],
 'name': ['安东尼·罗素 Anthony Russo'],
 'url': ['/celebrity/1321812/']}
2020-05-04 16:00:20,249 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-04 and tpp_id = 1228750
2020-05-04 16:00:20,249 -  movie_spider.py[line:156] - INFO: movie_name = 照相师 and movie_year = 2019-05-04 and tpp_id = 1228750
2020-05-04 16:00:20,249 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 16:00:20,249 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%85%A7%E7%9B%B8%E5%B8%88
2020-05-04 16:00:20,250 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:20,250 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:20,250 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:20,250 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:20,251 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 16:00:20,251 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26311974/?suggest=%E4%B8%8B%E4%B8%80%E4%BB%BB%EF%BC%9A%E5%89%8D%E4%BB%BB
2020-05-04 16:00:20,263 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:20,263 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:20,264 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:20,264 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:20,264 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:20,264 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:20,265 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:20,265 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:20,265 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :陈鸿仪 Hung-I Chen
{'identity': ['director'],
 'name': ['陈鸿仪 Hung-I Chen'],
 'url': ['/celebrity/1348355/']}
2020-05-04 16:00:20,265 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 16:00:20,265 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30170448/?suggest=%E4%BD%95%E4%BB%A5%E4%B8%BA%E5%AE%B6
2020-05-04 16:00:20,278 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:20,278 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:20,279 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:20,279 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:20,279 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:20,279 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:20,279 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:20,279 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:20,280 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :娜丁·拉巴基 Nadine Labaki
{'identity': ['director'],
 'name': ['娜丁·拉巴基 Nadine Labaki'],
 'url': ['/celebrity/1275745/']}
2020-05-04 16:00:21,462 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:21,462 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:21,464 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:21,464 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:21,486 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-04 16:00:21,486 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5 has been crawled, drop it
2020-05-04 16:00:21,493 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 16:00:21,494 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-04 16:00:21,494 -  movie_spider.py[line:134] - INFO: get 19 boxOffice, named .
2020-05-04 16:00:21,495 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#19
{'boxInfo': ['11.67'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1234116],
 'movieName': ['猫公主苏菲'],
 'releaseInfo': ['上映4天'],
 'seatRate': ['3.9%'],
 'showInfo': [1601],
 'showRate': ['0.5%'],
 'showView': ['3'],
 'splitBoxInfo': ['10.97'],
 'splitSumBoxInfo': ['89.1'],
 'sumBoxInfo': ['95.4'],
 'yearRate': ['2019-05-04#19']}
2020-05-04 16:00:21,879 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-04 and tpp_id = 1243904
2020-05-04 16:00:21,879 -  movie_spider.py[line:156] - INFO: movie_name = 动物出击 and movie_year = 2019-05-04 and tpp_id = 1243904
2020-05-04 16:00:21,880 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 16:00:21,880 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8A%A8%E7%89%A9%E5%87%BA%E5%87%BB
2020-05-04 16:00:21,880 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:21,880 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:21,880 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:21,880 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:21,885 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:21,885 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:21,886 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :乔·罗素 Joe Russo
{'identity': ['director'],
 'name': ['乔·罗素 Joe Russo'],
 'url': ['/celebrity/1320870/']}
2020-05-04 16:00:21,888 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,888 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,889 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,889 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,890 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :克里斯托弗·马库斯 Christopher Markus
{'identity': ['author'],
 'name': ['克里斯托弗·马库斯 Christopher Markus'],
 'url': ['/celebrity/1276125/']}
2020-05-04 16:00:21,892 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,892 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,893 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯蒂芬·麦克菲利 Stephen McFeely
{'identity': ['author'],
 'name': ['斯蒂芬·麦克菲利 Stephen McFeely'],
 'url': ['/celebrity/1276126/']}
2020-05-04 16:00:21,894 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,894 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,895 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯坦·李 Stan Lee
{'identity': ['author'],
 'name': ['斯坦·李 Stan Lee'],
 'url': ['/celebrity/1013888/']}
2020-05-04 16:00:21,896 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,896 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,897 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,897 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,897 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :陈鸿仪 Hung-I Chen
{'identity': ['author'],
 'name': ['陈鸿仪 Hung-I Chen'],
 'url': ['/celebrity/1348355/']}
2020-05-04 16:00:21,898 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,898 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,898 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,898 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,899 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :郭采洁 Amber Kuo
{'identity': ['actor'],
 'name': ['郭采洁 Amber Kuo'],
 'url': ['/celebrity/1274814/']}
2020-05-04 16:00:21,900 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,900 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,901 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :郑恺 Kai Zheng
{'identity': ['actor'],
 'name': ['郑恺 Kai Zheng'],
 'url': ['/celebrity/1275564/']}
2020-05-04 16:00:21,902 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,902 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,903 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :李东学 Ethan Li
{'identity': ['actor'],
 'name': ['李东学 Ethan Li'],
 'url': ['/celebrity/1317113/']}
2020-05-04 16:00:21,903 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,903 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,904 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :谢依霖 Yilin Sie
{'identity': ['actor'],
 'name': ['谢依霖 Yilin Sie'],
 'url': ['/celebrity/1319858/']}
2020-05-04 16:00:21,905 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,905 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,905 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :刘心悠 Annie Liu
{'identity': ['actor'],
 'name': ['刘心悠 Annie Liu'],
 'url': ['/celebrity/1001301/']}
2020-05-04 16:00:21,906 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,906 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,907 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :邱欣怡 Xinyi Qiu
{'identity': ['actor'],
 'name': ['邱欣怡 Xinyi Qiu'],
 'url': ['/celebrity/1349465/']}
2020-05-04 16:00:21,907 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,907 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,907 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,907 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,908 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :娜丁·拉巴基 Nadine Labaki
{'identity': ['author'],
 'name': ['娜丁·拉巴基 Nadine Labaki'],
 'url': ['/celebrity/1275745/']}
2020-05-04 16:00:21,909 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,909 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,909 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :吉哈德·霍加里 Jihad Hojeily
{'identity': ['author'],
 'name': ['吉哈德·霍加里 Jihad Hojeily'],
 'url': ['/celebrity/1395542/']}
2020-05-04 16:00:21,910 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,910 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,910 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :米歇尔·凯斯沃尼 Michelle Keserwany
{'identity': ['author'],
 'name': ['米歇尔·凯斯沃尼 Michelle Keserwany'],
 'url': ['/celebrity/1395543/']}
2020-05-04 16:00:21,911 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,911 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,911 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :乔治斯·哈巴兹 Georges Khabbaz
{'identity': ['author'],
 'name': ['乔治斯·哈巴兹 Georges Khabbaz'],
 'url': ['/celebrity/1411931/']}
2020-05-04 16:00:21,912 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,912 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:21,912 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :哈立德·穆扎纳 Khaled Mouzanar
{'identity': ['author'],
 'name': ['哈立德·穆扎纳 Khaled Mouzanar'],
 'url': ['/celebrity/1393709/']}
2020-05-04 16:00:21,913 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,913 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:21,913 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,913 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,913 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :赞恩·阿尔·拉菲亚 Zain al-Rafeea
{'identity': ['actor'],
 'name': ['赞恩·阿尔·拉菲亚 Zain al-Rafeea'],
 'url': ['/celebrity/1393813/']}
2020-05-04 16:00:21,914 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,914 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,914 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :约丹诺斯·希费罗 Yordanos Shiferaw
{'identity': ['actor'],
 'name': ['约丹诺斯·希费罗 Yordanos Shiferaw'],
 'url': ['/celebrity/1411924/']}
2020-05-04 16:00:21,915 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,915 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,915 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :博鲁瓦蒂夫·特雷杰·班科尔 Boluwatife Treasure Bankole
{'identity': ['actor'],
 'name': ['博鲁瓦蒂夫·特雷杰·班科尔 Boluwatife Treasure Bankole'],
 'url': ['/celebrity/1395545/']}
2020-05-04 16:00:21,916 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,916 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,916 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :卡萨尔·艾尔·哈达德 Kawsar Al Haddad
{'identity': ['actor'],
 'name': ['卡萨尔·艾尔·哈达德 Kawsar Al Haddad'],
 'url': ['/celebrity/1411925/']}
2020-05-04 16:00:21,917 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,917 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:21,917 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :法迪·尤瑟夫 Fadi Yousef
{'identity': ['actor'],
 'name': ['法迪·尤瑟夫 Fadi Yousef'],
 'url': ['/celebrity/1411926/']}
2020-05-04 16:00:23,523 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:23,523 -  movie_spider.py[line:176] - INFO: get movie info url = https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:23,525 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:23,525 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88 has been crawled, drop it
2020-05-04 16:00:23,551 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-04 16:00:23,551 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2 has been crawled, drop it
2020-05-04 16:00:23,567 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 16:00:23,568 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD> (referer: https://movie.douban.com/)
2020-05-04 16:00:23,570 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:23,571 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6> (referer: https://movie.douban.com/)
2020-05-04 16:00:23,573 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:23,574 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5> (referer: https://movie.douban.com/)
2020-05-04 16:00:23,575 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-04 16:00:23,575 -  movie_spider.py[line:134] - INFO: get 20 boxOffice, named .
2020-05-04 16:00:23,576 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#20
{'boxInfo': ['10.74'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [245881],
 'movieName': ['麦兜我和我妈妈'],
 'releaseInfo': [''],
 'seatRate': ['8.2%'],
 'showInfo': [515],
 'showRate': ['0.1%'],
 'showView': ['7'],
 'splitBoxInfo': ['9.57'],
 'splitSumBoxInfo': ['4646.4'],
 'sumBoxInfo': ['4668.1'],
 'yearRate': ['2019-05-04#20']}
2020-05-04 16:00:23,783 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-04 and tpp_id = 1211727
2020-05-04 16:00:23,783 -  movie_spider.py[line:156] - INFO: movie_name = 反贪风暴4 and movie_year = 2019-05-04 and tpp_id = 1211727
2020-05-04 16:00:23,784 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-04 16:00:23,784 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%8D%E8%B4%AA%E9%A3%8E%E6%9A%B44
2020-05-04 16:00:23,784 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:23,784 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:23,784 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:23,784 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:23,790 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:23,790 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:23,828 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:23,828 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:23,830 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:23,830 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:23,830 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:23,830 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:23,830 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:23,830 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:23,831 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:23,831 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:23,831 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:23,831 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:23,833 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:23,833 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:23,834 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'sql_mode'
2020-05-04 16:00:23,835 -  log.py[line:110] - INFO: {}
2020-05-04 16:00:23,838 -  log.py[line:110] - INFO: SHOW VARIABLES LIKE 'lower_case_table_names'
2020-05-04 16:00:23,838 -  log.py[line:110] - INFO: {}
2020-05-04 16:00:23,839 -  log.py[line:110] - INFO: SELECT DATABASE()
2020-05-04 16:00:23,840 -  log.py[line:110] - INFO: {}
2020-05-04 16:00:23,840 -  log.py[line:110] - INFO: show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'
2020-05-04 16:00:23,840 -  log.py[line:110] - INFO: {}
2020-05-04 16:00:23,843 -  log.py[line:110] - INFO: SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1
2020-05-04 16:00:23,843 -  log.py[line:110] - INFO: {}
2020-05-04 16:00:23,843 -  log.py[line:110] - INFO: SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1
2020-05-04 16:00:23,843 -  log.py[line:110] - INFO: {}
2020-05-04 16:00:23,844 -  log.py[line:110] - INFO: SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1
2020-05-04 16:00:23,844 -  log.py[line:110] - INFO: {}
2020-05-04 16:00:23,845 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:23,845 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:23,845 -  log.py[line:110] - INFO: {'name': '斯里兰姆·拉格万 Sriram Raghavan', 'url': '/celebrity/1306786/', 'identity': 'director'}
2020-05-04 16:00:23,846 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:24,114 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:24,115 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:24,115 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:24,156 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,156 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,158 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,158 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,158 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,158 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,158 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,158 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,159 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯里兰姆·拉格万 Sriram Raghavan
{'identity': ['director'],
 'name': ['斯里兰姆·拉格万 Sriram Raghavan'],
 'url': ['/celebrity/1306786/']}
2020-05-04 16:00:24,159 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-04 and tpp_id = 476263
2020-05-04 16:00:24,159 -  movie_spider.py[line:156] - INFO: movie_name = 天上再见 and movie_year = 2019-05-04 and tpp_id = 476263
2020-05-04 16:00:24,159 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-04 16:00:24,159 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%A4%A9%E4%B8%8A%E5%86%8D%E8%A7%81
2020-05-04 16:00:24,159 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:24,159 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:24,160 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:24,160 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:24,161 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:24,161 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:24,171 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,171 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,172 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,172 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,172 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,172 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,172 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,172 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,173 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:24,173 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:24,173 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:24,173 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:24,173 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:24,173 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:24,173 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:24,174 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:24,174 -  log.py[line:110] - INFO: {'name': '琪拉·穆拉托娃 Kira Muratova', 'url': '/celebrity/1040878/', 'identity': 'director'}
2020-05-04 16:00:24,174 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:24,306 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:24,307 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 16:00:24,307 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/30283179/?suggest=%E6%92%9E%E6%AD%BB%E4%BA%86%E4%B8%80%E5%8F%AA%E7%BE%8A
2020-05-04 16:00:24,348 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,348 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,350 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,350 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,350 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,350 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,351 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,351 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,351 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :万玛才旦 Pema Tseden
{'identity': ['director'],
 'name': ['万玛才旦 Pema Tseden'],
 'url': ['/celebrity/1316181/']}
2020-05-04 16:00:24,352 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 16:00:24,352 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2
2020-05-04 16:00:24,362 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,362 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:24,363 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,363 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:24,363 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,363 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,364 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,364 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:24,364 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:24,364 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:24,364 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:24,364 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:24,364 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:24,364 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:24,365 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:24,365 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:24,365 -  log.py[line:110] - INFO: {'name': '田梓橙 Zicheng Tian', 'url': '/celebrity/1415164/', 'identity': 'director'}
2020-05-04 16:00:24,366 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:24,504 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2>
None
2020-05-04 16:00:24,505 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:24,505 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:24,507 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :杰克·科比 Jack Kirby
{'identity': ['author'],
 'name': ['杰克·科比 Jack Kirby'],
 'url': ['/celebrity/1050183/']}
2020-05-04 16:00:24,509 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:24,509 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:24,510 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :吉姆·斯特林 Jim Starlin
{'identity': ['author'],
 'name': ['吉姆·斯特林 Jim Starlin'],
 'url': ['/celebrity/1360715/']}
2020-05-04 16:00:24,511 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,511 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:24,512 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,512 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,514 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :小罗伯特·唐尼 Robert Downey Jr.
{'identity': ['actor'],
 'name': ['小罗伯特·唐尼 Robert Downey Jr.'],
 'url': ['/celebrity/1016681/']}
2020-05-04 16:00:24,516 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,516 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,517 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :李荣浩 Ronghao Li
{'identity': ['actor'],
 'name': ['李荣浩 Ronghao Li'],
 'url': ['/celebrity/1346431/']}
2020-05-04 16:00:24,519 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,519 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,521 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :蓝心湄 Pauline Lan
{'identity': ['actor'],
 'name': ['蓝心湄 Pauline Lan'],
 'url': ['/celebrity/1275579/']}
2020-05-04 16:00:24,522 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,522 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,524 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :林辰唏 Zaizai Lin
{'identity': ['actor'],
 'name': ['林辰唏 Zaizai Lin'],
 'url': ['/celebrity/1275283/']}
2020-05-04 16:00:24,525 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,525 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,527 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :林美秀 Mei-shiu Lin
{'identity': ['actor'],
 'name': ['林美秀 Mei-shiu Lin'],
 'url': ['/celebrity/1316086/']}
2020-05-04 16:00:24,528 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,528 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,530 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :海塔·塞德拉·伊扎姆 Haita &#39;Cedra&#39; Izzam
{'identity': ['actor'],
 'name': ['海塔·塞德拉·伊扎姆 Haita &#39;Cedra&#39; Izzam'],
 'url': ['/celebrity/1411927/']}
2020-05-04 16:00:24,532 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,532 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,534 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :阿拉·乔什涅 Alaa Chouchnieh
{'identity': ['actor'],
 'name': ['阿拉·乔什涅 Alaa Chouchnieh'],
 'url': ['/celebrity/1411928/']}
2020-05-04 16:00:24,536 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,536 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:24,538 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :娜丁·拉巴基 Nadine Labaki
{'identity': ['actor'],
 'name': ['娜丁·拉巴基 Nadine Labaki'],
 'url': ['/celebrity/1275745/']}
2020-05-04 16:00:25,613 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-04 16:00:25,613 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88 has been crawled, drop it
2020-05-04 16:00:25,622 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:25,623 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2> (referer: https://movie.douban.com/)
2020-05-04 16:00:25,623 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-04 16:00:25,623 -  movie_spider.py[line:134] - INFO: get 21 boxOffice, named .
2020-05-04 16:00:25,624 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#21
{'boxInfo': ['9.48'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1213175],
 'movieName': ['在乎你'],
 'releaseInfo': ['上映23天'],
 'seatRate': ['0.8%'],
 'showInfo': [27],
 'showRate': ['<0.1%'],
 'showView': ['51'],
 'splitBoxInfo': ['9.48'],
 'splitSumBoxInfo': ['732.9'],
 'sumBoxInfo': ['764.7'],
 'yearRate': ['2019-05-04#21']}
2020-05-04 16:00:26,417 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 16:00:26,417 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26878827/?suggest=%E6%82%9F%E7%A9%BA%E5%A5%87%E9%81%87%E8%AE%B0
2020-05-04 16:00:26,445 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:26,445 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:26,447 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:26,447 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:26,447 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,447 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,447 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:26,447 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:26,448 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :殷玉麒 Yuqi Yin
{'identity': ['director'],
 'name': ['殷玉麒 Yuqi Yin'],
 'url': ['/celebrity/1330909/']}
2020-05-04 16:00:26,448 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,448 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,448 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,448 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,449 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:26,449 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:26,449 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:26,449 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:26,449 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:26,449 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:26,449 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:26,449 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:26,450 -  log.py[line:110] - INFO: {'name': '阿里吉特·比沙什 Arijit Biswas', 'url': '/celebrity/1407571/', 'identity': 'author'}
2020-05-04 16:00:26,450 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:26,686 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:26,687 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,687 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,688 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,688 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,690 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :阿里吉特·比沙什 Arijit Biswas
{'identity': ['author'],
 'name': ['阿里吉特·比沙什 Arijit Biswas'],
 'url': ['/celebrity/1407571/']}
2020-05-04 16:00:26,691 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,691 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,693 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:26,693 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:26,693 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:26,693 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:26,694 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:26,694 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:26,694 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:26,695 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:26,695 -  log.py[line:110] - INFO: {'name': '约戈什·查德卡尔 Yogesh Chandekar', 'url': '/celebrity/1407572/', 'identity': 'author'}
2020-05-04 16:00:26,697 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:26,834 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:26,835 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,835 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,836 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,836 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:26,837 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琪拉·穆拉托娃 Kira Muratova
{'identity': ['author'],
 'name': ['琪拉·穆拉托娃 Kira Muratova'],
 'url': ['/celebrity/1040878/']}
2020-05-04 16:00:26,839 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,839 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:26,840 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:26,840 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:26,842 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:26,842 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:26,843 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:26,843 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:26,843 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:26,843 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:26,844 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:26,845 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:26,846 -  log.py[line:110] - INFO: {'name': '阿拉·杰米多娃 Alla Demidova', 'url': '/celebrity/1080247/', 'identity': 'actor'}
2020-05-04 16:00:27,006 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:27,204 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:27,204 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,204 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,205 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:27,205 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:27,207 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :万玛才旦 Pema Tseden
{'identity': ['author'],
 'name': ['万玛才旦 Pema Tseden'],
 'url': ['/celebrity/1316181/']}
2020-05-04 16:00:27,209 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:27,209 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:27,210 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :次仁罗布 Tsering Norbu
{'identity': ['author'],
 'name': ['次仁罗布 Tsering Norbu'],
 'url': ['/celebrity/1415681/']}
2020-05-04 16:00:27,211 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,211 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,212 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,212 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,214 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :金巴 Jinpa
{'identity': ['actor'], 'name': ['金巴 Jinpa'], 'url': ['/celebrity/1362878/']}
2020-05-04 16:00:27,215 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,215 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,215 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:27,215 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:27,217 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:27,217 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:27,217 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:27,217 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:27,217 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:27,217 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:27,218 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:27,219 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:27,219 -  log.py[line:110] - INFO: {'name': '方岚 Lan Fang', 'url': '/celebrity/1394055/', 'identity': 'author'}
2020-05-04 16:00:27,221 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:27,352 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2>
None
2020-05-04 16:00:27,353 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,353 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,355 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :克里斯·埃文斯 Chris Evans
{'identity': ['actor'],
 'name': ['克里斯·埃文斯 Chris Evans'],
 'url': ['/celebrity/1017885/']}
2020-05-04 16:00:27,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,356 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,358 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :马克·鲁弗洛 Mark Ruffalo
{'identity': ['actor'],
 'name': ['马克·鲁弗洛 Mark Ruffalo'],
 'url': ['/celebrity/1040505/']}
2020-05-04 16:00:27,360 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,360 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,361 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :克里斯·海姆斯沃斯 Chris Hemsworth
{'identity': ['actor'],
 'name': ['克里斯·海姆斯沃斯 Chris Hemsworth'],
 'url': ['/celebrity/1021959/']}
2020-05-04 16:00:27,363 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,363 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,367 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :姚亦晴 Shiny Yao
{'identity': ['actor'],
 'name': ['姚亦晴 Shiny Yao'],
 'url': ['/celebrity/1420673/']}
2020-05-04 16:00:27,372 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26311974
{'actors': '郭采洁/郑恺/李东学/谢依霖/刘心悠/邱欣怡/李荣浩/蓝心湄/林辰唏/林美秀',
 'area': ' 中国台湾 / 中国大陆',
 'dbMovieID': ['26311974'],
 'directors': '陈鸿仪',
 'doubanRate': ['2.8'],
 'duration': [99],
 'genre': '爱情',
 'movieName': ['下一任：前任'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['23803'],
 'tppMovieID': [1228776],
 'writers': '陈鸿仪'}
2020-05-04 16:00:27,376 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,376 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,378 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :埃利亚斯·库利 Elias Khoury
{'identity': ['actor'],
 'name': ['埃利亚斯·库利 Elias Khoury'],
 'url': ['/celebrity/1411929/']}
2020-05-04 16:00:27,379 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,379 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:27,381 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :努尔·艾尔·侯赛尼 Nour El Husseini
{'identity': ['actor'],
 'name': ['努尔·艾尔·侯赛尼 Nour El Husseini'],
 'url': ['/celebrity/1411930/']}
2020-05-04 16:00:27,384 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30170448
{'actors': '赞恩·阿尔·拉菲亚/约丹诺斯·希费罗/博鲁瓦蒂夫·特雷杰·班科尔/卡萨尔·艾尔·哈达德/法迪·尤瑟夫/海塔·塞德拉·伊扎姆/阿拉·乔什涅/娜丁·拉巴基/埃利亚斯·库利/努尔·艾尔·侯赛尼',
 'area': ' 黎巴嫩 / 法国 / 美国',
 'dbMovieID': ['30170448'],
 'directors': '娜丁·拉巴基',
 'doubanRate': ['9.1'],
 'duration': [126],
 'genre': '剧情',
 'movieName': ['何以为家 كفرناحوم'],
 'publishedDate': ['2018-05-17'],
 'rateCount': ['638918'],
 'tppMovieID': [1218727],
 'writers': '娜丁·拉巴基/吉哈德·霍加里/米歇尔·凯斯沃尼/乔治斯·哈巴兹/哈立德·穆扎纳'}
2020-05-04 16:00:27,388 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-04 16:00:27,388 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0 has been crawled, drop it
2020-05-04 16:00:27,403 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88> (referer: https://movie.douban.com/)
2020-05-04 16:00:27,404 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-04 16:00:27,404 -  movie_spider.py[line:134] - INFO: get 22 boxOffice, named .
2020-05-04 16:00:27,405 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#22
{'boxInfo': ['9.03'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1229702],
 'movieName': ['青蛙王子历险记'],
 'releaseInfo': ['上映30天'],
 'seatRate': ['13.2%'],
 'showInfo': [83],
 'showRate': ['<0.1%'],
 'showView': ['15'],
 'splitBoxInfo': ['9.00'],
 'splitSumBoxInfo': ['1062.1'],
 'sumBoxInfo': ['1118.6'],
 'yearRate': ['2019-05-04#22']}
2020-05-04 16:00:27,854 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:27,854 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:27,891 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:27,891 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:27,893 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:27,893 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:27,893 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,893 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:27,893 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:27,893 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:27,894 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:27,894 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:27,894 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:27,894 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:27,894 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:27,894 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:27,894 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:27,895 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:27,895 -  log.py[line:110] - INFO: {'name': '迪兰·布朗 Dylan Brown', 'url': '/celebrity/1414949/', 'identity': 'director'}
2020-05-04 16:00:27,934 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:28,033 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:28,034 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-04 and tpp_id = 1212492
2020-05-04 16:00:28,034 -  movie_spider.py[line:156] - INFO: movie_name = 老师·好 and movie_year = 2019-05-04 and tpp_id = 1212492
2020-05-04 16:00:28,034 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-04 16:00:28,034 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E8%80%81%E5%B8%88%C2%B7%E5%A5%BD
2020-05-04 16:00:28,034 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:28,034 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:28,035 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:28,035 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:28,038 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:28,038 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:28,068 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:28,068 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:28,069 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:28,069 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:28,070 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,070 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,070 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:28,070 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:28,071 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琪拉·穆拉托娃 Kira Muratova
{'identity': ['director'],
 'name': ['琪拉·穆拉托娃 Kira Muratova'],
 'url': ['/celebrity/1040878/']}
2020-05-04 16:00:28,071 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-04 and tpp_id = 1205909
2020-05-04 16:00:28,071 -  movie_spider.py[line:156] - INFO: movie_name = 祈祷落幕时 and movie_year = 2019-05-04 and tpp_id = 1205909
2020-05-04 16:00:28,071 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-04 16:00:28,071 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%A5%88%E7%A5%B7%E8%90%BD%E5%B9%95%E6%97%B6
2020-05-04 16:00:28,072 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:28,072 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:28,072 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:28,072 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:28,073 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:28,073 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:28,084 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:28,084 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:28,085 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:28,085 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:28,085 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,085 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,085 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:28,085 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:28,086 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琪拉·穆拉托娃 Kira Muratova
{'identity': ['director'],
 'name': ['琪拉·穆拉托娃 Kira Muratova'],
 'url': ['/celebrity/1040878/']}
2020-05-04 16:00:28,086 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-04 and tpp_id = 1239281
2020-05-04 16:00:28,086 -  movie_spider.py[line:156] - INFO: movie_name = 港珠澳大桥 and movie_year = 2019-05-04 and tpp_id = 1239281
2020-05-04 16:00:28,086 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-04 16:00:28,086 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B8%AF%E7%8F%A0%E6%BE%B3%E5%A4%A7%E6%A1%A5
2020-05-04 16:00:28,087 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:28,087 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:28,087 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:28,087 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:28,087 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,087 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,088 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:28,088 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:28,088 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :殷玉麒 Yuqi Yin
{'identity': ['author'],
 'name': ['殷玉麒 Yuqi Yin'],
 'url': ['/celebrity/1330909/']}
2020-05-04 16:00:28,088 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,088 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:28,089 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,089 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,089 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :张震 Zhen Zhang
{'identity': ['actor'],
 'name': ['张震 Zhen Zhang'],
 'url': ['/celebrity/1378129/']}
2020-05-04 16:00:28,089 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,089 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,090 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :李姗姗 Shanshan Li
{'identity': ['actor'],
 'name': ['李姗姗 Shanshan Li'],
 'url': ['/celebrity/1360420/']}
2020-05-04 16:00:28,091 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,091 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,091 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :元气纣  
{'identity': ['actor'], 'name': ['元气纣  '], 'url': ['/celebrity/1411430/']}
2020-05-04 16:00:28,092 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,092 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,092 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :宝木中阳 Ming Song
{'identity': ['actor'],
 'name': ['宝木中阳 Ming Song'],
 'url': ['/celebrity/1334350/']}
2020-05-04 16:00:28,092 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,092 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,093 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :叮当 Sheng Zhang
{'identity': ['actor'],
 'name': ['叮当 Sheng Zhang'],
 'url': ['/celebrity/1361373/']}
2020-05-04 16:00:28,093 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,093 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:28,094 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :李璐 Lu Li
{'identity': ['actor'], 'name': ['李璐 Lu Li'], 'url': ['/celebrity/1410442/']}
2020-05-04 16:00:28,094 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26878827
{'actors': '张震/李姗姗/元气纣/宝木中阳/叮当/李璐',
 'area': ' 中国大陆',
 'dbMovieID': ['26878827'],
 'directors': '殷玉麒',
 'doubanRate': ['2.7'],
 'duration': [88],
 'genre': '喜剧/动画',
 'movieName': ['悟空奇遇记'],
 'publishedDate': ['2019-05-01'],
 'rateCount': ['712'],
 'tppMovieID': [672379],
 'writers': '殷玉麒'}
2020-05-04 16:00:29,585 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,585 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,588 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :约戈什·查德卡尔 Yogesh Chandekar
{'identity': ['author'],
 'name': ['约戈什·查德卡尔 Yogesh Chandekar'],
 'url': ['/celebrity/1407572/']}
2020-05-04 16:00:29,590 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,590 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,592 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯里兰姆·拉格万 Sriram Raghavan
{'identity': ['author'],
 'name': ['斯里兰姆·拉格万 Sriram Raghavan'],
 'url': ['/celebrity/1306786/']}
2020-05-04 16:00:29,594 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,594 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,595 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:29,595 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:29,595 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:29,595 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:29,596 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:29,596 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:29,597 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:29,598 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:29,598 -  log.py[line:110] - INFO: {'name': '赫曼斯·饶 Hemanth M. Rao', 'url': '/celebrity/1407573/', 'identity': 'author'}
2020-05-04 16:00:29,600 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:29,841 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:29,842 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,842 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,844 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯里兰姆·拉格万 Sriram Raghavan
{'identity': ['author'],
 'name': ['斯里兰姆·拉格万 Sriram Raghavan'],
 'url': ['/celebrity/1306786/']}
2020-05-04 16:00:29,846 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,846 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,847 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :赫曼斯·饶 Hemanth M. Rao
{'identity': ['author'],
 'name': ['赫曼斯·饶 Hemanth M. Rao'],
 'url': ['/celebrity/1407573/']}
2020-05-04 16:00:29,849 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,849 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:29,850 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:29,850 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:29,851 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:29,851 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:29,851 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:29,851 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:29,852 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:29,853 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:29,853 -  log.py[line:110] - INFO: {'name': '普哈·拉达·瑟蒂 Pooja Ladha Surti', 'url': '/celebrity/1306344/', 'identity': 'author'}
2020-05-04 16:00:29,914 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:30,038 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:30,039 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,039 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,041 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:30,041 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:30,041 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:30,041 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:30,042 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:30,042 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:30,042 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:30,043 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:30,043 -  log.py[line:110] - INFO: {'name': '雷娜塔·利特维诺娃 Renata Litvinova', 'url': '/celebrity/1014583/', 'identity': 'actor'}
2020-05-04 16:00:30,045 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:30,197 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:30,198 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,198 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,200 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :更登彭措 Genden Phuntsok
{'identity': ['actor'],
 'name': ['更登彭措 Genden Phuntsok'],
 'url': ['/celebrity/1363820/']}
2020-05-04 16:00:30,202 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,202 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,204 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :索朗旺姆 Sonam Wangmo
{'identity': ['actor'],
 'name': ['索朗旺姆 Sonam Wangmo'],
 'url': ['/celebrity/1400147/']}
2020-05-04 16:00:30,205 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,205 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,207 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :加华草 
{'identity': ['actor'], 'name': ['加华草 '], 'url': ['/celebrity/1431565/']}
2020-05-04 16:00:30,208 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:30,208 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:30,210 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :田梓橙 Zicheng Tian
{'identity': ['author'],
 'name': ['田梓橙 Zicheng Tian'],
 'url': ['/celebrity/1415164/']}
2020-05-04 16:00:30,212 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:30,212 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:30,212 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,212 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,214 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:30,214 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:30,214 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:30,214 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:30,215 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:30,215 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:30,215 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:30,216 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:30,216 -  log.py[line:110] - INFO: {'name': '王泽宗 Zezong Wang', 'url': '/celebrity/1415165/', 'identity': 'actor'}
2020-05-04 16:00:30,218 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:30,379 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2>
None
2020-05-04 16:00:30,380 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,380 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,380 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯嘉丽·约翰逊 Scarlett Johansson
{'identity': ['actor'],
 'name': ['斯嘉丽·约翰逊 Scarlett Johansson'],
 'url': ['/celebrity/1054453/']}
2020-05-04 16:00:30,381 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,381 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,381 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :杰瑞米·雷纳 Jeremy Renner
{'identity': ['actor'],
 'name': ['杰瑞米·雷纳 Jeremy Renner'],
 'url': ['/celebrity/1013770/']}
2020-05-04 16:00:30,382 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,382 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,382 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :保罗·路德 Paul Rudd
{'identity': ['actor'],
 'name': ['保罗·路德 Paul Rudd'],
 'url': ['/celebrity/1002667/']}
2020-05-04 16:00:30,383 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,383 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,383 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :凯伦·吉兰 Karen Gillan
{'identity': ['actor'],
 'name': ['凯伦·吉兰 Karen Gillan'],
 'url': ['/celebrity/1036344/']}
2020-05-04 16:00:30,384 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,384 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,385 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :唐·钱德尔 Don Cheadle
{'identity': ['actor'],
 'name': ['唐·钱德尔 Don Cheadle'],
 'url': ['/celebrity/1053573/']}
2020-05-04 16:00:30,385 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,385 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,386 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :布丽·拉尔森 Brie Larson
{'identity': ['actor'],
 'name': ['布丽·拉尔森 Brie Larson'],
 'url': ['/celebrity/1027194/']}
2020-05-04 16:00:30,386 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,386 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,387 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :布莱德利·库珀 Bradley Cooper
{'identity': ['actor'],
 'name': ['布莱德利·库珀 Bradley Cooper'],
 'url': ['/celebrity/1013757/']}
2020-05-04 16:00:30,388 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,388 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,388 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :泰莎·汤普森 Tessa Thompson
{'identity': ['actor'],
 'name': ['泰莎·汤普森 Tessa Thompson'],
 'url': ['/celebrity/1027395/']}
2020-05-04 16:00:30,389 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,389 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,389 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :汤姆·赫兰德 Tom Holland
{'identity': ['actor'],
 'name': ['汤姆·赫兰德 Tom Holland'],
 'url': ['/celebrity/1325351/']}
2020-05-04 16:00:30,389 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,389 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:30,390 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :伊丽莎白·奥尔森 Elizabeth Olsen
{'identity': ['actor'],
 'name': ['伊丽莎白·奥尔森 Elizabeth Olsen'],
 'url': ['/celebrity/1129847/']}
2020-05-04 16:00:33,579 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 16:00:33,579 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0 has been crawled, drop it
2020-05-04 16:00:33,609 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0> (referer: https://movie.douban.com/)
2020-05-04 16:00:33,611 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-04 16:00:33,611 -  movie_spider.py[line:134] - INFO: get 23 boxOffice, named .
2020-05-04 16:00:33,613 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#23
{'boxInfo': ['8.45'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [643506],
 'movieName': ['古镇画情'],
 'releaseInfo': ['展映'],
 'seatRate': ['--'],
 'showInfo': [74],
 'showRate': ['<0.1%'],
 'showView': ['30'],
 'splitBoxInfo': ['8.45'],
 'splitSumBoxInfo': ['1161.9'],
 'sumBoxInfo': ['1164.8'],
 'yearRate': ['2019-05-04#23']}
2020-05-04 16:00:33,853 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:33,853 -  movie_spider.py[line:182] - INFO: crawled movie info of https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88
2020-05-04 16:00:33,886 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:33,886 -  movie_spider.py[line:193] - INFO: len of movie info = 13
2020-05-04 16:00:33,888 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:33,888 -  movie_spider.py[line:230] - INFO: finish parse one movie info, ready to parse person
2020-05-04 16:00:33,888 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:33,888 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:33,889 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:33,889 -  movie_spider.py[line:211] - INFO: get person info with identity director
2020-05-04 16:00:33,890 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琪拉·穆拉托娃 Kira Muratova
{'identity': ['director'],
 'name': ['琪拉·穆拉托娃 Kira Muratova'],
 'url': ['/celebrity/1040878/']}
2020-05-04 16:00:33,890 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-04 and tpp_id = 1234116
2020-05-04 16:00:33,890 -  movie_spider.py[line:156] - INFO: movie_name = 猫公主苏菲 and movie_year = 2019-05-04 and tpp_id = 1234116
2020-05-04 16:00:33,891 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-04 16:00:33,891 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8C%AB%E5%85%AC%E4%B8%BB%E8%8B%8F%E8%8F%B2
2020-05-04 16:00:33,891 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:33,891 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:33,891 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:33,891 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:33,892 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:33,892 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:33,893 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:33,893 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:33,893 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:33,893 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:33,893 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:33,893 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:33,894 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:33,894 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:33,894 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:33,894 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:33,894 -  log.py[line:110] - INFO: {'name': '乔什·阿佩尔鲍姆 Josh Appelbaum', 'url': '/celebrity/1341524/', 'identity': 'author'}
2020-05-04 16:00:33,895 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:34,031 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:34,032 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,032 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,033 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,033 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,034 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琪拉·穆拉托娃 Kira Muratova
{'identity': ['author'],
 'name': ['琪拉·穆拉托娃 Kira Muratova'],
 'url': ['/celebrity/1040878/']}
2020-05-04 16:00:34,036 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,036 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,037 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,037 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,038 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :阿拉·杰米多娃 Alla Demidova
{'identity': ['actor'],
 'name': ['阿拉·杰米多娃 Alla Demidova'],
 'url': ['/celebrity/1080247/']}
2020-05-04 16:00:34,040 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,040 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,042 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :雷娜塔·利特维诺娃 Renata Litvinova
{'identity': ['actor'],
 'name': ['雷娜塔·利特维诺娃 Renata Litvinova'],
 'url': ['/celebrity/1014583/']}
2020-05-04 16:00:34,043 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,043 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,044 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,044 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,045 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琪拉·穆拉托娃 Kira Muratova
{'identity': ['author'],
 'name': ['琪拉·穆拉托娃 Kira Muratova'],
 'url': ['/celebrity/1040878/']}
2020-05-04 16:00:34,046 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,046 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,048 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,048 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,050 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :阿拉·杰米多娃 Alla Demidova
{'identity': ['actor'],
 'name': ['阿拉·杰米多娃 Alla Demidova'],
 'url': ['/celebrity/1080247/']}
2020-05-04 16:00:34,052 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,052 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,055 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :雷娜塔·利特维诺娃 Renata Litvinova
{'identity': ['actor'],
 'name': ['雷娜塔·利特维诺娃 Renata Litvinova'],
 'url': ['/celebrity/1014583/']}
2020-05-04 16:00:34,061 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,061 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,062 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :普哈·拉达·瑟蒂 Pooja Ladha Surti
{'identity': ['author'],
 'name': ['普哈·拉达·瑟蒂 Pooja Ladha Surti'],
 'url': ['/celebrity/1306344/']}
2020-05-04 16:00:34,064 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,064 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,066 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:34,066 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:34,066 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:34,066 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:34,067 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:34,067 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:34,067 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:34,068 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:34,068 -  log.py[line:110] - INFO: {'name': '奥利维耶·特雷内  Olivier Treiner', 'url': '/celebrity/1318819/', 'identity': 'author'}
2020-05-04 16:00:34,070 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:34,179 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:34,180 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,180 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:34,182 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :奥利维耶·特雷内  Olivier Treiner
{'identity': ['author'],
 'name': ['奥利维耶·特雷内  Olivier Treiner'],
 'url': ['/celebrity/1318819/']}
2020-05-04 16:00:34,183 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,183 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:34,184 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,184 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,185 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:34,185 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:34,186 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:34,186 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:34,186 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:34,186 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:34,187 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:34,188 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:34,188 -  log.py[line:110] - INFO: {'name': '阿尤斯曼·库拉纳 Ayushmann Khurrana', 'url': '/celebrity/1327903/', 'identity': 'actor'}
2020-05-04 16:00:34,190 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:34,338 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:34,339 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,339 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:34,341 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:34,341 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:34,341 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:34,341 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:34,342 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:34,342 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:34,342 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:34,343 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:34,343 -  log.py[line:110] - INFO: {'name': '尼娜·鲁斯拉诺娃 Nina Ruslanova', 'url': '/celebrity/1146176/', 'identity': 'actor'}
2020-05-04 16:00:34,345 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:34,497 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:34,500 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30283179
{'actors': '金巴/更登彭措/索朗旺姆/加华草',
 'area': ' 中国大陆',
 'dbMovieID': ['30283179'],
 'directors': '万玛才旦',
 'doubanRate': ['7.2'],
 'duration': [87],
 'genre': '剧情',
 'movieName': ['撞死了一只羊'],
 'publishedDate': ['2018-09-04'],
 'rateCount': ['40935'],
 'tppMovieID': [1230152],
 'writers': '万玛才旦/次仁罗布'}
2020-05-04 16:00:36,338 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,338 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,341 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:36,341 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:36,342 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:36,342 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:36,342 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:36,342 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:36,343 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:36,344 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:36,344 -  log.py[line:110] - INFO: {'name': '慈婉彤 Wantong Ci', 'url': '/celebrity/1385236/', 'identity': 'actor'}
2020-05-04 16:00:36,346 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:36,454 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2>
None
2020-05-04 16:00:36,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,457 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :本尼迪克特·康伯巴奇 Benedict Cumberbatch
{'identity': ['actor'],
 'name': ['本尼迪克特·康伯巴奇 Benedict Cumberbatch'],
 'url': ['/celebrity/1009405/']}
2020-05-04 16:00:36,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,458 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,460 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :蒂尔达·斯文顿 Tilda Swinton
{'identity': ['actor'],
 'name': ['蒂尔达·斯文顿 Tilda Swinton'],
 'url': ['/celebrity/1025152/']}
2020-05-04 16:00:36,462 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,462 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:36,463 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :格温妮斯·帕特洛 Gwyneth Paltrow
{'identity': ['actor'],
 'name': ['格温妮斯·帕特洛 Gwyneth Paltrow'],
 'url': ['/celebrity/1018985/']}
2020-05-04 16:00:36,472 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-04 16:00:36,472 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85 has been crawled, drop it
2020-05-04 16:00:36,493 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0> (referer: https://movie.douban.com/)
2020-05-04 16:00:36,494 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-04 16:00:36,494 -  movie_spider.py[line:134] - INFO: get 24 boxOffice, named .
2020-05-04 16:00:36,495 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#24
{'boxInfo': ['8.11'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [836],
 'movieName': ['毕业那年'],
 'releaseInfo': [''],
 'seatRate': ['--'],
 'showInfo': [46],
 'showRate': ['<0.1%'],
 'showView': ['55'],
 'splitBoxInfo': ['8.10'],
 'splitSumBoxInfo': ['1062.3'],
 'sumBoxInfo': ['1064.0'],
 'yearRate': ['2019-05-04#24']}
2020-05-04 16:00:37,237 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-04 and tpp_id = 245881
2020-05-04 16:00:37,237 -  movie_spider.py[line:156] - INFO: movie_name = 麦兜我和我妈妈 and movie_year = 2019-05-04 and tpp_id = 245881
2020-05-04 16:00:37,237 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-04 16:00:37,237 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88
2020-05-04 16:00:37,238 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:37,238 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:37,238 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:37,238 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:37,241 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:37,241 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:37,242 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:37,242 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:37,244 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琪拉·穆拉托娃 Kira Muratova
{'identity': ['author'],
 'name': ['琪拉·穆拉托娃 Kira Muratova'],
 'url': ['/celebrity/1040878/']}
2020-05-04 16:00:37,246 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:37,246 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:37,247 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,247 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,249 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :阿拉·杰米多娃 Alla Demidova
{'identity': ['actor'],
 'name': ['阿拉·杰米多娃 Alla Demidova'],
 'url': ['/celebrity/1080247/']}
2020-05-04 16:00:37,252 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,252 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,254 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :雷娜塔·利特维诺娃 Renata Litvinova
{'identity': ['actor'],
 'name': ['雷娜塔·利特维诺娃 Renata Litvinova'],
 'url': ['/celebrity/1014583/']}
2020-05-04 16:00:37,256 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:37,256 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:37,257 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,257 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,257 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,257 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,258 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,258 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,259 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:37,259 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:37,260 -  log.py[line:110] - INFO: {'name': '安德烈·内梅克 André Nemec', 'url': '/celebrity/1341525/', 'identity': 'author'}
2020-05-04 16:00:37,262 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:37,430 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:37,432 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,432 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,433 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :尼娜·鲁斯拉诺娃 Nina Ruslanova
{'identity': ['actor'],
 'name': ['尼娜·鲁斯拉诺娃 Nina Ruslanova'],
 'url': ['/celebrity/1146176/']}
2020-05-04 16:00:37,435 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,435 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,436 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,436 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,437 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,437 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,437 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,437 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,438 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:37,439 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:37,439 -  log.py[line:110] - INFO: {'name': 'Yuri Shlykov', 'url': '/celebrity/1138811/', 'identity': 'actor'}
2020-05-04 16:00:37,441 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:37,589 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:37,590 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,590 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,592 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :尼娜·鲁斯拉诺娃 Nina Ruslanova
{'identity': ['actor'],
 'name': ['尼娜·鲁斯拉诺娃 Nina Ruslanova'],
 'url': ['/celebrity/1146176/']}
2020-05-04 16:00:37,594 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,594 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,596 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Yuri Shlykov
{'identity': ['actor'],
 'name': ['Yuri Shlykov'],
 'url': ['/celebrity/1138811/']}
2020-05-04 16:00:37,597 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,597 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,599 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,599 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,599 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,599 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,600 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,600 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,600 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:37,601 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:37,601 -  log.py[line:110] - INFO: {'name': 'Vladimir Komarov', 'url': '/celebrity/1108509/', 'identity': 'actor'}
2020-05-04 16:00:37,603 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:37,748 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:37,749 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:37,749 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:37,750 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,750 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,751 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :阿尤斯曼·库拉纳 Ayushmann Khurrana
{'identity': ['actor'],
 'name': ['阿尤斯曼·库拉纳 Ayushmann Khurrana'],
 'url': ['/celebrity/1327903/']}
2020-05-04 16:00:37,753 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,753 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,754 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,754 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,755 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,755 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,755 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,755 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,756 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:37,757 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:37,757 -  log.py[line:110] - INFO: {'name': '塔布 Tabu', 'url': '/celebrity/1040796/', 'identity': 'actor'}
2020-05-04 16:00:37,759 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:37,896 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:37,897 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,897 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,899 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :塔布 Tabu
{'identity': ['actor'], 'name': ['塔布 Tabu'], 'url': ['/celebrity/1040796/']}
2020-05-04 16:00:37,901 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,901 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:37,902 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,902 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:37,903 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,903 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:37,903 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,903 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:37,904 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:37,905 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:37,905 -  log.py[line:110] - INFO: {'name': '拉迪卡·艾普特 Radhika Apte', 'url': '/celebrity/1329473/', 'identity': 'actor'}
2020-05-04 16:00:38,019 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:38,167 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:38,168 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,168 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,170 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Yuri Shlykov
{'identity': ['actor'],
 'name': ['Yuri Shlykov'],
 'url': ['/celebrity/1138811/']}
2020-05-04 16:00:38,172 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,172 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,173 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Vladimir Komarov
{'identity': ['actor'],
 'name': ['Vladimir Komarov'],
 'url': ['/celebrity/1108509/']}
2020-05-04 16:00:38,175 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,175 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,177 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:38,177 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:38,178 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:38,178 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:38,178 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:38,178 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:38,179 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:38,180 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:38,180 -  log.py[line:110] - INFO: {'name': '纳塔利亚·布兹科 Natalya Buzko', 'url': '/celebrity/1068070/', 'identity': 'actor'}
2020-05-04 16:00:38,182 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:38,315 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:38,319 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,319 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,321 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:38,321 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:38,321 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:38,321 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:38,322 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:38,322 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:38,322 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:38,323 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:38,323 -  log.py[line:110] - INFO: {'name': '周海媚 Kathy Chow', 'url': '/celebrity/1037908/', 'identity': 'actor'}
2020-05-04 16:00:38,325 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:38,447 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2>
None
2020-05-04 16:00:38,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,448 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,450 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :蕾妮·罗素 Rene Russo
{'identity': ['actor'],
 'name': ['蕾妮·罗素 Rene Russo'],
 'url': ['/celebrity/1004610/']}
2020-05-04 16:00:38,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,451 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,453 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :约翰·斯拉特里 John Slattery
{'identity': ['actor'],
 'name': ['约翰·斯拉特里 John Slattery'],
 'url': ['/celebrity/1022661/']}
2020-05-04 16:00:38,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,455 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:38,456 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :查德维克·博斯曼 Chadwick Boseman
{'identity': ['actor'],
 'name': ['查德维克·博斯曼 Chadwick Boseman'],
 'url': ['/celebrity/1327680/']}
2020-05-04 16:00:38,458 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-04 16:00:38,458 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4 has been crawled, drop it
2020-05-04 16:00:38,487 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85> (referer: https://movie.douban.com/)
2020-05-04 16:00:38,489 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-04 16:00:38,489 -  movie_spider.py[line:134] - INFO: get 25 boxOffice, named .
2020-05-04 16:00:38,490 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#25
{'boxInfo': ['8.10'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1216025],
 'movieName': ['欢迎来北方II'],
 'releaseInfo': ['点映'],
 'seatRate': ['64.9%'],
 'showInfo': [30],
 'showRate': ['<0.1%'],
 'showView': ['75'],
 'splitBoxInfo': ['8.01'],
 'splitSumBoxInfo': ['9.0'],
 'sumBoxInfo': ['9.1'],
 'yearRate': ['2019-05-04#25']}
2020-05-04 16:00:39,442 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-04 and tpp_id = 1213175
2020-05-04 16:00:39,442 -  movie_spider.py[line:156] - INFO: movie_name = 在乎你 and movie_year = 2019-05-04 and tpp_id = 1213175
2020-05-04 16:00:39,442 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-04 16:00:39,442 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%9C%A8%E4%B9%8E%E4%BD%A0
2020-05-04 16:00:39,442 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:39,442 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:39,442 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:39,442 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:39,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,443 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,444 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :尼娜·鲁斯拉诺娃 Nina Ruslanova
{'identity': ['actor'],
 'name': ['尼娜·鲁斯拉诺娃 Nina Ruslanova'],
 'url': ['/celebrity/1146176/']}
2020-05-04 16:00:39,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,444 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,445 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Yuri Shlykov
{'identity': ['actor'],
 'name': ['Yuri Shlykov'],
 'url': ['/celebrity/1138811/']}
2020-05-04 16:00:39,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,445 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,446 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Vladimir Komarov
{'identity': ['actor'],
 'name': ['Vladimir Komarov'],
 'url': ['/celebrity/1108509/']}
2020-05-04 16:00:39,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,446 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,446 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :纳塔利亚·布兹科 Natalya Buzko
{'identity': ['actor'],
 'name': ['纳塔利亚·布兹科 Natalya Buzko'],
 'url': ['/celebrity/1068070/']}
2020-05-04 16:00:39,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,447 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,447 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:39,447 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:39,447 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:39,447 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:39,447 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:39,447 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:39,448 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:39,448 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:39,448 -  log.py[line:110] - INFO: {'name': 'Sergei Bekhterev', 'url': '/celebrity/1062506/', 'identity': 'actor'}
2020-05-04 16:00:39,449 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:39,618 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:39,620 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:39,620 -  movie_spider.py[line:211] - INFO: get person info with identity author
2020-05-04 16:00:39,621 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:39,621 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:39,621 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:39,621 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:39,622 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:39,622 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:39,622 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:39,623 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:39,623 -  log.py[line:110] - INFO: {'name': '罗伯特·戈登 Robert Gordon', 'url': '/celebrity/1285199/', 'identity': 'author'}
2020-05-04 16:00:39,625 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:39,858 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:39,860 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,860 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,861 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Vladimir Komarov
{'identity': ['actor'],
 'name': ['Vladimir Komarov'],
 'url': ['/celebrity/1108509/']}
2020-05-04 16:00:39,863 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,863 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,865 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :纳塔利亚·布兹科 Natalya Buzko
{'identity': ['actor'],
 'name': ['纳塔利亚·布兹科 Natalya Buzko'],
 'url': ['/celebrity/1068070/']}
2020-05-04 16:00:39,867 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,867 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,868 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Sergei Bekhterev
{'identity': ['actor'],
 'name': ['Sergei Bekhterev'],
 'url': ['/celebrity/1062506/']}
2020-05-04 16:00:39,870 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,870 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,872 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :纳塔利亚·布兹科 Natalya Buzko
{'identity': ['actor'],
 'name': ['纳塔利亚·布兹科 Natalya Buzko'],
 'url': ['/celebrity/1068070/']}
2020-05-04 16:00:39,873 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,873 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,875 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Sergei Bekhterev
{'identity': ['actor'],
 'name': ['Sergei Bekhterev'],
 'url': ['/celebrity/1062506/']}
2020-05-04 16:00:39,877 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,877 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:39,878 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:39,878 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:39,879 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:39,879 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:39,880 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:39,880 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:39,880 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:39,881 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:39,881 -  log.py[line:110] - INFO: {'name': 'Olga Popova', 'url': '/celebrity/1030051/', 'identity': 'actor'}
2020-05-04 16:00:39,957 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:40,080 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/3326889/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:40,081 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,081 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,083 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :拉迪卡·艾普特 Radhika Apte
{'identity': ['actor'],
 'name': ['拉迪卡·艾普特 Radhika Apte'],
 'url': ['/celebrity/1329473/']}
2020-05-04 16:00:40,085 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,085 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,086 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:40,086 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:40,087 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:40,087 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:40,087 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:40,087 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:40,088 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:40,089 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:40,089 -  log.py[line:110] - INFO: {'name': '安尔·德霍万 Anil Dhawan', 'url': '/celebrity/1407574/', 'identity': 'actor'}
2020-05-04 16:00:40,091 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:40,239 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:40,240 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,240 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,242 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :安尔·德霍万 Anil Dhawan
{'identity': ['actor'],
 'name': ['安尔·德霍万 Anil Dhawan'],
 'url': ['/celebrity/1407574/']}
2020-05-04 16:00:40,244 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,244 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,245 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:40,245 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:40,246 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:40,246 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:40,246 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:40,246 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:40,247 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:40,248 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:40,248 -  log.py[line:110] - INFO: {'name': '马纳夫·维吉 Manav Vij', 'url': '/celebrity/1407575/', 'identity': 'actor'}
2020-05-04 16:00:40,250 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:40,412 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:40,413 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,413 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,415 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Sergei Bekhterev
{'identity': ['actor'],
 'name': ['Sergei Bekhterev'],
 'url': ['/celebrity/1062506/']}
2020-05-04 16:00:40,416 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,416 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,418 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Olga Popova
{'identity': ['actor'], 'name': ['Olga Popova'], 'url': ['/celebrity/1030051/']}
2020-05-04 16:00:40,421 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-04 16:00:40,423 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,423 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,425 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:40,425 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:40,425 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:40,425 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:40,426 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:40,426 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:40,426 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:40,427 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:40,427 -  log.py[line:110] - INFO: {'name': '胡昌霖 Changlin Hu', 'url': '/celebrity/1407476/', 'identity': 'actor'}
2020-05-04 16:00:40,429 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:40,571 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26879542/?suggest=%E6%8D%89%E5%A6%96%E5%AD%A6%E9%99%A2>
None
2020-05-04 16:00:40,572 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,572 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,574 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :安东尼·麦凯 Anthony Mackie
{'identity': ['actor'],
 'name': ['安东尼·麦凯 Anthony Mackie'],
 'url': ['/celebrity/1027217/']}
2020-05-04 16:00:40,575 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,575 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,577 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :塞巴斯蒂安·斯坦 Sebastian Stan
{'identity': ['actor'],
 'name': ['塞巴斯蒂安·斯坦 Sebastian Stan'],
 'url': ['/celebrity/1021985/']}
2020-05-04 16:00:40,579 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,579 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:40,580 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :克里斯·帕拉特 Chris Pratt
{'identity': ['actor'],
 'name': ['克里斯·帕拉特 Chris Pratt'],
 'url': ['/celebrity/1017967/']}
2020-05-04 16:00:40,582 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II has been crawled, drop it
2020-05-04 16:00:40,582 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II has been crawled, drop it
2020-05-04 16:00:40,607 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4> (referer: https://movie.douban.com/)
2020-05-04 16:00:40,609 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-04 16:00:40,609 -  movie_spider.py[line:134] - INFO: get 26 boxOffice, named .
2020-05-04 16:00:40,610 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#26
{'boxInfo': ['6.34'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [248906],
 'movieName': ['流浪地球'],
 'releaseInfo': [''],
 'seatRate': ['8.6%'],
 'showInfo': [265],
 'showRate': ['<0.1%'],
 'showView': ['8'],
 'splitBoxInfo': ['5.86'],
 'splitSumBoxInfo': ['435400.0'],
 'sumBoxInfo': ['468000.0'],
 'yearRate': ['2019-05-04#26']}
2020-05-04 16:00:41,105 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-04 and tpp_id = 1229702
2020-05-04 16:00:41,105 -  movie_spider.py[line:156] - INFO: movie_name = 青蛙王子历险记 and movie_year = 2019-05-04 and tpp_id = 1229702
2020-05-04 16:00:41,106 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:41,106 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%9D%92%E8%9B%99%E7%8E%8B%E5%AD%90%E5%8E%86%E9%99%A9%E8%AE%B0
2020-05-04 16:00:41,106 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:41,106 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:41,107 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:41,107 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:41,112 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:41,112 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:41,115 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Olga Popova
{'identity': ['actor'], 'name': ['Olga Popova'], 'url': ['/celebrity/1030051/']}
2020-05-04 16:00:41,118 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-04 16:00:42,972 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:42,972 -  movie_spider.py[line:206] - INFO: start to crawl person info
2020-05-04 16:00:42,974 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:42,974 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:42,976 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:42,976 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:42,976 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:42,976 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:42,977 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:42,977 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:42,977 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:42,978 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:42,978 -  log.py[line:110] - INFO: {'name': '索菲亚·玛丽 Sofia Mali', 'url': '/celebrity/1412961/', 'identity': 'actor'}
2020-05-04 16:00:42,980 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:43,151 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:43,152 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:43,152 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:43,154 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :Olga Popova
{'identity': ['actor'], 'name': ['Olga Popova'], 'url': ['/celebrity/1030051/']}
2020-05-04 16:00:43,157 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-04 16:00:44,655 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :3326889
{'actors': '阿拉·杰米多娃/雷娜塔·利特维诺娃/尼娜·鲁斯拉诺娃/Yuri/Vladimir/纳塔利亚·布兹科/Sergei/Olga',
 'area': ' 俄罗斯 / 乌克兰',
 'dbMovieID': ['3326889'],
 'directors': '琪拉·穆拉托娃',
 'doubanRate': ['7.9'],
 'duration': [0],
 'genre': '喜剧/剧情',
 'movieName': ['调音师 Настройщик'],
 'publishedDate': ['2004-09-06'],
 'rateCount': ['130'],
 'tppMovieID': [1239544],
 'writers': '琪拉·穆拉托娃'}
2020-05-04 16:00:46,288 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,288 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,291 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :马纳夫·维吉 Manav Vij
{'identity': ['actor'],
 'name': ['马纳夫·维吉 Manav Vij'],
 'url': ['/celebrity/1407575/']}
2020-05-04 16:00:46,293 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,293 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,294 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:46,294 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:46,294 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:46,294 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:46,295 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:46,295 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:46,296 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:46,296 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:46,297 -  log.py[line:110] - INFO: {'name': '阿什维尼·卡尔塞卡 Ashwini Kalsekar', 'url': '/celebrity/1407576/', 'identity': 'actor'}
2020-05-04 16:00:46,298 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:46,489 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:46,491 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,491 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,492 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :阿什维尼·卡尔塞卡 Ashwini Kalsekar
{'identity': ['actor'],
 'name': ['阿什维尼·卡尔塞卡 Ashwini Kalsekar'],
 'url': ['/celebrity/1407576/']}
2020-05-04 16:00:46,494 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,494 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:46,495 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:46,495 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:46,496 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:46,496 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:46,496 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:46,496 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:46,497 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:46,498 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:46,498 -  log.py[line:110] - INFO: {'name': '查亚·卡达姆 Chhaya Kadam', 'url': '/celebrity/1407577/', 'identity': 'actor'}
2020-05-04 16:00:46,500 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:46,599 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:47,993 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26879542
{'actors': '王泽宗/慈婉彤/周海媚/胡昌霖',
 'area': ' 中国大陆',
 'dbMovieID': ['26879542'],
 'directors': '田梓橙',
 'doubanRate': [''],
 'duration': [96],
 'genre': '奇幻/冒险',
 'movieName': ['捉妖学院'],
 'publishedDate': ['2019-04-30'],
 'rateCount': ['0'],
 'tppMovieID': [1189325],
 'writers': '方岚/田梓橙'}
2020-05-04 16:00:49,095 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:49,095 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:49,098 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :汤姆·希德勒斯顿 Tom Hiddleston
{'identity': ['actor'],
 'name': ['汤姆·希德勒斯顿 Tom Hiddleston'],
 'url': ['/celebrity/1004596/']}
2020-05-04 16:00:49,100 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:49,100 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:49,101 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :佐伊·索尔达娜 Zoe Saldana
{'identity': ['actor'],
 'name': ['佐伊·索尔达娜 Zoe Saldana'],
 'url': ['/celebrity/1047985/']}
2020-05-04 16:00:49,103 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:49,103 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:49,105 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :丹娜·奎里拉 Danai Gurira
{'identity': ['actor'],
 'name': ['丹娜·奎里拉 Danai Gurira'],
 'url': ['/celebrity/1308787/']}
2020-05-04 16:00:49,107 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-04 16:00:49,107 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83 has been crawled, drop it
2020-05-04 16:00:49,131 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II> (referer: https://movie.douban.com/)
2020-05-04 16:00:49,133 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-04 16:00:49,133 -  movie_spider.py[line:134] - INFO: get 27 boxOffice, named .
2020-05-04 16:00:49,134 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#27
{'boxInfo': ['4.94'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1263355],
 'movieName': ['狗眼看人心'],
 'releaseInfo': ['上映15天'],
 'seatRate': ['4.9%'],
 'showInfo': [377],
 'showRate': ['0.1%'],
 'showView': ['4'],
 'splitBoxInfo': ['4.62'],
 'splitSumBoxInfo': ['1707.6'],
 'sumBoxInfo': ['1839.3'],
 'yearRate': ['2019-05-04#27']}
2020-05-04 16:00:50,088 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-04 and tpp_id = 643506
2020-05-04 16:00:50,088 -  movie_spider.py[line:156] - INFO: movie_name = 古镇画情 and movie_year = 2019-05-04 and tpp_id = 643506
2020-05-04 16:00:50,088 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-04 16:00:50,088 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E5%8F%A4%E9%95%87%E7%94%BB%E6%83%85
2020-05-04 16:00:50,089 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:50,089 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:50,089 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:50,089 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:50,097 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,097 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,098 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:50,098 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:50,099 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:50,099 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:50,099 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:50,099 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:50,100 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:50,101 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:50,101 -  log.py[line:110] - INFO: {'name': '詹妮弗·加纳 Jennifer Garner', 'url': '/celebrity/1054512/', 'identity': 'actor'}
2020-05-04 16:00:50,103 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:50,264 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:50,272 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,272 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,273 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :查亚·卡达姆 Chhaya Kadam
{'identity': ['actor'],
 'name': ['查亚·卡达姆 Chhaya Kadam'],
 'url': ['/celebrity/1407577/']}
2020-05-04 16:00:50,275 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,275 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,276 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:50,276 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:50,277 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:50,277 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:50,277 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:50,277 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:50,278 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:50,279 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:50,279 -  log.py[line:110] - INFO: {'name': '萨基尔·侯赛因 Zakir Hussain', 'url': '/celebrity/1407578/', 'identity': 'actor'}
2020-05-04 16:00:50,281 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:50,436 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:50,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,438 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,439 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :萨基尔·侯赛因 Zakir Hussain
{'identity': ['actor'],
 'name': ['萨基尔·侯赛因 Zakir Hussain'],
 'url': ['/celebrity/1407578/']}
2020-05-04 16:00:50,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,441 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,442 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:50,442 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:50,443 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:50,443 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:50,443 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:50,443 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:50,444 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:50,445 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:50,445 -  log.py[line:110] - INFO: {'name': '拉什米·阿格德卡 Rashmi Agdekar', 'url': '/celebrity/1407579/', 'identity': 'actor'}
2020-05-04 16:00:50,447 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:50,546 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:50,553 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,553 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,555 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :本尼迪克特·王 Benedict Wong
{'identity': ['actor'],
 'name': ['本尼迪克特·王 Benedict Wong'],
 'url': ['/celebrity/1301179/']}
2020-05-04 16:00:50,557 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,557 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,558 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :庞·克莱门捷夫 Pom Klementieff
{'identity': ['actor'],
 'name': ['庞·克莱门捷夫 Pom Klementieff'],
 'url': ['/celebrity/1313255/']}
2020-05-04 16:00:50,560 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,560 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:50,562 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :戴夫·巴蒂斯塔 Dave Bautista
{'identity': ['actor'],
 'name': ['戴夫·巴蒂斯塔 Dave Bautista'],
 'url': ['/celebrity/1014003/']}
2020-05-04 16:00:50,564 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-04 16:00:50,564 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83 has been crawled, drop it
2020-05-04 16:00:50,584 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83> (referer: https://movie.douban.com/)
2020-05-04 16:00:50,585 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-04 16:00:50,585 -  movie_spider.py[line:134] - INFO: get 28 boxOffice, named .
2020-05-04 16:00:50,586 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#28
{'boxInfo': ['4.26'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1167831],
 'movieName': ['波西米亚狂想曲'],
 'releaseInfo': ['上映44天'],
 'seatRate': ['12.2%'],
 'showInfo': [103],
 'showRate': ['<0.1%'],
 'showView': ['10'],
 'splitBoxInfo': ['3.94'],
 'splitSumBoxInfo': ['8948.6'],
 'sumBoxInfo': ['9874.0'],
 'yearRate': ['2019-05-04#28']}
2020-05-04 16:00:51,531 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-04 and tpp_id = 836
2020-05-04 16:00:51,531 -  movie_spider.py[line:156] - INFO: movie_name = 毕业那年 and movie_year = 2019-05-04 and tpp_id = 836
2020-05-04 16:00:51,532 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-04 16:00:51,532 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AF%95%E4%B8%9A%E9%82%A3%E5%B9%B4
2020-05-04 16:00:51,532 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:51,532 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:51,533 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:51,533 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:51,537 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,537 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,538 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:51,538 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:51,538 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:51,538 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:51,539 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:51,539 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:51,540 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:51,541 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:51,541 -  log.py[line:110] - INFO: {'name': '肯·哈德森·坎贝尔 Ken Hudson Campbell', 'url': '/celebrity/1068149/', 'identity': 'actor'}
2020-05-04 16:00:51,543 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:51,647 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:51,648 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,648 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,650 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :拉什米·阿格德卡 Rashmi Agdekar
{'identity': ['actor'],
 'name': ['拉什米·阿格德卡 Rashmi Agdekar'],
 'url': ['/celebrity/1407579/']}
2020-05-04 16:00:51,652 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,652 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,654 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:51,654 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:51,654 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:51,654 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:51,655 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:51,655 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:51,656 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:51,657 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:51,657 -  log.py[line:110] - INFO: {'name': '莫希尼·凯瓦拉曼 Mohini Kewalramani', 'url': '/celebrity/1407780/', 'identity': 'actor'}
2020-05-04 16:00:51,660 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:51,795 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:51,796 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,796 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,798 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :莫希尼·凯瓦拉曼 Mohini Kewalramani
{'identity': ['actor'],
 'name': ['莫希尼·凯瓦拉曼 Mohini Kewalramani'],
 'url': ['/celebrity/1407780/']}
2020-05-04 16:00:51,799 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,799 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:51,801 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:51,801 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:51,801 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:51,801 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:51,802 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:51,802 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:51,802 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:51,803 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:51,803 -  log.py[line:110] - INFO: {'name': '卡比尔·谢赫 Kabir Shaikh', 'url': '/celebrity/1385858/', 'identity': 'actor'}
2020-05-04 16:00:52,016 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:52,115 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/30334073/?suggest=%E8%B0%83%E9%9F%B3%E5%B8%88>
None
2020-05-04 16:00:52,116 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,116 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,118 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :利蒂希娅·赖特 Letitia Wright
{'identity': ['actor'],
 'name': ['利蒂希娅·赖特 Letitia Wright'],
 'url': ['/celebrity/1356810/']}
2020-05-04 16:00:52,119 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,119 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,121 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :伊万杰琳·莉莉 Evangeline Lilly
{'identity': ['actor'],
 'name': ['伊万杰琳·莉莉 Evangeline Lilly'],
 'url': ['/celebrity/1021963/']}
2020-05-04 16:00:52,123 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,123 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,124 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :乔恩·费儒 Jon Favreau
{'identity': ['actor'],
 'name': ['乔恩·费儒 Jon Favreau'],
 'url': ['/celebrity/1027164/']}
2020-05-04 16:00:52,126 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-04 16:00:52,126 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2 has been crawled, drop it
2020-05-04 16:00:52,154 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83> (referer: https://movie.douban.com/)
2020-05-04 16:00:52,156 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-04 16:00:52,156 -  movie_spider.py[line:134] - INFO: get 29 boxOffice, named .
2020-05-04 16:00:52,157 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#29
{'boxInfo': ['3.35'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1217701],
 'movieName': ['九克拉战栗'],
 'releaseInfo': ['重映5天'],
 'seatRate': ['4.1%'],
 'showInfo': [443],
 'showRate': ['0.1%'],
 'showView': ['3'],
 'splitBoxInfo': ['3.05'],
 'splitSumBoxInfo': ['30.2'],
 'sumBoxInfo': ['32.8'],
 'yearRate': ['2019-05-04#29']}
2020-05-04 16:00:52,899 -  movie_spider.py[line:156] - INFO: movie_name = 欢迎来北方II and movie_year = 2019-05-04 and tpp_id = 1216025
2020-05-04 16:00:52,899 -  movie_spider.py[line:156] - INFO: movie_name = 欢迎来北方II and movie_year = 2019-05-04 and tpp_id = 1216025
2020-05-04 16:00:52,900 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II
2020-05-04 16:00:52,900 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%8C%97%E6%96%B9II
2020-05-04 16:00:52,900 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:52,900 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:52,900 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:52,900 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:52,904 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,904 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:52,906 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:52,906 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:52,907 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:52,907 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:52,908 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:52,908 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:52,909 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:52,910 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:52,910 -  log.py[line:110] - INFO: {'name': '基南·汤普森 Kenan Thompson', 'url': '/celebrity/1044941/', 'identity': 'actor'}
2020-05-04 16:00:52,912 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:53,044 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:53,045 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:53,045 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:53,047 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :卡比尔·谢赫 Kabir Shaikh
{'identity': ['actor'],
 'name': ['卡比尔·谢赫 Kabir Shaikh'],
 'url': ['/celebrity/1385858/']}
2020-05-04 16:00:53,050 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30334073
{'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼',
 'area': ' 印度',
 'dbMovieID': ['30334073'],
 'directors': '斯里兰姆·拉格万',
 'doubanRate': ['8.3'],
 'duration': [139],
 'genre': '喜剧/犯罪/悬疑/惊悚',
 'movieName': ['调音师 Andhadhun'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['657175'],
 'tppMovieID': [1239544],
 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内'}
2020-05-04 16:00:54,123 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :30334073
{'actors': '阿尤斯曼·库拉纳/塔布/拉迪卡·艾普特/安尔·德霍万/马纳夫·维吉/阿什维尼·卡尔塞卡/查亚·卡达姆/萨基尔·侯赛因/拉什米·阿格德卡/莫希尼·凯瓦拉曼',
 'area': ' 印度',
 'dbMovieID': ['30334073'],
 'directors': '斯里兰姆·拉格万',
 'doubanRate': ['8.3'],
 'duration': [139],
 'genre': '喜剧/犯罪/悬疑/惊悚',
 'movieName': ['调音师 Andhadhun'],
 'publishedDate': ['2018-10-05'],
 'rateCount': ['657175'],
 'tppMovieID': [1239544],
 'writers': '阿里吉特·比沙什/约戈什·查德卡尔/斯里兰姆·拉格万/赫曼斯·饶/普哈·拉达·瑟蒂/奥利维耶·特雷内'}
2020-05-04 16:00:55,815 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:55,815 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:55,819 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :海莉·阿特维尔 Hayley Atwell
{'identity': ['actor'],
 'name': ['海莉·阿特维尔 Hayley Atwell'],
 'url': ['/celebrity/1000051/']}
2020-05-04 16:00:55,820 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:55,820 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:55,822 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :娜塔莉·波特曼 Natalie Portman
{'identity': ['actor'],
 'name': ['娜塔莉·波特曼 Natalie Portman'],
 'url': ['/celebrity/1054454/']}
2020-05-04 16:00:55,824 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:55,824 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:55,826 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :玛丽莎·托梅 Marisa Tomei
{'identity': ['actor'],
 'name': ['玛丽莎·托梅 Marisa Tomei'],
 'url': ['/celebrity/1047974/']}
2020-05-04 16:00:55,828 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-04 16:00:55,828 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97 has been crawled, drop it
2020-05-04 16:00:55,852 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2> (referer: https://movie.douban.com/)
2020-05-04 16:00:55,853 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-04 16:00:55,853 -  movie_spider.py[line:134] - INFO: get 30 boxOffice, named .
2020-05-04 16:00:55,855 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :2019-05-04#30
{'boxInfo': ['3.26'],
 'boxRate': ['<0.1%'],
 'crawlDate': ['2019-05-04'],
 'movieID': [1262087],
 'movieName': ['醒来之爱的呼唤'],
 'releaseInfo': ['上映58天'],
 'seatRate': ['69.3%'],
 'showInfo': [18],
 'showRate': ['<0.1%'],
 'showView': ['61'],
 'splitBoxInfo': ['3.25'],
 'splitSumBoxInfo': ['322.1'],
 'sumBoxInfo': ['324.2'],
 'yearRate': ['2019-05-04#30']}
2020-05-04 16:00:56,662 -  logstats.py[line:48] - INFO: Crawled 42 pages (at 42 pages/min), scraped 40 items (at 40 items/min)
2020-05-04 16:00:56,662 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-04 and tpp_id = 248906
2020-05-04 16:00:56,662 -  movie_spider.py[line:156] - INFO: movie_name = 流浪地球 and movie_year = 2019-05-04 and tpp_id = 248906
2020-05-04 16:00:56,663 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-04 16:00:56,663 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B5%81%E6%B5%AA%E5%9C%B0%E7%90%83
2020-05-04 16:00:56,663 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:56,663 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:56,663 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:56,663 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:56,668 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,668 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,669 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:56,669 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:56,669 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:56,669 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:56,670 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:56,670 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:56,671 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:56,671 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:56,672 -  log.py[line:110] - INFO: {'name': '米拉·库尼斯 Mila Kunis', 'url': '/celebrity/1003481/', 'identity': 'actor'}
2020-05-04 16:00:56,674 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:56,777 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:56,784 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,784 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,786 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :塔伊加·维迪提 Taika Waititi
{'identity': ['actor'],
 'name': ['塔伊加·维迪提 Taika Waititi'],
 'url': ['/celebrity/1076354/']}
2020-05-04 16:00:56,788 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,788 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,789 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :安吉拉·贝塞特 Angela Bassett
{'identity': ['actor'],
 'name': ['安吉拉·贝塞特 Angela Bassett'],
 'url': ['/celebrity/1025214/']}
2020-05-04 16:00:56,791 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,791 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,793 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :迈克尔·道格拉斯 Michael Douglas
{'identity': ['actor'],
 'name': ['迈克尔·道格拉斯 Michael Douglas'],
 'url': ['/celebrity/1053620/']}
2020-05-04 16:00:56,795 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4 has been crawled, drop it
2020-05-04 16:00:56,795 -  middlewares.py[line:144] - ERROR: https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4 has been crawled, drop it
2020-05-04 16:00:56,817 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97> (referer: https://movie.douban.com/)
2020-05-04 16:00:56,820 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-04 and tpp_id = 1263355
2020-05-04 16:00:56,820 -  movie_spider.py[line:156] - INFO: movie_name = 狗眼看人心 and movie_year = 2019-05-04 and tpp_id = 1263355
2020-05-04 16:00:56,820 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-04 16:00:56,820 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E7%8B%97%E7%9C%BC%E7%9C%8B%E4%BA%BA%E5%BF%83
2020-05-04 16:00:56,820 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:56,820 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:56,820 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:56,820 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:56,822 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,822 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,823 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:56,823 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:56,823 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:56,823 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:56,823 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:56,823 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:56,824 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:56,824 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:56,824 -  log.py[line:110] - INFO: {'name': '约翰·奥利弗 John Oliver', 'url': '/celebrity/1173128/', 'identity': 'actor'}
2020-05-04 16:00:56,825 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:56,969 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:56,971 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,971 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,972 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :米歇尔·菲佛 Michelle Pfeiffer
{'identity': ['actor'],
 'name': ['米歇尔·菲佛 Michelle Pfeiffer'],
 'url': ['/celebrity/1035642/']}
2020-05-04 16:00:56,974 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,974 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,976 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :威廉·赫特 William Hurt
{'identity': ['actor'],
 'name': ['威廉·赫特 William Hurt'],
 'url': ['/celebrity/1031849/']}
2020-05-04 16:00:56,977 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,977 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,979 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :寇碧·史莫德斯 Cobie Smulders
{'identity': ['actor'],
 'name': ['寇碧·史莫德斯 Cobie Smulders'],
 'url': ['/celebrity/1000018/']}
2020-05-04 16:00:56,982 -  engine.py[line:239] - DEBUG: Crawled (200) <GET https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4> (referer: https://movie.douban.com/)
2020-05-04 16:00:56,983 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-04 and tpp_id = 1167831
2020-05-04 16:00:56,983 -  movie_spider.py[line:156] - INFO: movie_name = 波西米亚狂想曲 and movie_year = 2019-05-04 and tpp_id = 1167831
2020-05-04 16:00:56,984 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-04 16:00:56,984 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E6%B3%A2%E8%A5%BF%E7%B1%B3%E4%BA%9A%E7%8B%82%E6%83%B3%E6%9B%B2
2020-05-04 16:00:56,984 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:56,984 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:56,984 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:56,984 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:56,990 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,990 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,992 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :郑肯 Ken Jeong
{'identity': ['actor'],
 'name': ['郑肯 Ken Jeong'],
 'url': ['/celebrity/1275017/']}
2020-05-04 16:00:56,994 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,994 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:56,995 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:56,995 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:56,996 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:56,996 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:56,997 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:56,997 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:56,997 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:56,998 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:56,998 -  log.py[line:110] - INFO: {'name': '诺贝特·里奥·布茨 Norbert Leo Butz', 'url': '/celebrity/1076104/', 'identity': 'actor'}
2020-05-04 16:00:57,141 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:57,289 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:57,290 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,290 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,292 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :肖恩·古恩 Sean Gunn
{'identity': ['actor'],
 'name': ['肖恩·古恩 Sean Gunn'],
 'url': ['/celebrity/1022552/']}
2020-05-04 16:00:57,294 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,294 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,296 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :温斯顿·杜克 Winston Duke
{'identity': ['actor'],
 'name': ['温斯顿·杜克 Winston Duke'],
 'url': ['/celebrity/1362864/']}
2020-05-04 16:00:57,297 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,297 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,299 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :琳达·卡德里尼 Linda Cardellini
{'identity': ['actor'],
 'name': ['琳达·卡德里尼 Linda Cardellini'],
 'url': ['/celebrity/1010545/']}
2020-05-04 16:00:57,300 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-04 and tpp_id = 1217701
2020-05-04 16:00:57,300 -  movie_spider.py[line:156] - INFO: movie_name = 九克拉战栗 and movie_year = 2019-05-04 and tpp_id = 1217701
2020-05-04 16:00:57,301 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-04 16:00:57,301 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E4%B9%9D%E5%85%8B%E6%8B%89%E6%88%98%E6%A0%97
2020-05-04 16:00:57,301 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:57,301 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:57,302 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:57,302 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:57,306 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,306 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,308 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,308 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,308 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,308 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,309 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,309 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,309 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:57,310 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:57,310 -  log.py[line:110] - INFO: {'name': '马修·布罗德里克 Matthew Broderick', 'url': '/celebrity/1000045/', 'identity': 'actor'}
2020-05-04 16:00:57,312 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:57,459 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:57,463 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,463 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,464 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :马克斯米利亚诺·赫尔南德斯 Maximiliano Hernández
{'identity': ['actor'],
 'name': ['马克斯米利亚诺·赫尔南德斯 Maximiliano Hernández'],
 'url': ['/celebrity/1339359/']}
2020-05-04 16:00:57,466 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,466 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,468 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :弗兰克·格里罗 Frank Grillo
{'identity': ['actor'],
 'name': ['弗兰克·格里罗 Frank Grillo'],
 'url': ['/celebrity/1100321/']}
2020-05-04 16:00:57,469 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,469 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,471 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :真田广之 Hiroyuki Sanada
{'identity': ['actor'],
 'name': ['真田广之 Hiroyuki Sanada'],
 'url': ['/celebrity/1027879/']}
2020-05-04 16:00:57,473 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,473 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,475 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,475 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,476 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,476 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,476 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,476 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,477 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:57,478 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:57,479 -  log.py[line:110] - INFO: {'name': '凯特·麦克格雷格-斯图尔特 Kate McGregor-Stewart', 'url': '/celebrity/1116577/', 'identity': 'actor'}
2020-05-04 16:00:57,481 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:57,662 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:57,663 -  movie_spider.py[line:156] - INFO: movie_name = 醒来之爱的呼唤 and movie_year = 2019-05-04 and tpp_id = 1262087
2020-05-04 16:00:57,663 -  movie_spider.py[line:156] - INFO: movie_name = 醒来之爱的呼唤 and movie_year = 2019-05-04 and tpp_id = 1262087
2020-05-04 16:00:57,664 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4
2020-05-04 16:00:57,664 -  movie_spider.py[line:161] - INFO: the url of movieInfo in suggestion is https://movie.douban.com/j/subject_suggest?q=%E9%86%92%E6%9D%A5%E4%B9%8B%E7%88%B1%E7%9A%84%E5%91%BC%E5%94%A4
2020-05-04 16:00:57,664 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:57,664 -  movie_spider.py[line:162] - INFO: len of text is 0
2020-05-04 16:00:57,664 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:57,664 -  movie_spider.py[line:164] - ERROR: not response scraped
2020-05-04 16:00:57,668 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,668 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,670 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :汤姆-沃恩-劳勒 Tom Vaughan-Lawlor
{'identity': ['actor'],
 'name': ['汤姆-沃恩-劳勒 Tom Vaughan-Lawlor'],
 'url': ['/celebrity/1332428/']}
2020-05-04 16:00:57,673 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,673 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,675 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :詹姆斯·达西 James D&#39;Arcy
{'identity': ['actor'],
 'name': ['詹姆斯·达西 James D&#39;Arcy'],
 'url': ['/celebrity/1049713/']}
2020-05-04 16:00:57,676 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,676 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,678 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :雅各布·巴特朗 Jacob Batalon
{'identity': ['actor'],
 'name': ['雅各布·巴特朗 Jacob Batalon'],
 'url': ['/celebrity/1376777/']}
2020-05-04 16:00:57,680 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,680 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,681 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,681 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,682 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,682 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,682 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,682 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,683 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:57,684 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:57,684 -  log.py[line:110] - INFO: {'name': '凯文·张伯伦 Kevin Chamberlin', 'url': '/celebrity/1076329/', 'identity': 'actor'}
2020-05-04 16:00:57,686 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:57,842 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:57,843 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,843 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,845 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :范·迪塞尔 Vin Diesel
{'identity': ['actor'],
 'name': ['范·迪塞尔 Vin Diesel'],
 'url': ['/celebrity/1041020/']}
2020-05-04 16:00:57,847 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,847 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,849 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :罗伯特·雷德福 Robert Redford
{'identity': ['actor'],
 'name': ['罗伯特·雷德福 Robert Redford'],
 'url': ['/celebrity/1053617/']}
2020-05-04 16:00:57,850 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,850 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,852 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :乔什·布洛林 Josh Brolin
{'identity': ['actor'],
 'name': ['乔什·布洛林 Josh Brolin'],
 'url': ['/celebrity/1004568/']}
2020-05-04 16:00:57,854 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,854 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:57,855 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,855 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:57,856 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,856 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:57,856 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,856 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:57,857 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:57,858 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:57,858 -  log.py[line:110] - INFO: {'name': '凯斯·索西 Kath Soucie', 'url': '/celebrity/1154840/', 'identity': 'actor'}
2020-05-04 16:00:57,941 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:58,088 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:58,090 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,090 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,091 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :塞缪尔·杰克逊 Samuel L. Jackson
{'identity': ['actor'],
 'name': ['塞缪尔·杰克逊 Samuel L. Jackson'],
 'url': ['/celebrity/1054408/']}
2020-05-04 16:00:58,093 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,093 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,095 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :伊薇特·尼科尔·布朗 Yvette Nicole Brown
{'identity': ['actor'],
 'name': ['伊薇特·尼科尔·布朗 Yvette Nicole Brown'],
 'url': ['/celebrity/1210466/']}
2020-05-04 16:00:58,097 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,097 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,098 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :卡梅伦·布鲁姆布罗 Cameron Brumbelow
{'identity': ['actor'],
 'name': ['卡梅伦·布鲁姆布罗 Cameron Brumbelow'],
 'url': ['/celebrity/1392731/']}
2020-05-04 16:00:58,100 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,100 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,102 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:58,102 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:58,102 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:58,102 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:58,103 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:58,103 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:58,104 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:58,104 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:58,104 -  log.py[line:110] - INFO: {'name': '杰弗里·塔伯 Jeffrey Tambor', 'url': '/celebrity/1010578/', 'identity': 'actor'}
2020-05-04 16:00:58,106 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:58,270 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:58,271 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,271 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,273 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :蒂莫西·卡尔 Timothy Carr
{'identity': ['actor'],
 'name': ['蒂莫西·卡尔 Timothy Carr'],
 'url': ['/celebrity/1392730/']}
2020-05-04 16:00:58,274 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,274 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,276 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :凯瑞·康顿 Kerry Condon
{'identity': ['actor'],
 'name': ['凯瑞·康顿 Kerry Condon'],
 'url': ['/celebrity/1013874/']}
2020-05-04 16:00:58,278 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,278 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,279 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :迈克尔·A·库克 Michael A. Cook
{'identity': ['actor'],
 'name': ['迈克尔·A·库克 Michael A. Cook'],
 'url': ['/celebrity/1392741/']}
2020-05-04 16:00:58,281 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,281 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,283 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:58,283 -  pipelines.py[line:52] - INFO: item is new
2020-05-04 16:00:58,283 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:58,283 -  pipelines.py[line:74] - INFO: type of item is <class 'movie.items.PersonInfoItem'>
2020-05-04 16:00:58,284 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:58,284 -  pipelines.py[line:83] - INFO: insert database finished
2020-05-04 16:00:58,285 -  log.py[line:110] - INFO: BEGIN (implicit)
2020-05-04 16:00:58,286 -  log.py[line:110] - INFO: INSERT INTO person (name, url, identity) VALUES (%(name)s, %(url)s, %(identity)s)
2020-05-04 16:00:58,287 -  log.py[line:110] - INFO: {'name': '达兰·诺里斯 Daran Norris', 'url': '/celebrity/1093776/', 'identity': 'actor'}
2020-05-04 16:00:58,289 -  log.py[line:110] - INFO: COMMIT
2020-05-04 16:00:58,428 -  scraper.py[line:243] - DEBUG: Scraped from <200 https://movie.douban.com/subject/26662282/?suggest=%E7%A5%9E%E5%A5%87%E4%B9%90%E5%9B%AD%E5%8E%86%E9%99%A9%E8%AE%B0>
None
2020-05-04 16:00:58,430 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,430 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,431 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :凯莉·库恩 Carrie Coon
{'identity': ['actor'],
 'name': ['凯莉·库恩 Carrie Coon'],
 'url': ['/celebrity/1342808/']}
2020-05-04 16:00:58,433 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,433 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,435 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :艾玛·福尔曼 Emma Fuhrmann
{'identity': ['actor'],
 'name': ['艾玛·福尔曼 Emma Fuhrmann'],
 'url': ['/celebrity/1321687/']}
2020-05-04 16:00:58,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,436 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:58,438 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :雷纳·加拉赫 Renah Gallagher
{'identity': ['actor'],
 'name': ['雷纳·加拉赫 Renah Gallagher'],
 'url': ['/celebrity/1392734/']}
2020-05-04 16:00:58,442 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26662282
{'actors': '索菲亚·玛丽/詹妮弗·加纳/肯·哈德森·坎贝尔/基南·汤普森/米拉·库尼斯/约翰·奥利弗/郑肯/诺贝特·里奥·布茨/马修·布罗德里克/凯特·麦克格雷格-斯图尔特',
 'area': ' 美国 / 西班牙',
 'dbMovieID': ['26662282'],
 'directors': '迪兰·布朗',
 'doubanRate': ['6.3'],
 'duration': [86],
 'genre': '喜剧/动画/奇幻/冒险',
 'movieName': ['神奇乐园历险记 Wonder Park'],
 'publishedDate': ['2019-03-15'],
 'rateCount': ['2947'],
 'tppMovieID': [1211412],
 'writers': '乔什·阿佩尔鲍姆/安德烈·内梅克/罗伯特·戈登'}
2020-05-04 16:00:59,773 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,773 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,777 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :丹妮拉·加斯基 Daniela Gaskie
{'identity': ['actor'],
 'name': ['丹妮拉·加斯基 Daniela Gaskie'],
 'url': ['/celebrity/1392732/']}
2020-05-04 16:00:59,778 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,778 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,780 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :郑肯 Ken Jeong
{'identity': ['actor'],
 'name': ['郑肯 Ken Jeong'],
 'url': ['/celebrity/1275017/']}
2020-05-04 16:00:59,782 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,782 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,783 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :小弗洛伊德·安东尼·约翰 Floyd Anthony Johns Jr.
{'identity': ['actor'],
 'name': ['小弗洛伊德·安东尼·约翰 Floyd Anthony Johns Jr.'],
 'url': ['/celebrity/1392722/']}
2020-05-04 16:00:59,788 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,788 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,790 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :斯坦·李 Stan Lee
{'identity': ['actor'],
 'name': ['斯坦·李 Stan Lee'],
 'url': ['/celebrity/1013888/']}
2020-05-04 16:00:59,792 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,792 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,794 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :罗斯·马昆德 Ross Marquand
{'identity': ['actor'],
 'name': ['罗斯·马昆德 Ross Marquand'],
 'url': ['/celebrity/1348037/']}
2020-05-04 16:00:59,795 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,795 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,797 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :布伦特·麦吉 Brent McGee
{'identity': ['actor'],
 'name': ['布伦特·麦吉 Brent McGee'],
 'url': ['/celebrity/1392739/']}
2020-05-04 16:00:59,799 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,799 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,800 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :迈克尔·皮耶里诺·米勒 Michael Pierino Miller
{'identity': ['actor'],
 'name': ['迈克尔·皮耶里诺·米勒 Michael Pierino Miller'],
 'url': ['/celebrity/1392737/']}
2020-05-04 16:00:59,801 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,801 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,802 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :卡兰·马尔韦 Callan Mulvey
{'identity': ['actor'],
 'name': ['卡兰·马尔韦 Callan Mulvey'],
 'url': ['/celebrity/1126747/']}
2020-05-04 16:00:59,803 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,803 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,804 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :泰瑞·诺塔里 Terry Notary
{'identity': ['actor'],
 'name': ['泰瑞·诺塔里 Terry Notary'],
 'url': ['/celebrity/1341026/']}
2020-05-04 16:00:59,805 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,805 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,806 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :吉米·雷·皮肯斯 Jimmy Ray Pickens
{'identity': ['actor'],
 'name': ['吉米·雷·皮肯斯 Jimmy Ray Pickens'],
 'url': ['/celebrity/1133195/']}
2020-05-04 16:00:59,807 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,807 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,808 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :迈克尔·詹姆斯·肖 Michael James Shaw
{'identity': ['actor'],
 'name': ['迈克尔·詹姆斯·肖 Michael James Shaw'],
 'url': ['/celebrity/1344984/']}
2020-05-04 16:00:59,809 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,809 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,809 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :泰·辛普金斯 Ty Simpkins
{'identity': ['actor'],
 'name': ['泰·辛普金斯 Ty Simpkins'],
 'url': ['/celebrity/1322702/']}
2020-05-04 16:00:59,810 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,810 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,811 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :格雷格·蒂芬 Greg Tiffan
{'identity': ['actor'],
 'name': ['格雷格·蒂芬 Greg Tiffan'],
 'url': ['/celebrity/1392736/']}
2020-05-04 16:00:59,811 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,811 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,812 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :艾娃·罗素 Ava Russo
{'identity': ['actor'],
 'name': ['艾娃·罗素 Ava Russo'],
 'url': ['/celebrity/1415181/']}
2020-05-04 16:00:59,812 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,812 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,813 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :乔·罗素 Joe Russo
{'identity': ['actor'],
 'name': ['乔·罗素 Joe Russo'],
 'url': ['/celebrity/1320870/']}
2020-05-04 16:00:59,814 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,814 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,814 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :玛丽亚·Z·威尔逊 Maria Z. Wilson
{'identity': ['actor'],
 'name': ['玛丽亚·Z·威尔逊 Maria Z. Wilson'],
 'url': ['/celebrity/1392738/']}
2020-05-04 16:00:59,815 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,815 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,815 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :本杰明·韦弗 Benjamin Weaver
{'identity': ['actor'],
 'name': ['本杰明·韦弗 Benjamin Weaver'],
 'url': ['/celebrity/1392735/']}
2020-05-04 16:00:59,816 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,816 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,816 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :劳尔·阿尔坎塔 Raul Alcantar
{'identity': ['actor'],
 'name': ['劳尔·阿尔坎塔 Raul Alcantar'],
 'url': ['/celebrity/1392728/']}
2020-05-04 16:00:59,817 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,817 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,818 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :雅各布·埃文斯 Jacob Evans
{'identity': ['actor'],
 'name': ['雅各布·埃文斯 Jacob Evans'],
 'url': ['/celebrity/1392727/']}
2020-05-04 16:00:59,818 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,818 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,819 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :何塞·阿尔弗雷多·费尔南德斯 José Alfredo Fernandez
{'identity': ['actor'],
 'name': ['何塞·阿尔弗雷多·费尔南德斯 José Alfredo Fernandez'],
 'url': ['/celebrity/1411163/']}
2020-05-04 16:00:59,819 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,819 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,820 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :布伦特·莫雷尔·加斯金斯 Brent Moorer Gaskins
{'identity': ['actor'],
 'name': ['布伦特·莫雷尔·加斯金斯 Brent Moorer Gaskins'],
 'url': ['/celebrity/1392726/']}
2020-05-04 16:00:59,820 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,820 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,820 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :安东尼·B·哈里斯 Anthony B. Harris
{'identity': ['actor'],
 'name': ['安东尼·B·哈里斯 Anthony B. Harris'],
 'url': ['/celebrity/1266890/']}
2020-05-04 16:00:59,821 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,821 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,821 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :肖恩·麦克米伦 Shaun McMillan
{'identity': ['actor'],
 'name': ['肖恩·麦克米伦 Shaun McMillan'],
 'url': ['/celebrity/1392740/']}
2020-05-04 16:00:59,822 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,822 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,822 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :罗伯特·佩恩 Robert Payen
{'identity': ['actor'],
 'name': ['罗伯特·佩恩 Robert Payen'],
 'url': ['/celebrity/1392724/']}
2020-05-04 16:00:59,823 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,823 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,823 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :麦克斯威尔·海史密斯 Maxwell Highsmith
{'identity': ['actor'],
 'name': ['麦克斯威尔·海史密斯 Maxwell Highsmith'],
 'url': ['/celebrity/1392725/']}
2020-05-04 16:00:59,824 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,824 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,824 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :罗伯特·廷斯利 Robert Tinsley
{'identity': ['actor'],
 'name': ['罗伯特·廷斯利 Robert Tinsley'],
 'url': ['/celebrity/1402482/']}
2020-05-04 16:00:59,825 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,825 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,825 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :费斯·洛根 Faith Logan
{'identity': ['actor'],
 'name': ['费斯·洛根 Faith Logan'],
 'url': ['/celebrity/1393240/']}
2020-05-04 16:00:59,826 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,826 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,826 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :保罗·皮尔斯伯里 Paul Pillsbury
{'identity': ['actor'],
 'name': ['保罗·皮尔斯伯里 Paul Pillsbury'],
 'url': ['/celebrity/1392723/']}
2020-05-04 16:00:59,826 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,826 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,827 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :特拉维斯·汤普森 Travis Thompson
{'identity': ['actor'],
 'name': ['特拉维斯·汤普森 Travis Thompson'],
 'url': ['/celebrity/1392752/']}
2020-05-04 16:00:59,827 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,827 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,828 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :亚历珊德拉‧瑞秋·拉贝 Alexandra Rachael Rabe
{'identity': ['actor'],
 'name': ['亚历珊德拉‧瑞秋·拉贝 Alexandra Rachael Rabe'],
 'url': ['/celebrity/1415276/']}
2020-05-04 16:00:59,828 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,828 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,828 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :贾迈尔·钱伯斯 Jamel Chambers
{'identity': ['actor'],
 'name': ['贾迈尔·钱伯斯 Jamel Chambers'],
 'url': ['/celebrity/1392777/']}
2020-05-04 16:00:59,829 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,829 -  movie_spider.py[line:211] - INFO: get person info with identity actor
2020-05-04 16:00:59,829 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :杰克逊·艾顿 Jackson A. Dunn
{'identity': ['actor'],
 'name': ['杰克逊·艾顿 Jackson A. Dunn'],
 'url': ['/celebrity/1412334/']}
2020-05-04 16:00:59,830 -  scraper.py[line:229] - WARNING: Dropped: Duplicate item found :26100958
{'actors': '小罗伯特·唐尼/克里斯·埃文斯/马克·鲁弗洛/克里斯·海姆斯沃斯/斯嘉丽·约翰逊/杰瑞米·雷纳/保罗·路德/凯伦·吉兰/唐·钱德尔/布丽·拉尔森',
 'area': ' 美国',
 'dbMovieID': ['26100958'],
 'directors': '安东尼·罗素/乔·罗素',
 'doubanRate': ['8.5'],
 'duration': [181],
 'genre': '动作/科幻/奇幻/冒险',
 'movieName': ['复仇者联盟4：终局之战 Avengers: Endgame'],
 'publishedDate': ['2019-04-24'],
 'rateCount': ['833498'],
 'tppMovieID': [248172],
 'writers': '克里斯托弗·马库斯/斯蒂芬·麦克菲利/斯坦·李/杰克·科比/吉姆·斯特林'}
2020-05-04 16:01:01,026 -  engine.py[line:296] - INFO: Closing spider (finished)
2020-05-04 16:01:01,030 -  statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 53306,
 'downloader/request_count': 44,
 'downloader/request_method_count/GET': 44,
 'downloader/response_bytes': 318093,
 'downloader/response_count': 44,
 'downloader/response_status_count/200': 44,
 'elapsed_time_seconds': 68.743553,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 5, 4, 8, 1, 1, 29396),
 'item_dropped_count': 240,
 'item_dropped_reasons_count/DropItem': 240,
 'item_scraped_count': 49,
 'log_count/ERROR': 66,
 'log_count/WARNING': 240,
 'memusage/max': 119136256,
 'memusage/startup': 73777152,
 'request_depth_max': 2,
 'response_received_count': 44,
 'scheduler/dequeued': 44,
 'scheduler/dequeued/memory': 44,
 'scheduler/enqueued': 44,
 'scheduler/enqueued/memory': 44,
 'start_time': datetime.datetime(2020, 5, 4, 7, 59, 52, 285843)}
2020-05-04 16:01:01,030 -  engine.py[line:327] - INFO: Spider closed (finished)
